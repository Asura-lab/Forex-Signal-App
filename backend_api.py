# -*- coding: utf-8 -*-
"""
–§–æ—Ä–µ–∫—Å –°–∏–≥–Ω–∞–ª –¢–∞–∞–º–∞–≥–ª–∞—Ö Backend API
Flask –∞—à–∏–≥–ª–∞–Ω REST API “Ø“Ø—Å–≥—ç—Ö
React Native –∞–ø–ø–ª–∏–∫–µ–π—à–Ω–∞–∞—Å –¥—É—É–¥–∞–≥–¥–∞–Ω–∞
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import numpy as np
import pickle
import os
from datetime import datetime, timedelta
import hashlib
import secrets
import json

app = Flask(__name__)
CORS(app)  # React Native-–∞–∞—Å –¥—É—É–¥–∞–∂ –±–æ–ª–æ—Ö–æ–æ—Ä CORS –∏–¥—ç–≤—Ö–∂“Ø“Ø–ª—ç—Ö

# –ú–æ–¥–µ–ª—å –±–∞ scaler –∞—á–∞–∞–ª–∞—Ö
MODEL_PATH = 'models/hmm_forex_model.pkl'
SCALER_PATH = 'models/hmm_scaler.pkl'

# –ì–ª–æ–±–∞–ª —Ö—É–≤—å—Å–∞–≥—á—É—É–¥
model = None
scaler = None

# –•—ç—Ä—ç–≥–ª—ç–≥—á–¥–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª —Ö–∞–¥–≥–∞–ª–∞—Ö (JSON —Ñ–∞–π–ª–¥)
USERS_FILE = 'users_data.json'
SESSIONS_FILE = 'sessions_data.json'

def load_users():
    """–•—ç—Ä—ç–≥–ª—ç–≥—á–¥–∏–π–Ω –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –∞—á–∞–∞–ª–∞—Ö"""
    if os.path.exists(USERS_FILE):
        with open(USERS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_users(users):
    """–•—ç—Ä—ç–≥–ª—ç–≥—á–¥–∏–π–Ω –º—ç–¥—ç—ç–ª–ª–∏–π–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö"""
    with open(USERS_FILE, 'w', encoding='utf-8') as f:
        json.dump(users, f, ensure_ascii=False, indent=2)

def load_sessions():
    """Session –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –∞—á–∞–∞–ª–∞—Ö"""
    if os.path.exists(SESSIONS_FILE):
        with open(SESSIONS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_sessions(sessions):
    """Session –º—ç–¥—ç—ç–ª–ª–∏–π–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö"""
    with open(SESSIONS_FILE, 'w', encoding='utf-8') as f:
        json.dump(sessions, f, ensure_ascii=False, indent=2)

def hash_password(password):
    """–ù—É—É—Ü “Ø–≥–∏–π–≥ hash —Ö–∏–π—Ö"""
    return hashlib.sha256(password.encode()).hexdigest()

def generate_token():
    """–°–∞–Ω–∞–º—Å–∞—Ä–≥“Ø–π token “Ø“Ø—Å–≥—ç—Ö"""
    return secrets.token_urlsafe(32)

def verify_token(token):
    """Token —à–∞–ª–≥–∞–∂ —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –±—É—Ü–∞–∞—Ö"""
    sessions = load_sessions()
    if token in sessions:
        session = sessions[token]
        # Token —Ö“Ø—á–∏–Ω—Ç—ç–π —ç—Å—ç—Ö–∏–π–≥ —à–∞–ª–≥–∞—Ö (24 —Ü–∞–≥)
        expires_at = datetime.fromisoformat(session['expires_at'])
        if datetime.now() < expires_at:
            return session['email']
    return None

def load_models():
    """–ú–æ–¥–µ–ª—å –±–∞ scaler –∞—á–∞–∞–ª–∞—Ö"""
    global model, scaler
    
    try:
        with open(MODEL_PATH, 'rb') as f:
            model = pickle.load(f)
        
        with open(SCALER_PATH, 'rb') as f:
            scaler = pickle.load(f)
        
        print("‚úì –ú–æ–¥–µ–ª—å –∞–º–∂–∏–ª—Ç—Ç–∞–π –∞—á–∞–∞–ª–∞–≥–¥–ª–∞–∞")
        return True
    except Exception as e:
        print(f"‚úó –ú–æ–¥–µ–ª—å –∞—á–∞–∞–ª–∞—Ö –∞–ª–¥–∞–∞: {e}")
        return False

def calculate_features(df):
    """–¢–µ—Ö–Ω–∏–∫–∏–π–Ω —à–∏–Ω–∂ —á–∞–Ω–∞—Ä—É—É–¥ —Ç–æ–æ—Ü–æ–æ–ª–æ—Ö"""
    df = df.copy()
    
    # “Æ–Ω–∏–π–Ω ”©”©—Ä—á–ª”©–ª—Ç
    df['returns'] = df['close'].pct_change()
    
    # Volatility
    df['volatility'] = (df['high'] - df['low']) / df['close']
    
    # ATR
    df['true_range'] = np.maximum(
        df['high'] - df['low'],
        np.maximum(
            abs(df['high'] - df['close'].shift(1)),
            abs(df['low'] - df['close'].shift(1))
        )
    )
    df['atr'] = df['true_range'].rolling(window=14).mean()
    
    # Moving Averages
    df['ma_5'] = df['close'].rolling(window=5).mean()
    df['ma_20'] = df['close'].rolling(window=20).mean()
    df['ma_50'] = df['close'].rolling(window=50).mean()
    df['ma_cross'] = (df['ma_5'] - df['ma_20']) / df['close']
    
    # RSI
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    
    # Volume ”©”©—Ä—á–ª”©–ª—Ç
    df['volume_change'] = df['volume'].pct_change()
    
    # NaN —É—Å—Ç–≥–∞—Ö
    df.dropna(inplace=True)
    
    return df

@app.route('/')
def home():
    """API –º—ç–¥—ç—ç–ª—ç–ª"""
    return jsonify({
        'name': 'Forex Signal Prediction API',
        'version': '1.0',
        'status': 'active',
        'model_loaded': model is not None,
        'endpoints': {
            '/predict': 'POST - –§–æ—Ä–µ–∫—Å —Ö”©–¥”©–ª–≥”©”©–Ω —Ç–∞–∞–º–∞–≥–ª–∞—Ö',
            '/predict_file': 'POST - CSV —Ñ–∞–π–ª–∞–∞—Å —Ç–∞–∞–º–∞–≥–ª–∞–ª —Ö–∏–π—Ö',
            '/model_info': 'GET - –ú–æ–¥–µ–ª–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª'
        }
    })

@app.route('/model_info', methods=['GET'])
def model_info():
    """–ú–æ–¥–µ–ª–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª —Ö–∞—Ä—É—É–ª–∞—Ö"""
    if model is None:
        return jsonify({'error': '–ú–æ–¥–µ–ª—å –∞—á–∞–∞–ª–∞–≥–¥–∞–∞–≥“Ø–π –±–∞–π–Ω–∞'}), 500
    
    return jsonify({
        'n_components': model.n_components,
        'covariance_type': model.covariance_type,
        'features': ['returns', 'volatility', 'atr', 'ma_cross', 'rsi', 'volume_change'],
        'labels': {
            '0': 'High volatility down',
            '1': 'Medium volatility down',
            '2': 'No trend',
            '3': 'Medium volatility up',
            '4': 'High volatility up'
        }
    })

@app.route('/predict', methods=['POST'])
def predict():
    """
    –®–∏–Ω—ç OHLCV –¥–∞—Ç–∞ –¥—ç—ç—Ä —Ç–∞–∞–º–∞–≥–ª–∞–ª —Ö–∏–π—Ö
    
    Request body (JSON):
    {
        "data": [
            {"time": "2024-01-01 00:00", "open": 1.1000, "high": 1.1010, "low": 1.0990, "close": 1.1005, "volume": 1000},
            ...
        ]
    }
    """
    if model is None:
        return jsonify({'error': '–ú–æ–¥–µ–ª—å –∞—á–∞–∞–ª–∞–≥–¥–∞–∞–≥“Ø–π –±–∞–π–Ω–∞'}), 500
    
    try:
        # JSON –¥–∞—Ç–∞ –∞–≤–∞—Ö
        data = request.json.get('data')
        
        if not data or len(data) < 50:
            return jsonify({'error': '–•–∞–Ω–≥–∞–ª—Ç—Ç–∞–π –¥–∞—Ç–∞ –±–∞–π—Ö–≥“Ø–π (—Ö–∞–º–≥–∏–π–Ω –±–∞–≥–∞–¥–∞–∞ 50 –º”©—Ä —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π)'}), 400
        
        # DataFrame “Ø“Ø—Å–≥—ç—Ö
        df = pd.DataFrame(data)
        df['time'] = pd.to_datetime(df['time'])
        df.set_index('time', inplace=True)
        
        # –®–∏–Ω–∂ —á–∞–Ω–∞—Ä—É—É–¥ —Ç–æ–æ—Ü–æ–æ–ª–æ—Ö
        df = calculate_features(df)
        
        if len(df) == 0:
            return jsonify({'error': '–®–∏–Ω–∂ —á–∞–Ω–∞—Ä—É—É–¥ —Ç–æ–æ—Ü–æ–æ–ª—Å–Ω—ã –¥–∞—Ä–∞–∞ –¥–∞—Ç–∞ —Ö–æ–æ—Å–æ–Ω –±–∞–π–Ω–∞'}), 400
        
        # –¢–∞–∞–º–∞–≥–ª–∞–ª —Ö–∏–π—Ö
        feature_columns = ['returns', 'volatility', 'atr', 'ma_cross', 'rsi', 'volume_change']
        X = scaler.transform(df[feature_columns].values)
        predictions = model.predict(X)
        
        # –ê–Ω–≥–∏–ª–∞–ª—ã–Ω –Ω—ç—Ä—Å
        label_names = {
            0: 'High volatility down',
            1: 'Medium volatility down',
            2: 'No trend',
            3: 'Medium volatility up',
            4: 'High volatility up'
        }
        
        # –°“Ø“Ø–ª—á–∏–π–Ω —Ç–∞–∞–º–∞–≥–ª–∞–ª (—Ö–∞–º–≥–∏–π–Ω —Å“Ø“Ø–ª–∏–π–Ω “Ø—Ä –¥“Ø–Ω)
        latest_prediction = int(predictions[-1])
        latest_trend = label_names[latest_prediction]
        
        # –ú–∞–≥–∞–¥–ª–∞–ª —Ç–æ–æ—Ü–æ–æ–ª–æ—Ö (—Å“Ø“Ø–ª–∏–π–Ω 20 –º”©—Ä–∏–π–Ω —Ç–∞–∞–º–∞–≥–ª–∞–ª—ã–Ω —Ö—É–≤–∞–∞—Ä–∏–ª–∞–ª—Ç)
        recent_predictions = predictions[-20:] if len(predictions) >= 20 else predictions
        probabilities = {}
        for label, name in label_names.items():
            count = np.sum(recent_predictions == label)
            probabilities[name] = float(count / len(recent_predictions) * 100)
        
        # “Æ—Ä –¥“Ø–Ω –±—É—Ü–∞–∞—Ö
        result = {
            'success': True,
            'timestamp': datetime.now().isoformat(),
            'latest_prediction': {
                'label': latest_prediction,
                'trend': latest_trend,
                'confidence': probabilities[latest_trend]
            },
            'probabilities': probabilities,
            'recent_trends': [
                {
                    'label': int(p),
                    'trend': label_names[int(p)]
                }
                for p in predictions[-10:]  # –°“Ø“Ø–ª–∏–π–Ω 10 —Ç–∞–∞–º–∞–≥–ª–∞–ª
            ],
            'data_points_analyzed': len(predictions)
        }
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'error': f'–¢–∞–∞–º–∞–≥–ª–∞–ª —Ö–∏–π—Ö —è–≤—Ü–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {str(e)}'}), 500

@app.route('/predict_file', methods=['POST'])
def predict_file():
    """
    CSV —Ñ–∞–π–ª–∞–∞—Å –¥–∞—Ç–∞ —É–Ω—à–∏–∂ —Ç–∞–∞–º–∞–≥–ª–∞–ª —Ö–∏–π—Ö
    
    Request body (JSON):
    {
        "file_path": "data/test/EUR_USD_test.csv"
    }
    """
    if model is None:
        return jsonify({'error': '–ú–æ–¥–µ–ª—å –∞—á–∞–∞–ª–∞–≥–¥–∞–∞–≥“Ø–π –±–∞–π–Ω–∞'}), 500
    
    try:
        file_path = request.json.get('file_path')
        
        if not file_path or not os.path.exists(file_path):
            return jsonify({'error': '–§–∞–π–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π'}), 400
        
        # –î–∞—Ç–∞ —É–Ω—à–∏–∂ –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö
        df = pd.read_csv(file_path)
        df.columns = ['time', 'open', 'high', 'low', 'close', 'volume']
        df['time'] = pd.to_datetime(df['time'])
        df.set_index('time', inplace=True)
        
        # –®–∏–Ω–∂ —á–∞–Ω–∞—Ä—É—É–¥ —Ç–æ–æ—Ü–æ–æ–ª–æ—Ö
        df = calculate_features(df)
        
        # –¢–∞–∞–º–∞–≥–ª–∞–ª —Ö–∏–π—Ö
        feature_columns = ['returns', 'volatility', 'atr', 'ma_cross', 'rsi', 'volume_change']
        X = scaler.transform(df[feature_columns].values)
        predictions = model.predict(X)
        
        # –ê–Ω–≥–∏–ª–∞–ª—ã–Ω —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
        label_names = {
            0: 'High volatility down',
            1: 'Medium volatility down',
            2: 'No trend',
            3: 'Medium volatility up',
            4: 'High volatility up'
        }
        
        statistics = {}
        for label, name in label_names.items():
            count = np.sum(predictions == label)
            statistics[name] = {
                'count': int(count),
                'percentage': float(count / len(predictions) * 100)
            }
        
        result = {
            'success': True,
            'file': os.path.basename(file_path),
            'total_predictions': len(predictions),
            'statistics': statistics,
            'latest_prediction': {
                'label': int(predictions[-1]),
                'trend': label_names[int(predictions[-1])]
            }
        }
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'error': f'–§–∞–π–ª –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö —è–≤—Ü–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {str(e)}'}), 500

if __name__ == '__main__':
    print("="*60)
    print("–§–û–†–ï–ö–° –°–ò–ì–ù–ê–õ –¢–ê–ê–ú–ê–ì–õ–ê–• API")
    print("="*60)
    
    # –ú–æ–¥–µ–ª—å –∞—á–∞–∞–ª–∞—Ö
    if load_models():
        print("\nüöÄ API —ç—Ö—ç–ª–∂ –±–∞–π–Ω–∞...")
        print("üì° –•–æ–ª–±–æ–≥–¥–æ—Ö —Ö–∞—è–≥: http://localhost:5000")
        print("\nEndpoints:")
        print("  GET  /           - API –º—ç–¥—ç—ç–ª—ç–ª")
        print("  GET  /model_info - –ú–æ–¥–µ–ª–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª")
        print("  POST /predict    - –¢–∞–∞–º–∞–≥–ª–∞–ª —Ö–∏–π—Ö")
        print("  POST /predict_file - –§–∞–π–ª–∞–∞—Å —Ç–∞–∞–º–∞–≥–ª–∞–ª")
        print("\n" + "="*60)
        
        app.run(debug=True, host='0.0.0.0', port=5000)
    else:
        print("\n‚úó –ú–æ–¥–µ–ª—å –∞—á–∞–∞–ª–∞–≥–¥–∞–∞–≥“Ø–π —Ç—É–ª API —ç—Ö—ç–ª–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π")
        print("  –≠—Ö–ª—ç—ç–¥ HMM_machine_learning.ipynb-–≥ –∞–∂–∏–ª–ª—É—É–ª–∂ –º–æ–¥–µ–ª—å —Å—É—Ä–≥–∞–∞—Ä–∞–π")
