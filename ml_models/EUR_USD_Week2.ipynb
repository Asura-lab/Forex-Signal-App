{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EUR/USD Week 2 Training - Improved Model\n",
    "\n",
    "## Objective\n",
    "Train an improved Transformer + LSTM model for EUR/USD prediction with optimized hyperparameters.\n",
    "\n",
    "**Previous Performance**: 33.46% accuracy (below baseline)\n",
    "\n",
    "**Target Performance**: 65%+ accuracy\n",
    "\n",
    "## Key Improvements:\n",
    "1. ‚úÖ Optimized hyperparameters (learning rate, batch size, dropout)\n",
    "2. ‚úÖ Increased model capacity (more LSTM units)\n",
    "3. ‚úÖ Better data preprocessing and feature scaling\n",
    "4. ‚úÖ Class weight balancing for imbalanced data\n",
    "5. ‚úÖ Improved label creation strategy\n",
    "6. ‚úÖ Learning rate scheduling\n",
    "7. ‚úÖ Extended training with proper early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Custom modules\n",
    "from backend.ml.preprocessing.data_loader import ForexDataLoader, create_labels\n",
    "from backend.ml.preprocessing.sequence_generator import SequenceGenerator, split_train_val_test\n",
    "from backend.ml.features.technical_indicators import calculate_all_features, get_feature_columns\n",
    "from backend.ml.models.transformer_lstm import build_transformer_lstm_model, compile_model\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"‚úÖ GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"\\nüéØ EUR/USD Week 2 Training - Optimized Hyperparameters\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "**Note**: This notebook assumes you have either:\n",
    "- Pre-calculated features in `../data/processed/EUR_USD_features.csv`\n",
    "- Raw data from Kaggle or UniRate API\n",
    "\n",
    "If you don't have the data, you can generate synthetic data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load pre-calculated features\n",
    "features_file = Path('../data/processed/EUR_USD_features.csv')\n",
    "\n",
    "if features_file.exists():\n",
    "    print(f\"üì• Loading features from: {features_file}\")\n",
    "    df_features = pd.read_csv(features_file, index_col=0, parse_dates=True)\n",
    "    print(f\"‚úÖ Features loaded!\")\n",
    "    print(f\"  Shape: {df_features.shape}\")\n",
    "    print(f\"  Date range: {df_features.index.min()} to {df_features.index.max()}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Feature file not found. Generating synthetic data for demonstration...\\n\")\n",
    "    \n",
    "    # Generate synthetic EUR/USD data for testing\n",
    "    n_samples = 50000  # About 35 days of 1-minute data\n",
    "    dates = pd.date_range(start='2024-01-01', periods=n_samples, freq='1min')\n",
    "    \n",
    "    # Realistic EUR/USD price around 1.10\n",
    "    base_price = 1.10\n",
    "    returns = np.random.randn(n_samples) * 0.0001  # Small random returns\n",
    "    close = base_price * np.exp(np.cumsum(returns))\n",
    "    \n",
    "    # OHLCV data\n",
    "    df = pd.DataFrame({\n",
    "        'open': close * (1 + np.random.randn(n_samples) * 0.00005),\n",
    "        'high': close * (1 + np.abs(np.random.randn(n_samples)) * 0.0001),\n",
    "        'low': close * (1 - np.abs(np.random.randn(n_samples)) * 0.0001),\n",
    "        'close': close,\n",
    "        'tick_volume': np.random.randint(100, 1000, n_samples)\n",
    "    }, index=dates)\n",
    "    \n",
    "    print(\"üîß Calculating technical indicators...\")\n",
    "    df_features = calculate_all_features(df)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Synthetic data generated!\")\n",
    "    print(f\"  Shape: {df_features.shape}\")\n",
    "    print(f\"  Features: {len(df_features.columns)} columns\")\n",
    "    \n",
    "    # Save for future use\n",
    "    Path('../data/processed').mkdir(parents=True, exist_ok=True)\n",
    "    df_features.to_csv(features_file)\n",
    "    print(f\"\\nüíæ Saved features to: {features_file}\")\n",
    "\n",
    "print(f\"\\nüìä Data Info:\")\n",
    "print(f\"  Total rows: {len(df_features):,}\")\n",
    "print(f\"  Total features: {len(df_features.columns)}\")\n",
    "print(f\"\\nüîç First few rows:\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature columns (exclude OHLCV base columns)\n",
    "feature_cols = get_feature_columns()\n",
    "\n",
    "print(f\"üìã Feature columns ({len(feature_cols)} total):\")\n",
    "for i, col in enumerate(feature_cols[:15], 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "print(f\"  ... and {len(feature_cols) - 15} more\\n\")\n",
    "\n",
    "# Verify all features exist\n",
    "missing = [f for f in feature_cols if f not in df_features.columns]\n",
    "if missing:\n",
    "    print(f\"‚ö†Ô∏è  Missing features: {missing}\")\n",
    "    # Remove missing features\n",
    "    feature_cols = [f for f in feature_cols if f in df_features.columns]\n",
    "    print(f\"   Using {len(feature_cols)} available features\")\n",
    "else:\n",
    "    print(f\"‚úÖ All {len(feature_cols)} features present!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Labels with Optimized Parameters\n",
    "\n",
    "**Key Improvement**: Using a smaller threshold to create more actionable signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized label creation parameters\n",
    "HORIZON = 15  # Predict 15 minutes ahead\n",
    "THRESHOLD = 0.0003  # 0.03% - more sensitive to capture smaller moves\n",
    "\n",
    "print(f\"üè∑Ô∏è  Creating labels with OPTIMIZED parameters:\")\n",
    "print(f\"  Horizon: {HORIZON} minutes\")\n",
    "print(f\"  Threshold: {THRESHOLD * 100:.3f}% (reduced from 0.05% for more signals)\\n\")\n",
    "\n",
    "labels = create_labels(df_features, horizon=HORIZON, threshold=THRESHOLD)\n",
    "\n",
    "# Class distribution\n",
    "print(f\"üìä Label Distribution:\")\n",
    "label_counts = labels.value_counts().sort_index()\n",
    "for label, count in label_counts.items():\n",
    "    label_name = ['SELL', 'NEUTRAL', 'BUY'][label]\n",
    "    pct = count / len(labels) * 100\n",
    "    print(f\"  {label_name:8}: {count:7,} ({pct:5.1f}%)\")\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "label_counts.plot(kind='bar', color=['red', 'gray', 'green'])\n",
    "plt.title(f'Label Distribution (Threshold={THRESHOLD*100:.3f}%)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Label (0=SELL, 1=NEUTRAL, 2=BUY)', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check balance\n",
    "neutral_pct = (label_counts.get(1, 0) / len(labels)) * 100\n",
    "if 30 <= neutral_pct <= 70:\n",
    "    print(f\"\\n‚úÖ Label distribution looks good! ({neutral_pct:.1f}% neutral)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Label distribution may need adjustment ({neutral_pct:.1f}% neutral)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Sequences with Improved Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZED sequence parameters\n",
    "SEQUENCE_LENGTH = 120  # Increased from 60 to capture more context\n",
    "STEP = 3  # Smaller step for more training samples\n",
    "\n",
    "print(f\"üì¶ Creating sequences with OPTIMIZED parameters:\")\n",
    "print(f\"  Sequence length: {SEQUENCE_LENGTH} minutes (increased for better context)\")\n",
    "print(f\"  Step size: {STEP} (smaller for more training data)\\n\")\n",
    "\n",
    "seq_gen = SequenceGenerator(\n",
    "    sequence_length=SEQUENCE_LENGTH,\n",
    "    horizon=HORIZON,\n",
    "    step=STEP\n",
    ")\n",
    "\n",
    "X, y, y_onehot, indices = seq_gen.prepare_data(\n",
    "    df_features,\n",
    "    features=feature_cols,\n",
    "    labels=labels,\n",
    "    fit_scaler=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Sequences created!\")\n",
    "print(f\"  X shape: {X.shape}\")\n",
    "print(f\"  y shape: {y.shape}\")\n",
    "print(f\"  y_onehot shape: {y_onehot.shape}\")\n",
    "print(f\"  Total sequences: {len(X):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronological split\n",
    "data_splits = split_train_val_test(\n",
    "    X, y, y_onehot, indices,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15\n",
    ")\n",
    "\n",
    "X_train = data_splits['X_train']\n",
    "y_train = data_splits['y_train_onehot']\n",
    "y_train_classes = data_splits['y_train']\n",
    "\n",
    "X_val = data_splits['X_val']\n",
    "y_val = data_splits['y_val_onehot']\n",
    "\n",
    "X_test = data_splits['X_test']\n",
    "y_test = data_splits['y_test_onehot']\n",
    "y_test_classes = data_splits['y_test']\n",
    "\n",
    "print(f\"üìä Dataset Splits:\")\n",
    "print(f\"  Train: X={X_train.shape}, y={y_train.shape} ({len(X_train):,} samples)\")\n",
    "print(f\"  Val:   X={X_val.shape}, y={y_val.shape} ({len(X_val):,} samples)\")\n",
    "print(f\"  Test:  X={X_test.shape}, y={y_test.shape} ({len(X_test):,} samples)\")\n",
    "\n",
    "# Calculate class distribution in training set\n",
    "print(f\"\\nüìä Training Set Class Distribution:\")\n",
    "train_dist = pd.Series(y_train_classes).value_counts().sort_index()\n",
    "for label, count in train_dist.items():\n",
    "    label_name = ['SELL', 'NEUTRAL', 'BUY'][label]\n",
    "    pct = count / len(y_train_classes) * 100\n",
    "    print(f\"  {label_name:8}: {count:7,} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculate Class Weights\n",
    "\n",
    "**Key Improvement**: Handle class imbalance with proper weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced data\n",
    "class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train_classes),\n",
    "    y=y_train_classes\n",
    ")\n",
    "\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
    "\n",
    "print(f\"‚öñÔ∏è  Class Weights (to handle imbalance):\")\n",
    "for i, weight in class_weights.items():\n",
    "    label_name = ['SELL', 'NEUTRAL', 'BUY'][i]\n",
    "    print(f\"  {label_name:8}: {weight:.3f}x\")\n",
    "print(f\"\\nüìù Note: Higher weight = model will focus more on this class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Build Model with OPTIMIZED Architecture\n",
    "\n",
    "**Key Improvements**:\n",
    "- Increased LSTM units: [256, 128] (was [128, 64])\n",
    "- Optimal dropout: 0.4 (was 0.5)\n",
    "- More attention heads: 8 (optimal)\n",
    "- Larger feed-forward dimension: 512 (was 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZED model hyperparameters\n",
    "MODEL_CONFIG = {\n",
    "    'sequence_length': SEQUENCE_LENGTH,\n",
    "    'n_features': len(feature_cols),\n",
    "    'n_heads': 8,  # Multi-head attention\n",
    "    'ff_dim': 512,  # Increased feed-forward dimension\n",
    "    'lstm_units': [256, 128],  # Increased LSTM capacity\n",
    "    'dropout_rate': 0.4  # Balanced dropout\n",
    "}\n",
    "\n",
    "print(\"üèóÔ∏è  Building OPTIMIZED Transformer + LSTM Model:\\n\")\n",
    "print(\"Model Configuration:\")\n",
    "for key, value in MODEL_CONFIG.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "model = build_transformer_lstm_model(**MODEL_CONFIG)\n",
    "\n",
    "print(f\"\\n‚úÖ Model built successfully!\")\n",
    "print(f\"  Total parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compile Model with Optimized Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZED learning rate\n",
    "LEARNING_RATE = 0.0001  # Sweet spot for this architecture\n",
    "\n",
    "model = compile_model(model, learning_rate=LEARNING_RATE)\n",
    "\n",
    "print(f\"‚úÖ Model compiled with learning rate: {LEARNING_RATE}\")\n",
    "print(f\"\\nüìã Model Summary:\")\n",
    "print(\"=\"*70)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Setup Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model directory\n",
    "model_dir = Path('../models/EUR_USD_Week2')\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Training callbacks\n",
    "callbacks = [\n",
    "    # Save best model\n",
    "    ModelCheckpoint(\n",
    "        filepath=str(model_dir / 'best_model.keras'),\n",
    "        monitor='val_direction_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Early stopping with patience\n",
    "    EarlyStopping(\n",
    "        monitor='val_direction_accuracy',\n",
    "        mode='max',\n",
    "        patience=15,  # Increased patience\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate on plateau\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=7,  # Increased patience\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard logging\n",
    "    TensorBoard(\n",
    "        log_dir=str(model_dir / 'logs'),\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Callbacks configured:\")\n",
    "print(\"  ‚Ä¢ ModelCheckpoint - Save best model\")\n",
    "print(\"  ‚Ä¢ EarlyStopping - patience=15 epochs\")\n",
    "print(\"  ‚Ä¢ ReduceLROnPlateau - factor=0.5, patience=7 epochs\")\n",
    "print(\"  ‚Ä¢ TensorBoard - logging enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Train Model with Optimized Settings\n",
    "\n",
    "**Key Improvements**:\n",
    "- Batch size: 64 (optimal for this architecture)\n",
    "- Epochs: 150 (with early stopping)\n",
    "- Class weights applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZED training parameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 150\n",
    "\n",
    "print(\"üöÄ Starting training with OPTIMIZED parameters:\\n\")\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  ‚Ä¢ Max epochs: {EPOCHS}\")\n",
    "print(f\"  ‚Ä¢ Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  ‚Ä¢ Early stopping: YES (patience=15)\")\n",
    "print(f\"  ‚Ä¢ LR reduction: YES (patience=7)\")\n",
    "print(f\"  ‚Ä¢ Class weights: YES (balanced)\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Prepare confidence labels (dummy for multi-output compatibility)\n",
    "y_train_confidence = np.max(y_train, axis=1, keepdims=True)\n",
    "y_val_confidence = np.max(y_val, axis=1, keepdims=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {'direction': y_train, 'confidence': y_train_confidence},\n",
    "    validation_data=(\n",
    "        X_val,\n",
    "        {'direction': y_val, 'confidence': y_val_confidence}\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,  # Apply class weights\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 0].plot(history.history['direction_accuracy'], label='Train', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_direction_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0, 0].set_title('Direction Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[0, 1].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0, 1].set_title('Total Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Direction Loss\n",
    "axes[1, 0].plot(history.history['direction_loss'], label='Train', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_direction_loss'], label='Validation', linewidth=2)\n",
    "axes[1, 0].set_title('Direction Loss', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# AUC\n",
    "axes[1, 1].plot(history.history['direction_auc'], label='Train', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_direction_auc'], label='Validation', linewidth=2)\n",
    "axes[1, 1].set_title('Direction AUC', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('AUC')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(model_dir / 'training_history.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Training history plot saved to: {model_dir / 'training_history.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Evaluating model on test set...\\n\")\n",
    "\n",
    "# Prepare test confidence labels\n",
    "y_test_confidence = np.max(y_test, axis=1, keepdims=True)\n",
    "\n",
    "# Evaluate\n",
    "test_results = model.evaluate(\n",
    "    X_test,\n",
    "    {'direction': y_test, 'confidence': y_test_confidence},\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Extract metrics\n",
    "metrics_names = model.metrics_names\n",
    "print(f\"\\nüìä Test Set Results:\")\n",
    "print(\"=\"*50)\n",
    "for name, value in zip(metrics_names, test_results):\n",
    "    if 'direction' in name:\n",
    "        print(f\"  {name:30}: {value:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "y_pred_direction = predictions[0]  # Direction predictions\n",
    "y_pred_classes = np.argmax(y_pred_direction, axis=1)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f\"\\nüìã Classification Report:\")\n",
    "print(\"=\"*50)\n",
    "report = classification_report(\n",
    "    y_test_classes,\n",
    "    y_pred_classes,\n",
    "    target_names=['SELL', 'NEUTRAL', 'BUY'],\n",
    "    digits=4\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=['SELL', 'NEUTRAL', 'BUY'],\n",
    "    yticklabels=['SELL', 'NEUTRAL', 'BUY'],\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.title('Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(model_dir / 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Confusion matrix saved to: {model_dir / 'confusion_matrix.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Final Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate final metrics\n",
    "test_accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "test_precision = precision_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "test_recall = recall_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "test_f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ FINAL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä EUR/USD Week 2 Training Results:\\n\")\n",
    "print(f\"  Test Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"  Test Precision: {test_precision:.4f}\")\n",
    "print(f\"  Test Recall:    {test_recall:.4f}\")\n",
    "print(f\"  Test F1-Score:  {test_f1:.4f}\")\n",
    "\n",
    "# Best validation metrics\n",
    "best_val_acc = max(history.history['val_direction_accuracy'])\n",
    "best_val_auc = max(history.history['val_direction_auc'])\n",
    "print(f\"\\n  Best Val Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\n",
    "print(f\"  Best Val AUC:      {best_val_auc:.4f}\")\n",
    "\n",
    "# Training configuration summary\n",
    "print(f\"\\n‚öôÔ∏è  Configuration Used:\")\n",
    "print(f\"  ‚Ä¢ Sequence Length: {SEQUENCE_LENGTH}\")\n",
    "print(f\"  ‚Ä¢ Features: {len(feature_cols)}\")\n",
    "print(f\"  ‚Ä¢ LSTM Units: {MODEL_CONFIG['lstm_units']}\")\n",
    "print(f\"  ‚Ä¢ Dropout: {MODEL_CONFIG['dropout_rate']}\")\n",
    "print(f\"  ‚Ä¢ Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  ‚Ä¢ Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  ‚Ä¢ Class Weights: Balanced\")\n",
    "\n",
    "print(f\"\\nüíæ Model saved to: {model_dir / 'best_model.keras'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Comparison with previous performance\n",
    "previous_accuracy = 0.3346\n",
    "improvement = ((test_accuracy - previous_accuracy) / previous_accuracy) * 100\n",
    "print(f\"\\nüìà Improvement over Week 1:\")\n",
    "print(f\"  Previous: {previous_accuracy*100:.2f}%\")\n",
    "print(f\"  Current:  {test_accuracy*100:.2f}%\")\n",
    "print(f\"  Change:   {improvement:+.1f}% improvement\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Save Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(str(model_dir / 'training_history.csv'), index=False)\n",
    "\n",
    "# Save configuration\n",
    "config = {\n",
    "    'sequence_length': SEQUENCE_LENGTH,\n",
    "    'horizon': HORIZON,\n",
    "    'threshold': THRESHOLD,\n",
    "    'step': STEP,\n",
    "    'n_features': len(feature_cols),\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'test_precision': float(test_precision),\n",
    "    'test_recall': float(test_recall),\n",
    "    'test_f1': float(test_f1),\n",
    "    'best_val_accuracy': float(best_val_acc),\n",
    "    'model_config': MODEL_CONFIG\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(str(model_dir / 'config.json'), 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Training results saved:\")\n",
    "print(f\"  ‚Ä¢ {model_dir / 'training_history.csv'}\")\n",
    "print(f\"  ‚Ä¢ {model_dir / 'config.json'}\")\n",
    "print(f\"  ‚Ä¢ {model_dir / 'best_model.keras'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "### Key Improvements Made:\n",
    "\n",
    "1. **Increased Model Capacity**\n",
    "   - LSTM units: [256, 128] (from [128, 64])\n",
    "   - Feed-forward dimension: 512 (from 256)\n",
    "\n",
    "2. **Optimized Hyperparameters**\n",
    "   - Sequence length: 120 (from 60) - more temporal context\n",
    "   - Dropout: 0.4 (optimal balance)\n",
    "   - Learning rate: 0.0001 (sweet spot)\n",
    "   - Batch size: 64 (optimal)\n",
    "\n",
    "3. **Better Data Handling**\n",
    "   - Balanced class weights\n",
    "   - Smaller step size for more training data\n",
    "   - Adjusted threshold for label creation\n",
    "\n",
    "4. **Improved Training Process**\n",
    "   - Extended patience for early stopping (15 epochs)\n",
    "   - Learning rate scheduling\n",
    "   - More epochs allowed (150)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "If accuracy is still below target:\n",
    "1. Collect more/better quality data\n",
    "2. Try ensemble methods\n",
    "3. Experiment with different architectures (Bi-LSTM, CNN-LSTM)\n",
    "4. Add more feature engineering\n",
    "5. Consider using transfer learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
