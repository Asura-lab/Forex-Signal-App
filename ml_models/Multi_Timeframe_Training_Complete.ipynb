{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e413dfb9",
   "metadata": {},
   "source": [
    "# ğŸš€ Multi-Timeframe Deep Learning Training System\n",
    "\n",
    "## Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ¸Ğ¹Ğ½ Ñ‚Ğ°Ğ¹Ğ»Ğ±Ğ°Ñ€\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  INPUT: Real-time MT5 data (1M candles)         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  FEATURE ENGINEERING (100+ features)            â”‚\n",
    "â”‚  - Technical indicators (RSI, MACD, BB)         â”‚\n",
    "â”‚  - Price patterns (candlestick, S/R levels)     â”‚\n",
    "â”‚  - Volume profile                               â”‚\n",
    "â”‚  - Market microstructure                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  PARALLEL PREDICTION MODELS:                    â”‚\n",
    "â”‚                                                 â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "â”‚  â”‚ 15-min Model   â”‚ Transformer + LSTM    â”‚    â”‚\n",
    "â”‚  â”‚ Expected: 88%  â”‚ Focus: Quick scalping â”‚    â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "â”‚                                                 â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "â”‚  â”‚ 30-min Model   â”‚ Bi-LSTM + Attention   â”‚    â”‚\n",
    "â”‚  â”‚ Expected: 85%  â”‚ Focus: Swing trades   â”‚    â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "â”‚                                                 â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "â”‚  â”‚ 60-min Model   â”‚ CNN-LSTM Hybrid       â”‚    â”‚\n",
    "â”‚  â”‚ Expected: 82%  â”‚ Focus: Trend followingâ”‚    â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  META-LEARNER (XGBoost)                         â”‚\n",
    "â”‚  - Combines all 3 predictions                   â”‚\n",
    "â”‚  - Learns which model to trust when             â”‚\n",
    "â”‚  - Output: Direction + Confidence + Entry Price â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Ğ—Ğ¾Ñ€Ğ¸Ğ»Ğ³Ğ¾\n",
    "\n",
    "- ğŸ¯ 15-Ğ¼Ğ¸Ğ½ÑƒÑ‚: **88%+ accuracy** (scalping)\n",
    "- ğŸ¯ 30-Ğ¼Ğ¸Ğ½ÑƒÑ‚: **85%+ accuracy** (swing trading)\n",
    "- ğŸ¯ 60-Ğ¼Ğ¸Ğ½ÑƒÑ‚: **82%+ accuracy** (trend following)\n",
    "- ğŸ¯ Ensemble: **90%+ accuracy** with confidence filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34290483",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 1. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add backend to path\n",
    "sys.path.append(str(Path.cwd().parent / 'backend'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks, optimizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Custom modules\n",
    "from ml.features.technical_indicators import calculate_all_features\n",
    "from ml.preprocessing.data_loader import ForexDataLoader\n",
    "from ml.preprocessing.sequence_generator import create_sequences\n",
    "from ml.models.transformer_lstm import build_transformer_lstm_model\n",
    "\n",
    "print(f\"âœ… TensorFlow version: {tf.__version__}\")\n",
    "print(f\"âœ… GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"âœ… Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e4ff6",
   "metadata": {},
   "source": [
    "## âš™ï¸ 2. Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path.cwd().parent / 'data'\n",
    "TRAIN_DIR = DATA_DIR / 'train'\n",
    "TEST_DIR = DATA_DIR / 'test'\n",
    "MODELS_DIR = Path.cwd().parent / 'models'\n",
    "LOGS_DIR = Path.cwd().parent / 'logs'\n",
    "\n",
    "# Create directories\n",
    "for timeframe in ['15min', '30min', '60min', 'ensemble']:\n",
    "    (MODELS_DIR / timeframe).mkdir(parents=True, exist_ok=True)\n",
    "    (LOGS_DIR / timeframe / 'train').mkdir(parents=True, exist_ok=True)\n",
    "    (LOGS_DIR / timeframe / 'validation').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Currency pairs\n",
    "CURRENCY_PAIRS = ['EUR_USD', 'GBP_USD', 'USD_JPY', 'USD_CAD', 'USD_CHF', 'XAU_USD']\n",
    "\n",
    "# Training configuration\n",
    "CONFIG = {\n",
    "    '15min': {\n",
    "        'resample_period': '15T',\n",
    "        'sequence_length': 60,      # 60 * 15min = 15 hours history\n",
    "        'prediction_steps': 1,      # Predict next 15 minutes\n",
    "        'n_heads': 8,\n",
    "        'ff_dim': 256,\n",
    "        'lstm_units': [128, 64],\n",
    "        'dropout': 0.3,\n",
    "        'batch_size': 64,\n",
    "        'epochs': 100,\n",
    "        'learning_rate': 0.001\n",
    "    },\n",
    "    '30min': {\n",
    "        'resample_period': '30T',\n",
    "        'sequence_length': 48,      # 48 * 30min = 24 hours history\n",
    "        'prediction_steps': 1,\n",
    "        'n_heads': 8,\n",
    "        'ff_dim': 256,\n",
    "        'lstm_units': [128, 64],\n",
    "        'dropout': 0.3,\n",
    "        'batch_size': 64,\n",
    "        'epochs': 100,\n",
    "        'learning_rate': 0.001\n",
    "    },\n",
    "    '60min': {\n",
    "        'resample_period': '60T',\n",
    "        'sequence_length': 48,      # 48 * 60min = 48 hours history\n",
    "        'prediction_steps': 1,\n",
    "        'n_heads': 8,\n",
    "        'ff_dim': 256,\n",
    "        'lstm_units': [128, 64],\n",
    "        'dropout': 0.3,\n",
    "        'batch_size': 64,\n",
    "        'epochs': 100,\n",
    "        'learning_rate': 0.001\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… Configuration loaded\")\n",
    "print(f\"ğŸ“ Data directory: {DATA_DIR}\")\n",
    "print(f\"ğŸ’¾ Models directory: {MODELS_DIR}\")\n",
    "print(f\"ğŸ“Š Logs directory: {LOGS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a75e2ad",
   "metadata": {},
   "source": [
    "## ğŸ“¥ 3. Load and Explore Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = ForexDataLoader(data_dir=DATA_DIR)\n",
    "\n",
    "# Load EUR/USD as example\n",
    "pair = 'EUR_USD'\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ“Š Loading {pair} data\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "df_train = loader.load_train_data(pair=pair)\n",
    "df_test = loader.load_test_data(pair=pair)\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Training data shape: {df_train.shape}\")\n",
    "print(f\"ğŸ“‰ Test data shape: {df_test.shape}\")\n",
    "print(f\"\\nğŸ“‹ Columns: {df_train.columns.tolist()}\")\n",
    "print(f\"\\nğŸ” First 5 rows:\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d16ece",
   "metadata": {},
   "source": [
    "## ğŸ”§ 4. Feature Engineering Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_timeframe(df, timeframe_config):\n",
    "    \"\"\"\n",
    "    Prepare data for specific timeframe\n",
    "    \n",
    "    Steps:\n",
    "    1. Resample 1-min data to target timeframe (15min/30min/60min)\n",
    "    2. Calculate 100+ technical indicators\n",
    "    3. Create labels (price direction after N candles)\n",
    "    4. Remove NaN values\n",
    "    5. Normalize features\n",
    "    \n",
    "    Returns:\n",
    "        X: Features\n",
    "        y: Labels (0=SELL, 1=NEUTRAL, 2=BUY)\n",
    "        scaler: Fitted StandardScaler\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ”„ Resampling to {timeframe_config['resample_period']}...\")\n",
    "    \n",
    "    # Resample OHLCV data\n",
    "    df_resampled = df.resample(timeframe_config['resample_period']).agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'tick_volume': 'sum'\n",
    "    }).dropna()\n",
    "    \n",
    "    print(f\"âœ… Resampled shape: {df_resampled.shape}\")\n",
    "    \n",
    "    # Calculate features\n",
    "    print(\"\\nğŸ”§ Calculating technical indicators...\")\n",
    "    df_features = calculate_all_features(df_resampled)\n",
    "    \n",
    "    # Create labels\n",
    "    print(\"\\nğŸ·ï¸  Creating labels...\")\n",
    "    prediction_steps = timeframe_config['prediction_steps']\n",
    "    \n",
    "    # Future price change\n",
    "    df_features['future_return'] = df_features['close'].shift(-prediction_steps) / df_features['close'] - 1\n",
    "    \n",
    "    # Label: -1 (SELL), 0 (NEUTRAL), 1 (BUY)\n",
    "    # Threshold: Â±0.0005 (5 pips for most pairs)\n",
    "    threshold = 0.0005\n",
    "    conditions = [\n",
    "        df_features['future_return'] < -threshold,  # SELL\n",
    "        (df_features['future_return'] >= -threshold) & (df_features['future_return'] <= threshold),  # NEUTRAL\n",
    "        df_features['future_return'] > threshold   # BUY\n",
    "    ]\n",
    "    df_features['label'] = np.select(conditions, [0, 1, 2], default=1)\n",
    "    \n",
    "    # Remove NaN\n",
    "    df_features = df_features.dropna()\n",
    "    \n",
    "    print(f\"âœ… Features calculated: {df_features.shape}\")\n",
    "    print(f\"\\nğŸ“Š Label distribution:\")\n",
    "    print(df_features['label'].value_counts())\n",
    "    print(f\"\\nClass percentages:\")\n",
    "    print(df_features['label'].value_counts(normalize=True) * 100)\n",
    "    \n",
    "    # Separate features and labels\n",
    "    feature_cols = [col for col in df_features.columns \n",
    "                   if col not in ['label', 'future_return', 'open', 'high', 'low', 'close']]\n",
    "    \n",
    "    X = df_features[feature_cols].values\n",
    "    y = df_features['label'].values\n",
    "    \n",
    "    # Normalize features\n",
    "    print(\"\\nğŸ”„ Normalizing features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(f\"âœ… Final shape: X={X_scaled.shape}, y={y.shape}\")\n",
    "    print(f\"âœ… Number of features: {len(feature_cols)}\")\n",
    "    \n",
    "    return X_scaled, y, scaler, feature_cols\n",
    "\n",
    "print(\"âœ… Feature engineering function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d758e2",
   "metadata": {},
   "source": [
    "## ğŸ”„ 5. Create Sequences Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2030d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_for_training(X, y, sequence_length):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM/Transformer input\n",
    "    \n",
    "    Args:\n",
    "        X: Features (n_samples, n_features)\n",
    "        y: Labels (n_samples,)\n",
    "        sequence_length: Number of timesteps per sequence\n",
    "        \n",
    "    Returns:\n",
    "        X_seq: (n_sequences, sequence_length, n_features)\n",
    "        y_seq: (n_sequences,)\n",
    "    \"\"\"\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    \n",
    "    for i in range(sequence_length, len(X)):\n",
    "        X_seq.append(X[i-sequence_length:i])\n",
    "        y_seq.append(y[i])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "print(\"âœ… Sequence creation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee9391",
   "metadata": {},
   "source": [
    "## ğŸ‹ï¸ 6. Training Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b5e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_for_timeframe(timeframe, pair='EUR_USD'):\n",
    "    \"\"\"\n",
    "    Train model for specific timeframe\n",
    "    \n",
    "    Args:\n",
    "        timeframe: '15min', '30min', or '60min'\n",
    "        pair: Currency pair name\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained Keras model\n",
    "        history: Training history\n",
    "        test_metrics: Test set performance\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸš€ TRAINING {timeframe.upper()} MODEL FOR {pair}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    config = CONFIG[timeframe]\n",
    "    \n",
    "    # Load data\n",
    "    print(\"ğŸ“¥ Loading data...\")\n",
    "    loader = ForexDataLoader(data_dir=DATA_DIR)\n",
    "    df_train = loader.load_train_data(pair=pair)\n",
    "    df_test = loader.load_test_data(pair=pair)\n",
    "    \n",
    "    # Prepare training data\n",
    "    print(\"\\nğŸ”§ Preparing training data...\")\n",
    "    X_train, y_train, scaler_train, feature_cols = prepare_data_for_timeframe(df_train, config)\n",
    "    \n",
    "    # Prepare test data\n",
    "    print(\"\\nğŸ”§ Preparing test data...\")\n",
    "    X_test, y_test, scaler_test, _ = prepare_data_for_timeframe(df_test, config)\n",
    "    \n",
    "    # Use training scaler for test data\n",
    "    X_test = scaler_train.transform(X_test)\n",
    "    \n",
    "    # Create sequences\n",
    "    print(f\"\\nğŸ”„ Creating sequences (length={config['sequence_length']})...\")\n",
    "    X_train_seq, y_train_seq = create_sequences_for_training(X_train, y_train, config['sequence_length'])\n",
    "    X_test_seq, y_test_seq = create_sequences_for_training(X_test, y_test, config['sequence_length'])\n",
    "    \n",
    "    print(f\"âœ… Training sequences: {X_train_seq.shape}\")\n",
    "    print(f\"âœ… Test sequences: {X_test_seq.shape}\")\n",
    "    \n",
    "    # Split validation set\n",
    "    X_train_seq, X_val_seq, y_train_seq, y_val_seq = train_test_split(\n",
    "        X_train_seq, y_train_seq, test_size=0.2, random_state=42, stratify=y_train_seq\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Final splits:\")\n",
    "    print(f\"   Train: {X_train_seq.shape}\")\n",
    "    print(f\"   Val:   {X_val_seq.shape}\")\n",
    "    print(f\"   Test:  {X_test_seq.shape}\")\n",
    "    \n",
    "    # Build model\n",
    "    print(f\"\\nğŸ—ï¸  Building model...\")\n",
    "    n_features = X_train_seq.shape[2]\n",
    "    \n",
    "    model = build_transformer_lstm_model(\n",
    "        sequence_length=config['sequence_length'],\n",
    "        n_features=n_features,\n",
    "        n_heads=config['n_heads'],\n",
    "        ff_dim=config['ff_dim'],\n",
    "        lstm_units=config['lstm_units'],\n",
    "        dropout_rate=config['dropout'],\n",
    "        n_classes=3  # BUY/NEUTRAL/SELL\n",
    "    )\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=config['learning_rate']),\n",
    "        loss={\n",
    "            'direction': 'sparse_categorical_crossentropy',\n",
    "            'confidence': 'mse'\n",
    "        },\n",
    "        loss_weights={'direction': 1.0, 'confidence': 0.5},\n",
    "        metrics={\n",
    "            'direction': ['accuracy'],\n",
    "            'confidence': ['mae']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    # Callbacks\n",
    "    model_path = MODELS_DIR / timeframe / f\"{pair}_{timeframe}_best.keras\"\n",
    "    log_dir = LOGS_DIR / timeframe / 'train' / datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    callbacks_list = [\n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath=str(model_path),\n",
    "            monitor='val_direction_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor='val_direction_accuracy',\n",
    "            patience=15,\n",
    "            mode='max',\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.TensorBoard(\n",
    "            log_dir=str(log_dir),\n",
    "            histogram_freq=1,\n",
    "            write_graph=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nğŸ‹ï¸ Training model...\")\n",
    "    print(f\"ğŸ“Š Batch size: {config['batch_size']}\")\n",
    "    print(f\"ğŸ“Š Epochs: {config['epochs']}\")\n",
    "    print(f\"ğŸ“Š Learning rate: {config['learning_rate']}\")\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train_seq,\n",
    "        {\n",
    "            'direction': y_train_seq,\n",
    "            'confidence': np.ones_like(y_train_seq, dtype=float)  # Placeholder\n",
    "        },\n",
    "        validation_data=(\n",
    "            X_val_seq,\n",
    "            {\n",
    "                'direction': y_val_seq,\n",
    "                'confidence': np.ones_like(y_val_seq, dtype=float)\n",
    "            }\n",
    "        ),\n",
    "        batch_size=config['batch_size'],\n",
    "        epochs=config['epochs'],\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(f\"\\nğŸ“Š Evaluating on test set...\")\n",
    "    test_results = model.evaluate(\n",
    "        X_test_seq,\n",
    "        {\n",
    "            'direction': y_test_seq,\n",
    "            'confidence': np.ones_like(y_test_seq, dtype=float)\n",
    "        },\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test_seq)\n",
    "    y_pred = np.argmax(predictions[0], axis=1)\n",
    "    \n",
    "    # Calculate accuracy per class\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"ğŸ“ˆ TEST SET RESULTS FOR {timeframe.upper()}\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_seq, y_pred, target_names=['SELL', 'NEUTRAL', 'BUY']))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test_seq, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    # Save scaler and metadata\n",
    "    scaler_path = MODELS_DIR / timeframe / f\"{pair}_{timeframe}_scaler.pkl\"\n",
    "    joblib.dump(scaler_train, scaler_path)\n",
    "    \n",
    "    metadata = {\n",
    "        'timeframe': timeframe,\n",
    "        'pair': pair,\n",
    "        'n_features': n_features,\n",
    "        'sequence_length': config['sequence_length'],\n",
    "        'feature_columns': feature_cols,\n",
    "        'train_samples': len(X_train_seq),\n",
    "        'test_accuracy': float(np.mean(y_pred == y_test_seq)),\n",
    "        'training_date': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    metadata_path = MODELS_DIR / timeframe / f\"{pair}_{timeframe}_metadata.json\"\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ Model saved: {model_path}\")\n",
    "    print(f\"ğŸ’¾ Scaler saved: {scaler_path}\")\n",
    "    print(f\"ğŸ’¾ Metadata saved: {metadata_path}\")\n",
    "    \n",
    "    return model, history, test_results\n",
    "\n",
    "print(\"âœ… Training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafa05d2",
   "metadata": {},
   "source": [
    "## ğŸš€ 7. Train All Models\n",
    "\n",
    "ĞĞ´Ğ¾Ğ¾ 3 Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ‹Ğ³ Ğ·ÑÑ€ÑĞ³ ÑÑƒÑ€Ğ³Ğ°Ğ½Ğ°:\n",
    "\n",
    "- 15-Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğ½ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (scalping)\n",
    "- 30-Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğ½ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (swing trading)\n",
    "- 60-Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğ½ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (trend following)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf8a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train EUR/USD for all timeframes\n",
    "pair = 'EUR_USD'\n",
    "results = {}\n",
    "\n",
    "for timeframe in ['15min', '30min', '60min']:\n",
    "    try:\n",
    "        model, history, test_results = train_model_for_timeframe(timeframe, pair=pair)\n",
    "        results[timeframe] = {\n",
    "            'model': model,\n",
    "            'history': history,\n",
    "            'test_results': test_results\n",
    "        }\n",
    "        print(f\"\\nâœ… {timeframe} training completed!\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error training {timeframe}: {str(e)}\\n\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ‰ ALL MODELS TRAINING COMPLETED!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75da83",
   "metadata": {},
   "source": [
    "## ğŸ“Š 8. Visualize Training Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb14990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for all models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Training History - All Timeframes', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (timeframe, result) in enumerate(results.items()):\n",
    "    if 'history' not in result:\n",
    "        continue\n",
    "        \n",
    "    history = result['history']\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax1 = axes[0, idx]\n",
    "    ax1.plot(history.history['direction_accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(history.history['val_direction_accuracy'], label='Val Accuracy')\n",
    "    ax1.set_title(f'{timeframe} - Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss plot\n",
    "    ax2 = axes[1, idx]\n",
    "    ax2.plot(history.history['loss'], label='Train Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Val Loss')\n",
    "    ax2.set_title(f'{timeframe} - Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODELS_DIR / 'training_results_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Training plots saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8499ee",
   "metadata": {},
   "source": [
    "## ğŸ¯ 9. Test All Models on Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a96935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_performance(timeframe, pair='EUR_USD'):\n",
    "    \"\"\"\n",
    "    Load trained model and test on test dataset\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ§ª TESTING {timeframe.upper()} MODEL ON {pair}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Load model and scaler\n",
    "    model_path = MODELS_DIR / timeframe / f\"{pair}_{timeframe}_best.keras\"\n",
    "    scaler_path = MODELS_DIR / timeframe / f\"{pair}_{timeframe}_scaler.pkl\"\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"âŒ Model not found: {model_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ğŸ“¥ Loading model from {model_path}\")\n",
    "    model = keras.models.load_model(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    # Load test data\n",
    "    loader = ForexDataLoader(data_dir=DATA_DIR)\n",
    "    df_test = loader.load_test_data(pair=pair)\n",
    "    \n",
    "    config = CONFIG[timeframe]\n",
    "    \n",
    "    # Prepare test data\n",
    "    X_test, y_test, _, _ = prepare_data_for_timeframe(df_test, config)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Create sequences\n",
    "    X_test_seq, y_test_seq = create_sequences_for_training(X_test, y_test, config['sequence_length'])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Test data shape: {X_test_seq.shape}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test_seq, verbose=1)\n",
    "    y_pred = np.argmax(predictions[0], axis=1)\n",
    "    y_confidence = predictions[1].flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_seq, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test_seq, y_pred, average='weighted')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"ğŸ“ˆ TEST RESULTS FOR {timeframe.upper()}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nğŸ¯ Overall Accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"ğŸ¯ Precision: {precision*100:.2f}%\")\n",
    "    print(f\"ğŸ¯ Recall: {recall*100:.2f}%\")\n",
    "    print(f\"ğŸ¯ F1-Score: {f1*100:.2f}%\")\n",
    "    \n",
    "    print(\"\\nğŸ“Š Classification Report:\")\n",
    "    print(classification_report(y_test_seq, y_pred, target_names=['SELL', 'NEUTRAL', 'BUY']))\n",
    "    \n",
    "    # High confidence predictions\n",
    "    high_conf_mask = y_confidence > 0.85\n",
    "    if high_conf_mask.sum() > 0:\n",
    "        high_conf_accuracy = accuracy_score(y_test_seq[high_conf_mask], y_pred[high_conf_mask])\n",
    "        print(f\"\\nâœ¨ High Confidence (>85%) Accuracy: {high_conf_accuracy*100:.2f}%\")\n",
    "        print(f\"   Number of high confidence predictions: {high_conf_mask.sum()} ({high_conf_mask.sum()/len(y_pred)*100:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'predictions': y_pred,\n",
    "        'confidence': y_confidence,\n",
    "        'true_labels': y_test_seq\n",
    "    }\n",
    "\n",
    "# Test all models\n",
    "test_results = {}\n",
    "for timeframe in ['15min', '30min', '60min']:\n",
    "    test_results[timeframe] = test_model_performance(timeframe, pair=pair)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ‰ ALL MODELS TESTED!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d69d42",
   "metadata": {},
   "source": [
    "## ğŸ“Š 10. Compare Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_data = []\n",
    "for timeframe, result in test_results.items():\n",
    "    if result is not None:\n",
    "        comparison_data.append({\n",
    "            'Timeframe': timeframe,\n",
    "            'Accuracy (%)': f\"{result['accuracy']*100:.2f}\",\n",
    "            'Precision (%)': f\"{result['precision']*100:.2f}\",\n",
    "            'Recall (%)': f\"{result['recall']*100:.2f}\",\n",
    "            'F1-Score (%)': f\"{result['f1']*100:.2f}\"\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv(MODELS_DIR / 'model_comparison.csv', index=False)\n",
    "print(f\"\\nğŸ’¾ Comparison saved to {MODELS_DIR / 'model_comparison.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535985f",
   "metadata": {},
   "source": [
    "## ğŸ¯ 11. Ensemble Prediction Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4875ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(sample_idx=0):\n",
    "    \"\"\"\n",
    "    Example: Combine predictions from all 3 models\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ¯ ENSEMBLE PREDICTION EXAMPLE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    for timeframe in ['15min', '30min', '60min']:\n",
    "        result = test_results[timeframe]\n",
    "        if result is not None:\n",
    "            pred = result['predictions'][sample_idx]\n",
    "            conf = result['confidence'][sample_idx]\n",
    "            true_label = result['true_labels'][sample_idx]\n",
    "            \n",
    "            predictions[timeframe] = {\n",
    "                'prediction': ['SELL', 'NEUTRAL', 'BUY'][pred],\n",
    "                'confidence': conf,\n",
    "                'true_label': ['SELL', 'NEUTRAL', 'BUY'][true_label]\n",
    "            }\n",
    "    \n",
    "    print(f\"\\nSample #{sample_idx}:\")\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    for timeframe, pred in predictions.items():\n",
    "        print(f\"{timeframe:8s} | Prediction: {pred['prediction']:7s} | Confidence: {pred['confidence']:.3f} | True: {pred['true_label']}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Simple voting\n",
    "    votes = [pred['prediction'] for pred in predictions.values()]\n",
    "    from collections import Counter\n",
    "    vote_count = Counter(votes)\n",
    "    ensemble_prediction = vote_count.most_common(1)[0][0]\n",
    "    \n",
    "    print(f\"\\nğŸ—³ï¸  Ensemble Vote: {ensemble_prediction}\")\n",
    "    print(f\"ğŸ“Š Vote breakdown: {dict(vote_count)}\")\n",
    "    \n",
    "    return predictions, ensemble_prediction\n",
    "\n",
    "# Test ensemble on first 10 samples\n",
    "print(\"\\nğŸ§ª Testing ensemble on 10 samples...\\n\")\n",
    "for i in range(min(10, len(test_results['15min']['predictions']))):\n",
    "    ensemble_predict(sample_idx=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235da74",
   "metadata": {},
   "source": [
    "## ğŸ’¡ 12. Next Steps\n",
    "\n",
    "### âœ… Completed:\n",
    "\n",
    "- [x] Data loading and preprocessing\n",
    "- [x] Feature engineering (100+ indicators)\n",
    "- [x] Multi-timeframe model training\n",
    "- [x] Model evaluation on test data\n",
    "- [x] Basic ensemble voting\n",
    "\n",
    "### ğŸ”œ To Implement:\n",
    "\n",
    "1. **Meta-Learner (XGBoost)**\n",
    "\n",
    "   - Train ensemble model on predictions from 3 models\n",
    "   - Learn when to trust which model\n",
    "\n",
    "2. **Confidence Filtering**\n",
    "\n",
    "   - Filter signals by confidence threshold (>85%)\n",
    "   - Multi-timeframe alignment check\n",
    "\n",
    "3. **Risk Management**\n",
    "\n",
    "   - Calculate entry price, take profit, stop loss\n",
    "   - Expected time to target\n",
    "\n",
    "4. **Production Integration**\n",
    "\n",
    "   - Flask API endpoints\n",
    "   - Real-time prediction from MT5\n",
    "   - Mobile app integration\n",
    "\n",
    "5. **Monitoring**\n",
    "   - TensorBoard logs\n",
    "   - Performance tracking\n",
    "   - Retraining triggers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68595c20",
   "metadata": {},
   "source": [
    "## ğŸ‰ Summary\n",
    "\n",
    "Ğ­Ğ½Ñ notebook-Ğ´ Ğ±Ğ¸Ğ´:\n",
    "\n",
    "1. âœ… **Data/train folder**-Ğ¾Ğ¾Ñ 1-Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğ½ Ğ´Ğ°Ñ‚Ğ°Ğ³ ÑƒĞ½ÑˆÑĞ°Ğ½\n",
    "2. âœ… 15-Ğ¼Ğ¸Ğ½, 30-Ğ¼Ğ¸Ğ½, 60-Ğ¼Ğ¸Ğ½ **timeframe Ñ€ÑƒÑƒ resample** Ñ…Ğ¸Ğ¹ÑÑĞ½\n",
    "3. âœ… **100+ Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸Ğ¹Ğ½ Ò¯Ğ·Ò¯Ò¯Ğ»ÑĞ»Ñ‚** Ñ‚Ğ¾Ğ¾Ñ†ÑĞ¾Ğ½\n",
    "4. âœ… **Label Ò¯Ò¯ÑĞ³ÑÑÑĞ½** (BUY/NEUTRAL/SELL)\n",
    "5. âœ… **Transformer + LSTM Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ** Ğ±Ò¯Ñ‚ÑÑĞ¶, ÑÑƒÑ€Ğ³Ğ°ÑĞ°Ğ½\n",
    "6. âœ… **Data/test folder**-Ñ‹Ğ½ Ğ´Ğ°Ñ‚Ğ°Ğ°Ñ€ ÑˆĞ°Ğ»Ğ³Ğ°ÑĞ°Ğ½\n",
    "7. âœ… **Ğ“ÑƒÑ€Ğ²Ğ°Ğ½ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ** Ğ·ÑÑ€ÑĞ³ ÑÑƒÑ€Ğ³Ğ°ÑĞ°Ğ½\n",
    "8. âœ… **Ensemble voting** ÑĞ¸ÑÑ‚ĞµĞ¼ Ò¯Ò¯ÑĞ³ÑÑÑĞ½\n",
    "9. âœ… **Ò®Ñ€ Ğ´Ò¯Ğ½Ğ³ Ñ…Ğ°Ñ€ÑŒÑ†ÑƒÑƒĞ»ÑĞ°Ğ½**\n",
    "\n",
    "### Ğ”Ğ°Ñ€Ğ°Ğ°Ğ³Ğ¸Ğ¹Ğ½ Ğ°Ğ»Ñ…Ğ°Ğ¼:\n",
    "\n",
    "- Ğ‘ÑƒÑĞ°Ğ´ Ğ²Ğ°Ğ»ÑÑ‚Ñ‹Ğ½ Ñ…Ğ¾ÑĞ»Ğ¾Ğ» Ğ´ÑÑÑ€ ÑÑƒÑ€Ğ³Ğ°Ñ… (GBP/USD, USD/JPY, Ğ³ÑÑ… Ğ¼ÑÑ‚)\n",
    "- Meta-learner (XGBoost) ÑÑƒÑ€Ğ³Ğ°Ñ…\n",
    "- Flask API Ğ´ÑÑÑ€ deploy Ñ…Ğ¸Ğ¹Ñ…\n",
    "- Mobile app-Ñ‚ÑĞ¹ Ñ…Ğ¾Ğ»Ğ±Ğ¾Ñ…\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
