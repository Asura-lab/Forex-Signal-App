{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d038c3",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Install & Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6a3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install RL framework (uncomment if needed)\n",
    "# !pip install stable-baselines3 gymnasium pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77763c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 03:41:40.619318: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763437300.642368     172 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763437300.649565     172 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported\n",
      "   Gymnasium: 0.29.0\n",
      "   PyTorch: 2.6.0+cu124\n",
      "   CUDA available: True\n",
      "ðŸ“… Date: 2025-11-18 03:41:43\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# RL Framework\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(\"âœ… Libraries imported\")\n",
    "print(f\"   Gymnasium: {gym.__version__}\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"ðŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33752c4",
   "metadata": {},
   "source": [
    "## ðŸ“Š Load Kaggle EUR/USD Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b2ff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading EUR/USD data from Kaggle...\n",
      "\n",
      "âœ… Data loaded successfully!\n",
      "   Shape: (1859492, 6)\n",
      "   Date range: 2019-12-31 16:00:00+00:00 â†’ 2024-12-30 16:00:00+00:00\n",
      "   Duration: 1826 days\n",
      "   Total bars: 1,859,492\n",
      "\n",
      "ðŸ“Š Sample:\n",
      "                       time     open     high      low    close  volume\n",
      "0 2019-12-31 16:00:00+00:00  1.12237  1.12287  1.12225  1.12279  697.06\n",
      "1 2019-12-31 16:01:00+00:00  1.12277  1.12278  1.12226  1.12231  442.42\n",
      "2 2019-12-31 16:02:00+00:00  1.12231  1.12249  1.12222  1.12236  382.16\n",
      "3 2019-12-31 16:03:00+00:00  1.12235  1.12248  1.12222  1.12225  242.60\n",
      "4 2019-12-31 16:04:00+00:00  1.12225  1.12225  1.12200  1.12209  281.48\n",
      "\n",
      "âœ… Data loaded successfully!\n",
      "   Shape: (1859492, 6)\n",
      "   Date range: 2019-12-31 16:00:00+00:00 â†’ 2024-12-30 16:00:00+00:00\n",
      "   Duration: 1826 days\n",
      "   Total bars: 1,859,492\n",
      "\n",
      "ðŸ“Š Sample:\n",
      "                       time     open     high      low    close  volume\n",
      "0 2019-12-31 16:00:00+00:00  1.12237  1.12287  1.12225  1.12279  697.06\n",
      "1 2019-12-31 16:01:00+00:00  1.12277  1.12278  1.12226  1.12231  442.42\n",
      "2 2019-12-31 16:02:00+00:00  1.12231  1.12249  1.12222  1.12236  382.16\n",
      "3 2019-12-31 16:03:00+00:00  1.12235  1.12248  1.12222  1.12225  242.60\n",
      "4 2019-12-31 16:04:00+00:00  1.12225  1.12225  1.12200  1.12209  281.48\n"
     ]
    }
   ],
   "source": [
    "# Load EUR/USD data from Kaggle\n",
    "import os\n",
    "\n",
    "print(\"ðŸ“‚ Loading EUR/USD data from Kaggle...\")\n",
    "\n",
    "# Kaggle path\n",
    "dataset_path = '/kaggle/input/dataset/EUR_USD_1min.csv'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(\"\\nâŒ ERROR: Kaggle dataset not attached!\")\n",
    "    print(\"\\nðŸ“ To fix:\")\n",
    "    print(\"   1. Click 'Add Data' in Kaggle\")\n",
    "    print(\"   2. Search: 'asurajims/dataset'\")\n",
    "    print(\"   3. Click 'Add'\")\n",
    "    print(\"   4. Re-run this cell\")\n",
    "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Rename columns if needed\n",
    "if 'timestamp' in df.columns:\n",
    "    df = df.rename(columns={'timestamp': 'time'})\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nâœ… Data loaded successfully!\")\n",
    "print(f\"   Shape: {df.shape}\")\n",
    "print(f\"   Date range: {df['time'].min()} â†’ {df['time'].max()}\")\n",
    "print(f\"   Duration: {(df['time'].max() - df['time'].min()).days} days\")\n",
    "print(f\"   Total bars: {len(df):,}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Sample:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266ad482",
   "metadata": {},
   "source": [
    "## ðŸ”§ Feature Engineering (Technical Indicators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e538d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Adding technical indicators...\n",
      "   âœ… 15 indicators added\n",
      "\n",
      "ðŸ“Š Data with indicators: (1859492, 21)\n",
      "   âœ… 15 indicators added\n",
      "\n",
      "ðŸ“Š Data with indicators: (1859492, 21)\n"
     ]
    }
   ],
   "source": [
    "def add_technical_indicators(df):\n",
    "    \"\"\"\n",
    "    Add technical indicators for RL agent state\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”§ Adding technical indicators...\")\n",
    "    \n",
    "    data = df.copy()\n",
    "    \n",
    "    # Price features\n",
    "    data['returns'] = data['close'].pct_change()\n",
    "    data['log_returns'] = np.log(data['close'] / data['close'].shift(1))\n",
    "    \n",
    "    # RSI\n",
    "    delta = data['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    data['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD\n",
    "    ema12 = data['close'].ewm(span=12).mean()\n",
    "    ema26 = data['close'].ewm(span=26).mean()\n",
    "    data['macd'] = ema12 - ema26\n",
    "    data['macd_signal'] = data['macd'].ewm(span=9).mean()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    data['bb_middle'] = data['close'].rolling(window=20).mean()\n",
    "    bb_std = data['close'].rolling(window=20).std()\n",
    "    data['bb_upper'] = data['bb_middle'] + (bb_std * 2)\n",
    "    data['bb_lower'] = data['bb_middle'] - (bb_std * 2)\n",
    "    data['bb_position'] = (data['close'] - data['bb_lower']) / (data['bb_upper'] - data['bb_lower'])\n",
    "    \n",
    "    # ATR\n",
    "    high_low = data['high'] - data['low']\n",
    "    high_close = np.abs(data['high'] - data['close'].shift())\n",
    "    low_close = np.abs(data['low'] - data['close'].shift())\n",
    "    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    data['atr'] = true_range.rolling(window=14).mean()\n",
    "    \n",
    "    # EMAs\n",
    "    data['ema_9'] = data['close'].ewm(span=9).mean()\n",
    "    data['ema_21'] = data['close'].ewm(span=21).mean()\n",
    "    data['ema_50'] = data['close'].ewm(span=50).mean()\n",
    "    \n",
    "    # Volatility\n",
    "    data['volatility'] = data['returns'].rolling(window=20).std()\n",
    "    \n",
    "    # Volume ratio\n",
    "    data['volume_ratio'] = data['volume'] / data['volume'].rolling(window=20).mean()\n",
    "    \n",
    "    # Handle NaN\n",
    "    data = data.fillna(method='bfill').fillna(0)\n",
    "    \n",
    "    print(f\"   âœ… {len(data.columns) - len(df.columns)} indicators added\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Add indicators\n",
    "df_features = add_technical_indicators(df)\n",
    "\n",
    "print(f\"\\nðŸ“Š Data with indicators: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa68eb",
   "metadata": {},
   "source": [
    "## ðŸŽ® Forex Trading Environment (Gymnasium)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98253e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ForexTradingEnv defined\n",
      "   State: Lookback features + Portfolio state\n",
      "   Actions: HOLD, BUY, SELL, CLOSE\n",
      "   Reward: Realized PnL - costs\n"
     ]
    }
   ],
   "source": [
    "class ForexTradingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Forex Trading Environment for Reinforcement Learning\n",
    "    \n",
    "    State: Technical indicators + Portfolio state\n",
    "    Actions: 0=HOLD, 1=BUY, 2=SELL, 3=CLOSE\n",
    "    Reward: Realized PnL - costs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, initial_balance=10000, commission=0.0002, \n",
    "                 max_position=1.0, lookback=60):\n",
    "        super(ForexTradingEnv, self).__init__()\n",
    "        \n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.initial_balance = initial_balance\n",
    "        self.commission = commission  # 2 pips\n",
    "        self.max_position = max_position\n",
    "        self.lookback = lookback\n",
    "        \n",
    "        # Feature columns (excluding time, OHLCV)\n",
    "        self.feature_cols = [col for col in df.columns \n",
    "                             if col not in ['time', 'open', 'high', 'low', 'close', 'volume']]\n",
    "        \n",
    "        # State: lookback Ã— features + portfolio state (5)\n",
    "        state_size = lookback * len(self.feature_cols) + 5\n",
    "        \n",
    "        # Define spaces\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(state_size,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Actions: 0=HOLD, 1=BUY, 2=SELL, 3=CLOSE\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        # Reset episode\n",
    "        self.current_step = self.lookback\n",
    "        self.balance = self.initial_balance\n",
    "        self.position = 0  # -1=SHORT, 0=FLAT, 1=LONG\n",
    "        self.entry_price = 0\n",
    "        self.trades = []\n",
    "        self.equity_curve = [self.initial_balance]\n",
    "        \n",
    "        return self._get_observation(), {}\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        State = [lookback features] + [portfolio state]\n",
    "        \"\"\"\n",
    "        # Get lookback window of features\n",
    "        start = self.current_step - self.lookback\n",
    "        end = self.current_step\n",
    "        \n",
    "        features = self.df[self.feature_cols].iloc[start:end].values\n",
    "        features_flat = features.flatten()\n",
    "        \n",
    "        # Portfolio state\n",
    "        current_price = self.df['close'].iloc[self.current_step]\n",
    "        \n",
    "        portfolio_state = np.array([\n",
    "            self.balance / self.initial_balance,  # Normalized balance\n",
    "            self.position,  # -1, 0, 1\n",
    "            (current_price - self.entry_price) / current_price if self.position != 0 else 0,  # Unrealized PnL %\n",
    "            len(self.trades) / 100,  # Trade count (normalized)\n",
    "            (self.balance + self._get_unrealized_pnl()) / self.initial_balance  # Total equity\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Concatenate\n",
    "        state = np.concatenate([features_flat, portfolio_state])\n",
    "        \n",
    "        return state.astype(np.float32)\n",
    "    \n",
    "    def _get_unrealized_pnl(self):\n",
    "        \"\"\"Calculate unrealized PnL for open position\"\"\"\n",
    "        if self.position == 0:\n",
    "            return 0\n",
    "        \n",
    "        current_price = self.df['close'].iloc[self.current_step]\n",
    "        price_diff = (current_price - self.entry_price) * self.position\n",
    "        \n",
    "        # Convert to USD (assuming 1 lot = $100,000)\n",
    "        pnl = price_diff * 100000\n",
    "        \n",
    "        return pnl\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Execute action and return (state, reward, done, truncated, info)\n",
    "        \"\"\"\n",
    "        current_price = self.df['close'].iloc[self.current_step]\n",
    "        reward = 0\n",
    "        \n",
    "        # Execute action\n",
    "        if action == 1 and self.position == 0:  # BUY\n",
    "            self.position = 1\n",
    "            self.entry_price = current_price\n",
    "            reward -= self.commission  # Trading cost\n",
    "            \n",
    "        elif action == 2 and self.position == 0:  # SELL\n",
    "            self.position = -1\n",
    "            self.entry_price = current_price\n",
    "            reward -= self.commission\n",
    "            \n",
    "        elif action == 3 and self.position != 0:  # CLOSE\n",
    "            # Realize PnL\n",
    "            pnl = self._get_unrealized_pnl()\n",
    "            self.balance += pnl\n",
    "            \n",
    "            # Record trade\n",
    "            self.trades.append({\n",
    "                'entry': self.entry_price,\n",
    "                'exit': current_price,\n",
    "                'pnl': pnl,\n",
    "                'type': 'LONG' if self.position == 1 else 'SHORT'\n",
    "            })\n",
    "            \n",
    "            # Reward = PnL - commission\n",
    "            reward = pnl / self.initial_balance - self.commission\n",
    "            \n",
    "            # Reset position\n",
    "            self.position = 0\n",
    "            self.entry_price = 0\n",
    "        \n",
    "        # Small penalty for holding position too long\n",
    "        if self.position != 0:\n",
    "            reward -= 0.00001\n",
    "        \n",
    "        # Move to next step\n",
    "        self.current_step += 1\n",
    "        \n",
    "        # Update equity curve\n",
    "        total_equity = self.balance + self._get_unrealized_pnl()\n",
    "        self.equity_curve.append(total_equity)\n",
    "        \n",
    "        # Check if done\n",
    "        done = self.current_step >= len(self.df) - 1\n",
    "        truncated = False\n",
    "        \n",
    "        # Info\n",
    "        info = {\n",
    "            'balance': self.balance,\n",
    "            'position': self.position,\n",
    "            'total_equity': total_equity,\n",
    "            'trades_count': len(self.trades)\n",
    "        }\n",
    "        \n",
    "        return self._get_observation(), reward, done, truncated, info\n",
    "\n",
    "\n",
    "print(\"âœ… ForexTradingEnv defined\")\n",
    "print(\"   State: Lookback features + Portfolio state\")\n",
    "print(\"   Actions: HOLD, BUY, SELL, CLOSE\")\n",
    "print(\"   Reward: Realized PnL - costs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333eee3",
   "metadata": {},
   "source": [
    "## ðŸ§ª Test Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbfd7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing environment with random actions...\n",
      "\n",
      "ðŸ“Š Initial state shape: (905,)\n",
      "   Action space: Discrete(4)\n",
      "   Observation space: (905,)\n",
      "\n",
      "âœ… Environment test complete:\n",
      "   Steps: 100\n",
      "   Total reward: -0.0077\n",
      "   Final balance: $10008.00\n",
      "   Trades: 19\n"
     ]
    }
   ],
   "source": [
    "# Test environment with random actions\n",
    "print(\"ðŸ§ª Testing environment with random actions...\")\n",
    "\n",
    "# Use first 10,000 bars for testing\n",
    "test_df = df_features.iloc[:10000].copy()\n",
    "\n",
    "env = ForexTradingEnv(test_df, initial_balance=10000)\n",
    "\n",
    "state, info = env.reset()\n",
    "print(f\"\\nðŸ“Š Initial state shape: {state.shape}\")\n",
    "print(f\"   Action space: {env.action_space}\")\n",
    "print(f\"   Observation space: {env.observation_space.shape}\")\n",
    "\n",
    "# Run 100 random steps\n",
    "total_reward = 0\n",
    "for i in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(f\"\\nâœ… Environment test complete:\")\n",
    "print(f\"   Steps: {i+1}\")\n",
    "print(f\"   Total reward: {total_reward:.4f}\")\n",
    "print(f\"   Final balance: ${info['balance']:.2f}\")\n",
    "print(f\"   Trades: {info['trades_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397875c5",
   "metadata": {},
   "source": [
    "## ðŸ¤– Train DQN Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca8e951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Data split:\n",
      "   Train: 1,487,593 bars\n",
      "   Test:  371,899 bars\n",
      "\n",
      "âœ… Training environment ready\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data (80% of data)\n",
    "train_size = int(len(df_features) * 0.8)\n",
    "train_df = df_features.iloc[:train_size].copy()\n",
    "test_df = df_features.iloc[train_size:].copy()\n",
    "\n",
    "print(f\"ðŸ“Š Data split:\")\n",
    "print(f\"   Train: {len(train_df):,} bars\")\n",
    "print(f\"   Test:  {len(test_df):,} bars\")\n",
    "\n",
    "# Create training environment\n",
    "train_env = ForexTradingEnv(train_df, initial_balance=10000)\n",
    "\n",
    "print(f\"\\nâœ… Training environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b75dc652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training callback configured\n"
     ]
    }
   ],
   "source": [
    "# Training callback for logging\n",
    "class TradingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq=1000, verbose=1):\n",
    "        super(TradingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.episode_rewards = []\n",
    "        \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            print(f\"   Step: {self.n_calls:,} | Episodes: {self.num_timesteps // 1000}\")\n",
    "        return True\n",
    "\n",
    "callback = TradingCallback(check_freq=5000)\n",
    "\n",
    "print(\"âœ… Training callback configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training DQN agent...\n",
      "   This may take 1-2 hours depending on hardware\n",
      "   Algorithm: Deep Q-Network (DQN)\n",
      "   Total timesteps: 100,000\n",
      "\n",
      "============================================================\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/forex_dqn/DQN_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24aa902a5e77442f8e5d5ef9ac6475db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Step: 5,000 | Episodes: 5\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Step: 5,000 | Episodes: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Step: 10,000 | Episodes: 10\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Step: 10,000 | Episodes: 10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Step: 15,000 | Episodes: 15\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Step: 15,000 | Episodes: 15\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Step: 20,000 | Episodes: 20\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Step: 20,000 | Episodes: 20\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Step: 25,000 | Episodes: 25\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Step: 25,000 | Episodes: 25\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Step: 30,000 | Episodes: 30\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Step: 30,000 | Episodes: 30\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Step: 35,000 | Episodes: 35\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Step: 35,000 | Episodes: 35\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Step: 40,000 | Episodes: 40\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Step: 40,000 | Episodes: 40\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Step: 45,000 | Episodes: 45\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Step: 45,000 | Episodes: 45\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Step: 50,000 | Episodes: 50\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Step: 50,000 | Episodes: 50\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train DQN agent\n",
    "print(\"ðŸš€ Training DQN agent...\")\n",
    "print(\"   This may take 1-2 hours depending on hardware\")\n",
    "print(\"   Algorithm: Deep Q-Network (DQN)\")\n",
    "print(\"   Total timesteps: 100,000\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Create DQN model\n",
    "model = DQN(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=train_env,\n",
    "    learning_rate=0.0001,\n",
    "    buffer_size=50000,\n",
    "    learning_starts=1000,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    exploration_fraction=0.3,\n",
    "    exploration_initial_eps=1.0,\n",
    "    exploration_final_eps=0.05,\n",
    "    target_update_interval=1000,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./logs/forex_dqn/\"\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.learn(\n",
    "    total_timesteps=100000,\n",
    "    callback=callback,\n",
    "    progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Training complete!\")\n",
    "\n",
    "# Save model\n",
    "model_path = \"../models/dqn_forex_agent\"\n",
    "model.save(model_path)\n",
    "print(f\"ðŸ’¾ Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8085c5",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Evaluate Agent on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8d2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test environment\n",
    "test_env = ForexTradingEnv(test_df, initial_balance=10000)\n",
    "\n",
    "print(\"ðŸ”¬ Evaluating trained agent on test data...\")\n",
    "\n",
    "# Run evaluation\n",
    "state, info = test_env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "actions_taken = []\n",
    "\n",
    "while not done:\n",
    "    action, _ = model.predict(state, deterministic=True)\n",
    "    state, reward, done, truncated, info = test_env.step(action)\n",
    "    total_reward += reward\n",
    "    actions_taken.append(action)\n",
    "\n",
    "# Results\n",
    "final_balance = info['balance']\n",
    "total_equity = info['total_equity']\n",
    "trades = test_env.trades\n",
    "equity_curve = test_env.equity_curve\n",
    "\n",
    "print(f\"\\nâœ… Evaluation complete!\")\n",
    "print(f\"\\nðŸ“Š Performance Metrics:\")\n",
    "print(f\"   Initial Balance: $10,000.00\")\n",
    "print(f\"   Final Balance: ${final_balance:,.2f}\")\n",
    "print(f\"   Total Return: {(final_balance - 10000) / 10000 * 100:.2f}%\")\n",
    "print(f\"   Total Trades: {len(trades)}\")\n",
    "\n",
    "if len(trades) > 0:\n",
    "    winning_trades = [t for t in trades if t['pnl'] > 0]\n",
    "    losing_trades = [t for t in trades if t['pnl'] < 0]\n",
    "    \n",
    "    win_rate = len(winning_trades) / len(trades) * 100\n",
    "    avg_win = np.mean([t['pnl'] for t in winning_trades]) if winning_trades else 0\n",
    "    avg_loss = np.mean([t['pnl'] for t in losing_trades]) if losing_trades else 0\n",
    "    \n",
    "    print(f\"   Win Rate: {win_rate:.1f}%\")\n",
    "    print(f\"   Winning Trades: {len(winning_trades)}\")\n",
    "    print(f\"   Losing Trades: {len(losing_trades)}\")\n",
    "    print(f\"   Avg Win: ${avg_win:.2f}\")\n",
    "    print(f\"   Avg Loss: ${avg_loss:.2f}\")\n",
    "    \n",
    "    if avg_loss != 0:\n",
    "        profit_factor = abs(avg_win * len(winning_trades)) / abs(avg_loss * len(losing_trades))\n",
    "        print(f\"   Profit Factor: {profit_factor:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe666c8",
   "metadata": {},
   "source": [
    "## ðŸ“Š Visualize Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot equity curve\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Equity curve\n",
    "axes[0].plot(equity_curve, linewidth=2, color='blue')\n",
    "axes[0].axhline(y=10000, color='red', linestyle='--', label='Initial Balance')\n",
    "axes[0].set_title('Equity Curve', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Balance ($)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trade PnL distribution\n",
    "if len(trades) > 0:\n",
    "    pnls = [t['pnl'] for t in trades]\n",
    "    axes[1].hist(pnls, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[1].set_title('Trade PnL Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('PnL ($)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Visualizations complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7edcc",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Save Training Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f3b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary\n",
    "import json\n",
    "\n",
    "summary = {\n",
    "    'algorithm': 'DQN',\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'training_bars': len(train_df),\n",
    "    'test_bars': len(test_df),\n",
    "    'initial_balance': 10000,\n",
    "    'final_balance': float(final_balance),\n",
    "    'total_return_pct': float((final_balance - 10000) / 10000 * 100),\n",
    "    'total_trades': len(trades),\n",
    "    'win_rate': float(win_rate) if len(trades) > 0 else 0,\n",
    "    'model_path': model_path\n",
    "}\n",
    "\n",
    "summary_path = '../models/dqn_forex_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"ðŸ’¾ Summary saved to: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9c1102",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ‰ Training Complete!\n",
    "\n",
    "### âœ… Completed:\n",
    "1. âœ… Forex Trading Environment (Gymnasium)\n",
    "2. âœ… Technical indicators (state features)\n",
    "3. âœ… DQN agent training\n",
    "4. âœ… Test set evaluation\n",
    "5. âœ… Performance visualization\n",
    "\n",
    "### ðŸš€ Next Steps:\n",
    "- Try different algorithms (PPO, A3C)\n",
    "- Tune hyperparameters\n",
    "- Optimize reward function\n",
    "- Deploy to backend for live trading\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
                                                                                                                                                                                                                                                                             