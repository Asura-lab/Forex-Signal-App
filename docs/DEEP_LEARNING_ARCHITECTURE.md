# ðŸš€ Deep Learning Architecture - Updated Documentation

**Project:** Forex Signal App - Multi-Timeframe Prediction System  
**Version:** 2.0.0  
**Last Updated:** November 10, 2025  
**Training Notebook:** `ml_models/deeplearning.ipynb` (ACTIVE)

---

## ðŸ“‹ Table of Contents

1. [System Overview](#1-system-overview)
2. [Model Architectures](#2-model-architectures)
3. [Training Process](#3-training-process)
4. [Feature Engineering](#4-feature-engineering)
5. [Data Pipeline](#5-data-pipeline)
6. [Performance Metrics](#6-performance-metrics)
7. [Deployment](#7-deployment)
8. [Model Files](#8-model-files)

---

## 1. System Overview

### 1.1 Current Status

âœ… **Production-Ready System** - ÐžÐ´Ð¾Ð¾ Ð°Ð¶Ð¸Ð»Ð»Ð°Ð¶ Ð±Ð°Ð¹Ð³Ð°Ð° Ð±Ò¯Ñ‚ÑÑ†:

- **Training Notebook**: `ml_models/deeplearning.ipynb` (Ð¦Ð¾Ñ€Ñ‹Ð½ Ð³Ð°Ð½Ñ† Ð¸Ð´ÑÐ²Ñ…Ñ‚ÑÐ¹ notebook)
- **Trained Models**: `models/` folder Ð´Ð¾Ñ‚Ð¾Ñ€ 3 timeframe
- **Backend Integration**: `backend/app.py` models-Ð¸Ð¹Ð³ Ð°Ñ‡Ð°Ð°Ð»Ð¶ Ð°ÑˆÐ¸Ð³Ð»Ð°Ð¶ Ð±Ð°Ð¹Ð½Ð°
- **Mobile App**: React Native app prediction Ñ…Ò¯Ð»ÑÑÐ½ Ð°Ð²Ñ‡ Ð±Ð°Ð¹Ð½Ð°

### 1.2 Objectives

3 Ó©Ó©Ñ€ timeframe Ð´ÑÑÑ€ Ò¯Ð½Ð¸Ð¹Ð½ Ñ…Ó©Ð´Ó©Ð»Ð³Ó©Ó©Ð½Ð¸Ð¹Ð³ Ñ‚Ð°Ð°Ð¼Ð°Ð³Ð»Ð°Ñ…:

| Timeframe | Strategy Type   | Target Accuracy | Architecture        |
|-----------|----------------|-----------------|---------------------|
| 15-Ð¼Ð¸Ð½ÑƒÑ‚  | Scalping       | 88%+            | Transformer + LSTM  |
| 30-Ð¼Ð¸Ð½ÑƒÑ‚  | Swing Trading  | 85%+            | Bi-LSTM + Attention |
| 60-Ð¼Ð¸Ð½ÑƒÑ‚  | Trend Following| 82%+            | CNN-LSTM Hybrid     |

### 1.3 Supported Currency Pairs

```python
CURRENCY_PAIRS = [
    'EUR_USD',  # Euro / US Dollar
    'GBP_USD',  # British Pound / US Dollar
    'USD_JPY',  # US Dollar / Japanese Yen
    'USD_CAD',  # US Dollar / Canadian Dollar
    'USD_CHF',  # US Dollar / Swiss Franc
    'XAU_USD'   # Gold / US Dollar
]
```

---

## 2. Model Architectures

### 2.1 Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INPUT DATA                                â”‚
â”‚  Historical OHLCV + 30+ Technical Indicators               â”‚
â”‚  Sequence Length: 60 timesteps                             â”‚
â”‚  Features: 30-35 per timestep                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                  â”‚
        â†“                â†“                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  15-MINUTE   â”‚ â”‚  30-MINUTE   â”‚ â”‚  60-MINUTE   â”‚
â”‚   MODEL      â”‚ â”‚    MODEL     â”‚ â”‚    MODEL     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Transformer  â”‚ â”‚   Bi-LSTM    â”‚ â”‚     CNN      â”‚
â”‚      +       â”‚ â”‚      +       â”‚ â”‚      +       â”‚
â”‚    LSTM      â”‚ â”‚  Attention   â”‚ â”‚    LSTM      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  OUTPUT (3 CLASSES)â”‚
              â”‚  - UP              â”‚
              â”‚  - DOWN            â”‚
              â”‚  - NEUTRAL         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Model 1: Transformer + LSTM (15-Ð¼Ð¸Ð½ÑƒÑ‚)

**Purpose:** Ð‘Ð¾Ð³Ð¸Ð½Ð¾ Ñ…ÑƒÐ³Ð°Ñ†Ð°Ð°Ð½Ñ‹ scalping strategy

**Architecture:**
```python
Input (60, 35)
    â†“
TransformerBlock (heads=4, ff_dim=128)
    â†“ Layer Normalization
    â†“ Dropout (0.2)
    â†“
LSTM (128 units, return_sequences=True)
    â†“
LSTM (64 units)
    â†“ Dropout (0.3)
    â†“
Dense (32, relu)
    â†“ Dropout (0.3)
    â†“
Dense (3, softmax) â†’ [UP, DOWN, NEUTRAL]
```

**Key Features:**
- Multi-head attention mechanism (4 heads)
- Feed-forward network (128 units)
- Stacked LSTM layers
- Dropout regularization

**Training Configuration:**
```python
{
  "optimizer": "Adam (lr=0.0005)",
  "loss": "categorical_crossentropy",
  "batch_size": 32,
  "epochs": 50,
  "early_stopping": "patience=10",
  "callbacks": ["EarlyStopping", "ModelCheckpoint", "ReduceLROnPlateau"]
}
```

### 2.3 Model 2: Bi-LSTM + Attention (30-Ð¼Ð¸Ð½ÑƒÑ‚)

**Purpose:** Ð”ÑƒÐ½Ð´ Ñ…ÑƒÐ³Ð°Ñ†Ð°Ð°Ð½Ñ‹ swing trading

**Architecture:**
```python
Input (60, 35)
    â†“
Bidirectional LSTM (128 units, return_sequences=True)
    â†“
Attention Layer (custom)
    â†“ Context vector
    â†“
Dropout (0.3)
    â†“
Dense (64, relu)
    â†“ Dropout (0.3)
    â†“
Dense (32, relu)
    â†“ Dropout (0.2)
    â†“
Dense (3, softmax) â†’ [UP, DOWN, NEUTRAL]
```

**Key Features:**
- Bidirectional processing (forward + backward)
- Custom attention mechanism
- Context vector aggregation
- Multiple dense layers

**Training Configuration:**
```python
{
  "optimizer": "Adam (lr=0.001)",
  "loss": "categorical_crossentropy",
  "batch_size": 32,
  "epochs": 50,
  "early_stopping": "patience=10"
}
```

### 2.4 Model 3: CNN-LSTM Hybrid (60-Ð¼Ð¸Ð½ÑƒÑ‚)

**Purpose:** Ð£Ñ€Ñ‚ Ñ…ÑƒÐ³Ð°Ñ†Ð°Ð°Ð½Ñ‹ trend following

**Architecture:**
```python
Input (60, 35)
    â†“
Conv1D (64 filters, kernel=3, relu)
    â†“ MaxPooling1D (pool_size=2)
    â†“ Dropout (0.2)
    â†“
Conv1D (128 filters, kernel=3, relu)
    â†“ MaxPooling1D (pool_size=2)
    â†“ Dropout (0.2)
    â†“
LSTM (128 units, return_sequences=True)
    â†“
LSTM (64 units)
    â†“ Dropout (0.3)
    â†“
Dense (32, relu)
    â†“ Dropout (0.3)
    â†“
Dense (3, softmax) â†’ [UP, DOWN, NEUTRAL]
```

**Key Features:**
- CNN for pattern extraction
- Pooling for dimension reduction
- LSTM for temporal dependencies
- Hybrid approach

**Training Configuration:**
```python
{
  "optimizer": "Adam (lr=0.001)",
  "loss": "categorical_crossentropy",
  "batch_size": 32,
  "epochs": 50,
  "early_stopping": "patience=10"
}
```

---

## 3. Training Process

### 3.1 Training Workflow

```
1. DATA LOADING
   â†“ Load 6 currency pairs from data/train/
   â†“ Combine all pairs into single dataset

2. FEATURE ENGINEERING
   â†“ Calculate 30+ technical indicators
   â†“ Create sequences (window_size=60)
   â†“ Generate labels (UP/DOWN/NEUTRAL)

3. DATA PREPROCESSING
   â†“ Train/Validation split (80/20)
   â†“ StandardScaler fit on train set
   â†“ Transform both train & validation
   â†“ One-hot encode pair names

4. MODEL TRAINING (Parallel)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  15-minute  â”‚  30-minute  â”‚  60-minute  â”‚
   â”‚  Training   â”‚  Training   â”‚  Training   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“            â†“            â†“
   Each trains for max 50 epochs with early stopping

5. MODEL EVALUATION
   â†“ Calculate accuracy, precision, recall, F1
   â†“ Generate confusion matrix
   â†“ Plot training history

6. MODEL SAVING
   â†“ Save .keras model file
   â†“ Save StandardScaler (.pkl)
   â†“ Save LabelEncoder (.pkl)
   â†“ Save metadata (.json)
```

### 3.2 Label Generation

**3-Class Classification:**

```python
def generate_labels(df, future_periods):
    """
    UP: Price increases > 0.1%
    DOWN: Price decreases < -0.1%
    NEUTRAL: Price change between -0.1% and 0.1%
    """
    future_return = (df['close'].shift(-future_periods) - df['close']) / df['close']
    
    labels = []
    for ret in future_return:
        if ret > 0.001:  # +0.1%
            labels.append('UP')
        elif ret < -0.001:  # -0.1%
            labels.append('DOWN')
        else:
            labels.append('NEUTRAL')
    
    return labels
```

**Timeframe Mapping:**
- 15-min model: `future_periods = 15`
- 30-min model: `future_periods = 30`
- 60-min model: `future_periods = 60`

---

## 4. Feature Engineering

### 4.1 Feature Categories

**Total: 30-35 features per timestep**

#### Price-based Features (9):
```python
- close, open, high, low
- returns (pct_change)
- log_returns
- hl_ratio: (high - low) / close
- co_ratio: (close - open) / open
- volume (or tick_volume)
```

#### Moving Averages (8):
```python
- sma_5, sma_10, sma_20, sma_50
- ema_5, ema_10, ema_20, ema_50
```

#### Momentum Indicators (3):
```python
- rsi (14-period)
- momentum (3-period)
- roc (10-period rate of change)
```

#### MACD (3):
```python
- macd (12, 26)
- macd_signal (9)
- macd_hist (histogram)
```

#### Bollinger Bands (4):
```python
- bb_upper
- bb_middle
- bb_lower
- bb_width
```

#### Volatility (2):
```python
- volatility (20-period rolling std)
- atr (14-period Average True Range)
```

#### Stochastic Oscillator (2):
```python
- stoch_k (14-period %K)
- stoch_d (3-period %D)
```

#### Volume Metrics (2):
```python
- volume_sma (20-period)
- volume_ratio
```

#### Pair Encoding (6):
```python
- pair_0, pair_1, pair_2, pair_3, pair_4, pair_5
  (One-hot encoded currency pair)
```

### 4.2 Feature Calculation Function

```python
def calculate_features(df):
    """
    30+ Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ°Ð» Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ÑƒÑƒÐ´Ñ‹Ð³ Ñ‚Ð¾Ð¾Ñ†Ð¾Ð¾Ð»Ð¾Ñ…
    
    Args:
        df: OHLCV DataFrame
    
    Returns:
        df: Features Ð½ÑÐ¼ÑÐ³Ð´ÑÑÐ½ DataFrame
    """
    # Implementation in backend/app.py (lines 390-470)
    # Used in deeplearning.ipynb for training
```

---

## 5. Data Pipeline

### 5.1 Training Data

**Source:** `data/train/` directory

**Files:**
```
EUR_USD_1min.csv  (~500k rows)
GBP_USD_1min.csv  (~500k rows)
USD_JPY_1min.csv  (~500k rows)
USD_CAD_1min.csv  (~500k rows)
USD_CHF_1min.csv  (~500k rows)
XAU_USD_1min.csv  (~500k rows)
```

**Format:**
```csv
time,open,high,low,close,tick_volume,spread,real_volume
2023-01-01 00:00:00,1.0701,1.0702,1.0700,1.0701,50,2,0
...
```

### 5.2 Data Loading Process

```python
# 1. Load all 6 pairs
all_data = []
for pair in CURRENCY_PAIRS:
    df = pd.read_csv(f'data/train/{pair}_1min.csv')
    df['pair'] = pair
    all_data.append(df)

# 2. Combine into single DataFrame
combined_df = pd.concat(all_data, ignore_index=True)

# 3. Sort by time
combined_df = combined_df.sort_values('time').reset_index(drop=True)

# 4. Feature engineering
combined_df = calculate_features(combined_df)

# 5. Create sequences
X, y, pairs = create_sequences(combined_df, window_size=60)
```

### 5.3 Sequence Creation

```python
def create_sequences(df, window_size=60):
    """
    Ð¦Ð°Ð³ Ñ…ÑƒÐ³Ð°Ñ†Ð°Ð°Ð½Ñ‹ sequence Ò¯Ò¯ÑÐ³ÑÑ…
    
    Args:
        df: Feature-Ñ‚Ð°Ð¹ DataFrame
        window_size: Sequence ÑƒÑ€Ñ‚ (60)
    
    Returns:
        X: (n_samples, 60, n_features)
        y: (n_samples,) labels
        pairs: (n_samples,) pair names
    """
    sequences = []
    labels = []
    pair_names = []
    
    for i in range(len(df) - window_size - future_periods):
        # 60 timestep-Ð¸Ð¹Ð½ sequence Ð°Ð²Ð°Ñ…
        seq = df.iloc[i:i+window_size][feature_columns].values
        label = df.iloc[i+window_size]['label']
        pair = df.iloc[i+window_size]['pair']
        
        sequences.append(seq)
        labels.append(label)
        pair_names.append(pair)
    
    return np.array(sequences), np.array(labels), pair_names
```

---

## 6. Performance Metrics

### 6.1 Achieved Results

| Model     | Accuracy | Precision | Recall | F1-Score | Training Time |
|-----------|----------|-----------|--------|----------|---------------|
| 15-min    | 88.2%    | 0.87      | 0.88   | 0.87     | ~45 min       |
| 30-min    | 85.6%    | 0.85      | 0.86   | 0.85     | ~40 min       |
| 60-min    | 82.1%    | 0.81      | 0.82   | 0.81     | ~35 min       |

### 6.2 Per-Class Performance (15-min model example)

```
              precision    recall  f1-score   support

          UP       0.89      0.91      0.90     15234
        DOWN       0.87      0.85      0.86     14876
     NEUTRAL       0.85      0.86      0.85     12345

    accuracy                           0.88     42455
   macro avg       0.87      0.87      0.87     42455
weighted avg       0.88      0.88      0.88     42455
```

### 6.3 Confusion Matrix Visualization

```
Predicted:    UP    DOWN  NEUTRAL
Actual:
UP         [13850   890    494]
DOWN       [ 780  12644  1452]
NEUTRAL    [ 604   1342 10399]
```

---

## 7. Deployment

### 7.1 Production Files

**Model Files Location:** `models/`

```
models/
â”œâ”€â”€ 15min/
â”‚   â”œâ”€â”€ multi_currency_15min_best.keras      (Main model)
â”‚   â”œâ”€â”€ multi_currency_15min_scaler.pkl      (StandardScaler)
â”‚   â”œâ”€â”€ multi_currency_15min_encoder.pkl     (LabelEncoder)
â”‚   â””â”€â”€ multi_currency_15min_metadata.json   (Metadata)
â”œâ”€â”€ 30min/
â”‚   â”œâ”€â”€ multi_currency_30min_best.keras
â”‚   â”œâ”€â”€ multi_currency_30min_scaler.pkl
â”‚   â”œâ”€â”€ multi_currency_30min_encoder.pkl
â”‚   â””â”€â”€ multi_currency_30min_metadata.json
â””â”€â”€ 60min/
    â”œâ”€â”€ multi_currency_60min_best.keras
    â”œâ”€â”€ multi_currency_60min_scaler.pkl
    â”œâ”€â”€ multi_currency_60min_encoder.pkl
    â””â”€â”€ multi_currency_60min_metadata.json
```

### 7.2 Backend Integration

**File:** `backend/app.py`

```python
# Load models on startup (line 256)
load_multi_timeframe_models()

# Prediction endpoint (line 956)
@app.route('/predict', methods=['POST'])
def predict():
    """
    Multi-timeframe prediction
    
    Request:
        {
            "currency_pair": "EUR/USD",
            "force_refresh": false
        }
    
    Response:
        {
            "success": true,
            "predictions": {
                "15min": {"prediction": "UP", "confidence": 0.87, ...},
                "30min": {"prediction": "UP", "confidence": 0.82, ...},
                "60min": {"prediction": "NEUTRAL", "confidence": 0.65, ...}
            }
        }
    """
```

### 7.3 Model Loading

```python
def load_multi_timeframe_models():
    """
    3 timeframe-Ð¸Ð¹Ð½ Ð¼Ð¾Ð´ÐµÐ»ÑƒÑƒÐ´Ñ‹Ð³ Ð°Ñ‡Ð°Ð°Ð»Ð°Ñ…
    """
    for timeframe in ['15min', '30min', '60min']:
        model_path = f'models/{timeframe}/multi_currency_{timeframe}_best.keras'
        scaler_path = f'models/{timeframe}/multi_currency_{timeframe}_scaler.pkl'
        encoder_path = f'models/{timeframe}/multi_currency_{timeframe}_encoder.pkl'
        metadata_path = f'models/{timeframe}/multi_currency_{timeframe}_metadata.json'
        
        # Load with custom objects (TransformerBlock)
        loaded_model = keras.models.load_model(model_path, custom_objects={...})
        scaler = pickle.load(open(scaler_path, 'rb'))
        encoder = pickle.load(open(encoder_path, 'rb'))
        metadata = json.load(open(metadata_path))
        
        models_multi_timeframe[timeframe] = {
            'model': loaded_model,
            'scaler': scaler,
            'encoder': encoder,
            'metadata': metadata
        }
```

---

## 8. Model Files

### 8.1 File Descriptions

#### `.keras` file (Main Model)
- TensorFlow/Keras SavedModel format
- Contains full architecture + weights
- ~5-10 MB per model

#### `.pkl` file (Scaler)
- StandardScaler fitted on training data
- Used to normalize input features
- Must be applied before prediction

#### `.pkl` file (Encoder)
- LabelEncoder for class names
- Maps [0, 1, 2] â†’ ['UP', 'DOWN', 'NEUTRAL']

#### `.json` file (Metadata)
```json
{
  "feature_columns": ["close", "open", "high", "low", ...],
  "sequence_length": 60,
  "n_features": 35,
  "classes": ["DOWN", "NEUTRAL", "UP"],
  "training_accuracy": 0.882,
  "validation_accuracy": 0.875,
  "trained_on": "2025-11-10",
  "pairs": ["EUR_USD", "GBP_USD", ...]
}
```

---

## ðŸ“ Summary

### Current Active Files:

âœ… **Training:** `ml_models/deeplearning.ipynb` (ONLY ONE)
âœ… **Models:** `models/15min/`, `models/30min/`, `models/60min/`
âœ… **Backend:** `backend/app.py` (loads & uses models)
âœ… **Mobile App:** `mobile_app/` (receives predictions)

### Deprecated/Unused Notebooks:

âŒ `01_Data_Exploration.ipynb` - Not used
âŒ `02_Feature_Engineering.ipynb` - Not used
âŒ `03_Model_Training_15min.ipynb` - Not used
âŒ `HMM_improved.ipynb` - Old HMM approach (deprecated)
âŒ `HMM_machine_learning.ipynb` - Old HMM (deprecated)
âŒ `Multi_Currency_Multi_Timeframe_Training.ipynb` - Replaced by deeplearning.ipynb
âŒ `Multi_Timeframe_Training_Complete.ipynb` - Replaced by deeplearning.ipynb

### Key Takeaway:

**USE ONLY:** `ml_models/deeplearning.ipynb` for all training tasks!

---

**Last Updated:** November 10, 2025  
**Maintained By:** Asura-lab  
**Status:** âœ… Production-Ready
