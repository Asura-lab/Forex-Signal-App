# üöÄ Hybrid Trading System - 4 –°–∞—Ä—ã–Ω –°—É—Ä–≥–∞–ª—Ç—ã–Ω –¢”©–ª”©–≤–ª”©–≥”©”©

**–≠—Ö–ª—ç—Ö –æ–≥–Ω–æ–æ:** 2025-11-12  
**–î—É—É—Å–∞—Ö –æ–≥–Ω–æ–æ:** 2026-03-12  
**–ù–∏–π—Ç —Ö—É–≥–∞—Ü–∞–∞:** 16 –¥–æ–ª–æ–æ —Ö–æ–Ω–æ–≥ (4 —Å–∞—Ä)  
**–ó–æ—Ä–∏–ª–≥–æ:** –®–∏–Ω—ç—ç—Ä –Ω—ç–≥ —É–Ω–∏–≤–µ—Ä—Å–∞–ª Direction Predictor + Price Target Predictor + RL Agent

---

## üéØ –°–∏—Å—Ç–µ–º–∏–π–Ω –¢–æ–¥–æ—Ä—Ö–æ–π–ª–æ–ª—Ç

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã–Ω –¢–æ–π–º

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    HYBRID TRADING SYSTEM                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MODEL 1: Universal Direction Predictor (NEW!)              ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ              ‚îÇ
‚îÇ  Input: Historical OHLCV + 40+ indicators                   ‚îÇ
‚îÇ  Architecture: Transformer + Bi-LSTM + Attention            ‚îÇ
‚îÇ  Output: [UP, DOWN, NEUTRAL] + Confidence                   ‚îÇ
‚îÇ  Training: 6 –≤–∞–ª—é—Ç—ã–Ω —Ö–æ—Å –Ω—ç–≥—Ç–≥—ç—Å—ç–Ω                          ‚îÇ
‚îÇ  No timeframe split (Universal model)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MODEL 2: Price Target Predictor (Regression)               ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ              ‚îÇ
‚îÇ  Input: Direction + Confidence + Features                   ‚îÇ
‚îÇ  Output: Entry Price, Take Profit, Stop Loss                ‚îÇ
‚îÇ  Architecture: LSTM + Dense layers                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MODEL 3: RL Agent (PPO/A2C)                                ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ              ‚îÇ
‚îÇ  State: Market + Position + P&L + Predictions               ‚îÇ
‚îÇ  Action: [BUY, SELL, HOLD, CLOSE]                           ‚îÇ
‚îÇ  Reward: Profit + Risk-adjusted metrics                     ‚îÇ
‚îÇ  Training: Gym environment with backtest                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÖ –°–∞—Ä—ã–Ω –¢–æ–π–º

| –°–∞—Ä       | “Æ–Ω–¥—Å—ç–Ω –ê–∂–∏–ª                             | –ì–æ–ª “Æ—Ä –î“Ø–Ω                   |
| --------- | --------------------------------------- | ---------------------------- |
| **–°–∞—Ä 1** | Model 1 - Universal Direction Predictor | 90%+ accuracy –º–æ–¥–µ–ª—å         |
| **–°–∞—Ä 2** | Model 2 - Price Target Predictor        | Entry/TP/SL —Ç–∞–∞–º–∞–≥–ª–∞—Ö –º–æ–¥–µ–ª—å |
| **–°–∞—Ä 3** | Model 3 - RL Agent —Å—É—Ä–≥–∞–ª—Ç              | –ê–≤—Ç–æ–º–∞—Ç trading agent        |
| **–°–∞—Ä 4** | Integration + Production deployment     | Live trading system          |

---

# üìÜ –°–ê–†–´–ù –î–≠–õ–ì–≠–†–≠–ù–ì“Æ–ô –¢”®–õ”®–í–õ”®–ì”®”®

---

## üóìÔ∏è –°–ê–† 1: Universal Direction Predictor (–î–æ–ª–æ–æ —Ö–æ–Ω–æ–≥ 1-4)

**–ó–æ—Ä–∏–ª–≥–æ:** –ù—ç–≥ —Ö“Ø—á–∏—Ä—Ö—ç–≥ —É–Ω–∏–≤–µ—Ä—Å–∞–ª –º–æ–¥–µ–ª—å –±“Ø—Ç—ç—ç—Ö (timeframe split –±–∞–π—Ö–≥“Ø–π)

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 1: ”®–≥”©–≥–¥”©–ª –±—ç–ª—Ç–≥—ç—Ö & Feature Engineering

**–û–≥–Ω–æ–æ:** 2025-11-12 ‚Üí 2025-11-18

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 1.1: –¢“Ø“Ø—Ö—ç–Ω ”©–≥”©–≥–¥”©–ª —Ç–∞—Ç–∞—Ö (2 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- MetaTrader 5-–∞–∞—Å 12-24 —Å–∞—Ä—ã–Ω 1-–º–∏–Ω—É—Ç—ã–Ω ”©–≥”©–≥–¥”©–ª —Ç–∞—Ç–∞—Ö
- 6 –≤–∞–ª—é—Ç—ã–Ω —Ö–æ—Å (EUR/USD, GBP/USD, USD/JPY, USD/CAD, USD/CHF, XAU/USD)
- ”®–≥”©–≥–¥”©–ª —à–∞–ª–≥–∞—Ö, –∞–ª–¥–∞–∞—Ç–∞–π –º”©—Ä —É—Å—Ç–≥–∞—Ö
- –¶–∞–≥–∏–π–Ω –±“Ø—Å —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö (UTC)

–•“Ø–ª—ç—ç–≥–¥—ç–∂ –±—É–π “Ø—Ä –¥“Ø–Ω:
- data/train/PAIR_NAME_1min_12months.csv
- –ë–∞–≥–∞–¥–∞–∞ 500k+ rows per pair
- Clean, validated data

Code —Ñ–∞–π–ª:
- scripts/download_extended_data.py
```

**Sample code:**

```python
# scripts/download_extended_data.py
import MetaTrader5 as mt5
from datetime import datetime, timedelta
import pandas as pd

def download_historical_data(symbol, months=12):
    """12 —Å–∞—Ä—ã–Ω —Ç“Ø“Ø—Ö—ç–Ω ”©–≥”©–≥–¥”©–ª —Ç–∞—Ç–∞—Ö"""
    if not mt5.initialize():
        print("MT5 —ç—Ö–ª“Ø“Ø–ª—ç—Ö –∞–ª–¥–∞–∞")
        return None

    # 12 —Å–∞—Ä—ã–Ω ”©–º–Ω”©—Ö –æ–≥–Ω–æ–æ
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365)  # ~12 months

    # 1-–º–∏–Ω—É—Ç—ã–Ω ”©–≥”©–≥–¥”©–ª
    rates = mt5.copy_rates_range(
        symbol,
        mt5.TIMEFRAME_M1,
        start_date,
        end_date
    )

    if rates is None or len(rates) == 0:
        print(f"”®–≥”©–≥–¥”©–ª —Ç–∞—Ç–∞—Ö –∞–ª–¥–∞–∞: {symbol}")
        return None

    df = pd.DataFrame(rates)
    df['time'] = pd.to_datetime(df['time'], unit='s')

    # Save
    filename = f'data/train/{symbol}_1min_12months.csv'
    df.to_csv(filename, index=False)
    print(f"‚úì {symbol}: {len(df)} rows —Ç–∞—Ç–∞–≥–¥–ª–∞–∞")

    return df

# –¢–∞—Ç–∞—Ö
pairs = ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCAD', 'USDCHF', 'XAUUSD']
for pair in pairs:
    download_historical_data(pair, months=12)
```

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 1.2: Advanced Feature Engineering (3 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- 40+ —Ç–µ—Ö–Ω–∏–∫–∞–ª –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –Ω—ç–º—ç—Ö
- Market microstructure features
- Order flow proxies
- Volatility clustering features
- Time-based features (hour, day, week)

–®–∏–Ω—ç features:
- Volume Profile indicators
- Market breadth indicators
- Correlation features (pair-to-pair)
- Sentiment proxies
- Multi-timeframe aggregation (5min, 15min, 1h average)

Code —Ñ–∞–π–ª:
- ml_models/feature_engineering_advanced.py
```

**Advanced features:**

```python
# ml_models/feature_engineering_advanced.py
import pandas as pd
import numpy as np
import talib

def calculate_advanced_features(df):
    """40+ Advanced —Ç–µ—Ö–Ω–∏–∫–∞–ª –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä"""

    # === EXISTING FEATURES (30) ===
    # Price features
    df['returns'] = df['close'].pct_change()
    df['log_returns'] = np.log(df['close']).diff()
    df['hl_ratio'] = (df['high'] - df['low']) / df['close']
    df['co_ratio'] = (df['close'] - df['open']) / df['open']

    # Moving Averages
    for period in [5, 10, 20, 50, 100, 200]:
        df[f'sma_{period}'] = df['close'].rolling(period).mean()
        df[f'ema_{period}'] = df['close'].ewm(span=period).mean()

    # RSI
    df['rsi_14'] = talib.RSI(df['close'], timeperiod=14)
    df['rsi_28'] = talib.RSI(df['close'], timeperiod=28)

    # MACD
    macd, signal, hist = talib.MACD(df['close'])
    df['macd'] = macd
    df['macd_signal'] = signal
    df['macd_hist'] = hist

    # Bollinger Bands
    upper, middle, lower = talib.BBANDS(df['close'])
    df['bb_upper'] = upper
    df['bb_middle'] = middle
    df['bb_lower'] = lower
    df['bb_width'] = (upper - lower) / middle

    # ATR
    df['atr_14'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=14)
    df['atr_28'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=28)

    # Stochastic
    slowk, slowd = talib.STOCH(df['high'], df['low'], df['close'])
    df['stoch_k'] = slowk
    df['stoch_d'] = slowd

    # === NEW ADVANCED FEATURES (10+) ===

    # 1. ADX (Trend Strength)
    df['adx'] = talib.ADX(df['high'], df['low'], df['close'], timeperiod=14)

    # 2. CCI (Commodity Channel Index)
    df['cci'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=20)

    # 3. Williams %R
    df['willr'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=14)

    # 4. MFI (Money Flow Index)
    df['mfi'] = talib.MFI(df['high'], df['low'], df['close'], df['tick_volume'], timeperiod=14)

    # 5. OBV (On Balance Volume)
    df['obv'] = talib.OBV(df['close'], df['tick_volume'])
    df['obv_ema'] = df['obv'].ewm(span=20).mean()

    # 6. Parabolic SAR
    df['sar'] = talib.SAR(df['high'], df['low'])

    # 7. TRIX (Triple Exponential Average)
    df['trix'] = talib.TRIX(df['close'], timeperiod=30)

    # 8. Ichimoku Cloud components
    # Tenkan-sen (Conversion Line)
    high_9 = df['high'].rolling(window=9).max()
    low_9 = df['low'].rolling(window=9).min()
    df['tenkan_sen'] = (high_9 + low_9) / 2

    # Kijun-sen (Base Line)
    high_26 = df['high'].rolling(window=26).max()
    low_26 = df['low'].rolling(window=26).min()
    df['kijun_sen'] = (high_26 + low_26) / 2

    # Senkou Span A (Leading Span A)
    df['senkou_span_a'] = ((df['tenkan_sen'] + df['kijun_sen']) / 2).shift(26)

    # 9. Volatility indicators
    df['historical_volatility'] = df['returns'].rolling(20).std() * np.sqrt(252)
    df['parkinson_volatility'] = np.sqrt(
        (1 / (4 * np.log(2))) *
        ((np.log(df['high'] / df['low'])) ** 2).rolling(20).mean()
    )

    # 10. Market microstructure
    df['spread'] = df['spread']  # Already exists
    df['volume_imbalance'] = (df['tick_volume'] - df['tick_volume'].rolling(20).mean()) / df['tick_volume'].rolling(20).std()

    # 11. Time-based features
    df['hour'] = pd.to_datetime(df['time']).dt.hour
    df['day_of_week'] = pd.to_datetime(df['time']).dt.dayofweek
    df['is_london_session'] = ((df['hour'] >= 8) & (df['hour'] < 16)).astype(int)
    df['is_ny_session'] = ((df['hour'] >= 13) & (df['hour'] < 21)).astype(int)
    df['is_overlap'] = ((df['hour'] >= 13) & (df['hour'] < 16)).astype(int)

    # 12. Multi-timeframe aggregation
    # Calculate 5-min features
    df['close_5min'] = df['close'].rolling(5).mean()
    df['volatility_5min'] = df['returns'].rolling(5).std()

    # Calculate 15-min features
    df['close_15min'] = df['close'].rolling(15).mean()
    df['volatility_15min'] = df['returns'].rolling(15).std()

    # Calculate 1-hour features
    df['close_1h'] = df['close'].rolling(60).mean()
    df['volatility_1h'] = df['returns'].rolling(60).std()

    # Drop NaN
    df = df.dropna()

    return df
```

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 1.3: Label Generation Strategy (2 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- Fixed horizon labeling (30/60/120 –º–∏–Ω—É—Ç—ã–Ω –∏—Ä—ç—ç–¥“Ø–π)
- Adaptive labeling (volatility-based)
- Triple barrier method (TP/SL based)
- Multiple label strategies —Ç–µ—Å—Ç–ª—ç—Ö

“Æ—Ä –¥“Ø–Ω:
- Optimal labeling strategy —Å–æ–Ω–≥–æ—Ö
- Training labels –±“Ø—Ç—ç—ç—Ö
- Label distribution —à–∏–Ω–∂–ª—ç—Ö

Code —Ñ–∞–π–ª:
- ml_models/label_generation_strategy.py
```

**Label generation:**

```python
# ml_models/label_generation_strategy.py
import pandas as pd
import numpy as np

def triple_barrier_labeling(df, lookforward=60, profit_target=0.5, stop_loss=0.3):
    """
    Triple Barrier Method for labeling

    Args:
        lookforward: –•—ç–¥—ç–Ω –º–∏–Ω—É—Ç —É—Ä–∞–≥—à —Ö–∞—Ä–∞—Ö
        profit_target: TP —Ö—É–≤—å (0.5% = 50 pips for forex)
        stop_loss: SL —Ö—É–≤—å (0.3% = 30 pips)

    Returns:
        labels: ['UP', 'DOWN', 'NEUTRAL']
    """
    labels = []

    for i in range(len(df) - lookforward):
        entry_price = df.iloc[i]['close']
        future_prices = df.iloc[i+1:i+lookforward+1]['close']

        # Define barriers
        upper_barrier = entry_price * (1 + profit_target / 100)
        lower_barrier = entry_price * (1 - stop_loss / 100)

        # Check which barrier is hit first
        hit_upper = (future_prices >= upper_barrier).any()
        hit_lower = (future_prices <= lower_barrier).any()

        if hit_upper and hit_lower:
            # Both hit - check which came first
            upper_idx = (future_prices >= upper_barrier).idxmax()
            lower_idx = (future_prices <= lower_barrier).idxmax()

            if upper_idx < lower_idx:
                labels.append('UP')
            else:
                labels.append('DOWN')
        elif hit_upper:
            labels.append('UP')
        elif hit_lower:
            labels.append('DOWN')
        else:
            # Neither hit - check final direction
            final_return = (future_prices.iloc[-1] - entry_price) / entry_price
            if final_return > 0.001:  # >0.1%
                labels.append('UP')
            elif final_return < -0.001:
                labels.append('DOWN')
            else:
                labels.append('NEUTRAL')

    return labels

def adaptive_labeling(df, lookforward=60, volatility_multiplier=2.0):
    """
    Adaptive labeling based on ATR (volatility)
    TP/SL dynamically adjusted
    """
    labels = []

    for i in range(len(df) - lookforward):
        entry_price = df.iloc[i]['close']
        atr = df.iloc[i]['atr_14']

        # Dynamic barriers
        upper_barrier = entry_price + (atr * volatility_multiplier)
        lower_barrier = entry_price - (atr * volatility_multiplier)

        future_prices = df.iloc[i+1:i+lookforward+1]['close']

        hit_upper = (future_prices >= upper_barrier).any()
        hit_lower = (future_prices <= lower_barrier).any()

        if hit_upper and not hit_lower:
            labels.append('UP')
        elif hit_lower and not hit_upper:
            labels.append('DOWN')
        else:
            labels.append('NEUTRAL')

    return labels
```

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 2: Model Architecture Design

**–û–≥–Ω–æ–æ:** 2025-11-19 ‚Üí 2025-11-25

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 2.1: Hybrid Architecture —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö (2 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- Transformer + Bi-LSTM + Attention –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –¥–∏–∑–∞–π–Ω
- Layer –±“Ø—Ä–∏–π–Ω “Ø“Ø—Ä—ç–≥ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö
- Hyperparameter space —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Input (sequence_length, features)  ‚îÇ
‚îÇ           ‚Üì                        ‚îÇ
‚îÇ TransformerBlock (4 heads)         ‚îÇ
‚îÇ           ‚Üì                        ‚îÇ
‚îÇ Bidirectional LSTM (256 units)     ‚îÇ
‚îÇ           ‚Üì                        ‚îÇ
‚îÇ Attention Layer                    ‚îÇ
‚îÇ           ‚Üì                        ‚îÇ
‚îÇ Dense (128, relu) + Dropout(0.3)   ‚îÇ
‚îÇ           ‚Üì                        ‚îÇ
‚îÇ Dense (64, relu) + Dropout(0.3)    ‚îÇ
‚îÇ           ‚Üì                        ‚îÇ
‚îÇ Output (3, softmax)                ‚îÇ
‚îÇ [UP, DOWN, NEUTRAL]                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Code —Ñ–∞–π–ª:
- ml_models/hybrid_direction_model.py
```

**Model architecture:**

```python
# ml_models/hybrid_direction_model.py
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import keras

class TransformerBlock(layers.Layer):
    """Multi-head self-attention + Feed-forward"""
    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):
        super().__init__()
        self.att = layers.MultiHeadAttention(
            num_heads=num_heads,
            key_dim=embed_dim
        )
        self.ffn = keras.Sequential([
            layers.Dense(ff_dim, activation="relu"),
            layers.Dense(embed_dim),
        ])
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(dropout_rate)
        self.dropout2 = layers.Dropout(dropout_rate)

    def call(self, inputs, training=False):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

def build_hybrid_direction_model(
    sequence_length=60,
    n_features=45,
    transformer_heads=4,
    transformer_ff_dim=128,
    lstm_units=256,
    dropout_rate=0.3
):
    """
    Hybrid Direction Predictor Model

    Architecture:
        Input ‚Üí Transformer ‚Üí Bi-LSTM ‚Üí Attention ‚Üí Dense ‚Üí Output

    Args:
        sequence_length: –¶–∞–≥–∏–π–Ω –±–∞–≥—Ü—ã–Ω —É—Ä—Ç (default: 60)
        n_features: Feature —Ç–æ–æ (default: 45)
        transformer_heads: Attention heads (default: 4)
        transformer_ff_dim: FF network dim (default: 128)
        lstm_units: LSTM –Ω—ç–≥–∂–∏–π–Ω —Ç–æ–æ (default: 256)
        dropout_rate: Dropout rate (default: 0.3)

    Returns:
        model: Keras Model
    """

    # Input
    inputs = layers.Input(shape=(sequence_length, n_features))

    # Transformer Block
    x = TransformerBlock(
        embed_dim=n_features,
        num_heads=transformer_heads,
        ff_dim=transformer_ff_dim,
        dropout_rate=0.1
    )(inputs)

    # Bidirectional LSTM
    x = layers.Bidirectional(
        layers.LSTM(lstm_units, return_sequences=True)
    )(x)
    x = layers.Dropout(dropout_rate)(x)

    # Attention mechanism
    attention = layers.MultiHeadAttention(
        num_heads=4,
        key_dim=lstm_units*2
    )(x, x)
    x = layers.Add()([x, attention])
    x = layers.LayerNormalization()(x)

    # Global pooling
    x = layers.GlobalAveragePooling1D()(x)

    # Dense layers
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dropout(dropout_rate)(x)
    x = layers.Dense(64, activation='relu')(x)
    x = layers.Dropout(dropout_rate)(x)

    # Output layer
    outputs = layers.Dense(3, activation='softmax', name='direction')(x)

    # Confidence output (auxiliary)
    confidence = layers.Dense(1, activation='sigmoid', name='confidence')(x)

    # Model
    model = keras.Model(
        inputs=inputs,
        outputs={'direction': outputs, 'confidence': confidence}
    )

    return model

# Example usage
model = build_hybrid_direction_model()
model.summary()
```

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 2.2: Training Pipeline –±“Ø—Ç—ç—ç—Ö (3 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- Data preprocessing pipeline
- Custom data generator
- Multi-output loss function
- Custom callbacks (EarlyStopping, ReduceLR, ModelCheckpoint)
- TensorBoard logging

Code —Ñ–∞–π–ª:
- ml_models/training_pipeline.py
```

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 2.3: Cross-validation —Å—Ç—Ä–∞—Ç–µ–≥–∏ (2 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- Time-series cross-validation
- Walk-forward validation
- Purging & embargo
- Validation metrics —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö

–°—Ç—Ä–∞—Ç–µ–≥–∏:
- 70% train, 15% validation, 15% test
- Walk-forward: 5-fold expanding window

Code —Ñ–∞–π–ª:
- ml_models/cross_validation.py
```

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 3: Model Training & Tuning

**–û–≥–Ω–æ–æ:** 2025-11-26 ‚Üí 2025-12-02

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 3.1: Baseline –º–æ–¥–µ–ª—å —Å—É—Ä–≥–∞—Ö (2 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- –≠–Ω–≥–∏–π–Ω hyperparameters-–∞–∞—Ä —ç—Ö–Ω–∏–π –º–æ–¥–µ–ª—å —Å—É—Ä–≥–∞—Ö
- Training/validation accuracy —Ö—è–Ω–∞—Ö
- Overfitting —à–∞–ª–≥–∞—Ö
- Confusion matrix, classification report

Target:
- Validation accuracy: 70%+
- Balanced classes

Code:
- ml_models/train_baseline.py
```

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 3.2: Hyperparameter Tuning with Optuna (3 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- Optuna-–∞–∞—Ä hyperparameter optimization
- Search space —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö
- 50-100 trials –∞–∂–∏–ª–ª—É—É–ª–∞—Ö
- Best model —Å–æ–Ω–≥–æ—Ö

Hyperparameters:
- Learning rate: [1e-5, 1e-2]
- LSTM units: [128, 256, 512]
- Transformer heads: [2, 4, 8]
- Dropout: [0.2, 0.3, 0.4, 0.5]
- Batch size: [32, 64, 128]

Code:
- ml_models/hyperparameter_tuning.py
```

**Optuna code:**

```python
# ml_models/hyperparameter_tuning.py
import optuna
from optuna.integration import TFKerasPruningCallback

def objective(trial):
    # Hyperparameters
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)
    lstm_units = trial.suggest_categorical('lstm_units', [128, 256, 512])
    transformer_heads = trial.suggest_categorical('transformer_heads', [2, 4, 8])
    dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.5)
    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])

    # Build model
    model = build_hybrid_direction_model(
        lstm_units=lstm_units,
        transformer_heads=transformer_heads,
        dropout_rate=dropout_rate
    )

    # Compile
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    # Train
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=50,
        batch_size=batch_size,
        callbacks=[
            TFKerasPruningCallback(trial, 'val_accuracy'),
            keras.callbacks.EarlyStopping(patience=10)
        ],
        verbose=0
    )

    # Return best validation accuracy
    return max(history.history['val_accuracy'])

# Run optimization
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100, timeout=86400)  # 24 hours

print("Best hyperparameters:", study.best_params)
print("Best validation accuracy:", study.best_value)
```

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 3.3: Best –º–æ–¥–µ–ª—å –¥–∞—Ö–∏–Ω —Å—É—Ä–≥–∞—Ö (2 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- Best hyperparameters –∞—à–∏–≥–ª–∞–∂ –¥–∞—Ö–∏–Ω —Å—É—Ä–≥–∞—Ö
- Full training data (train+val) –∞—à–∏–≥–ª–∞—Ö
- Final test set –¥—ç—ç—Ä “Ø–Ω—ç–ª—ç—Ö
- Model —Ö–∞–¥–≥–∞–ª–∞—Ö

Target:
- Test accuracy: 85%+
- Balanced precision/recall

Output:
- models/hybrid_direction_predictor_best.keras
- models/hybrid_direction_scaler.pkl
- models/hybrid_direction_metadata.json
```

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 4: Model Evaluation & Analysis

**–û–≥–Ω–æ–æ:** 2025-12-03 ‚Üí 2025-12-09

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 4.1: Comprehensive evaluation (3 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- Per-currency accuracy
- Per-timeframe performance analysis
- Confidence calibration
- Error analysis
- Confusion matrix visualization

Metrics:
- Accuracy, Precision, Recall, F1
- ROC-AUC, PR-AUC
- Sharpe ratio (if applicable)
- Win rate per confidence threshold

Code:
- ml_models/model_evaluation.py
```

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 4.2: Backtesting simulation (2 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- Direction-only backtesting
- Simple trading strategy (follow predictions)
- P&L calculation
- Drawdown analysis

Strategy:
- BUY if prediction=UP & confidence>0.7
- SELL if prediction=DOWN & confidence>0.7
- Exit after 60 minutes

Code:
- ml_models/direction_backtest.py
```

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 4.3: Documentation & Cleanup (2 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- Model architecture documentation
- Training –ø—Ä–æ—Ü–µ—Å—Å —Ç–∞–π–ª–±–∞—Ä–ª–∞—Ö
- Best practices –±–∏—á–∏—Ö
- Code refactoring

Output:
- docs/MODEL1_DIRECTION_PREDICTOR.md
```

---

## üóìÔ∏è –°–ê–† 2: Price Target Predictor (–î–æ–ª–æ–æ —Ö–æ–Ω–æ–≥ 5-8)

**–ó–æ—Ä–∏–ª–≥–æ:** Entry, Take Profit, Stop Loss —Ç–∞–∞–º–∞–≥–ª–∞—Ö regression –º–æ–¥–µ–ª—å

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 5: Architecture & Data Preparation

**–û–≥–Ω–æ–æ:** 2025-12-10 ‚Üí 2025-12-16

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 5.1: Target generation (3 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- Optimal entry point —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö
- TP/SL calculation strategy
- ATR-based dynamic levels
- Risk/Reward ratio optimization

Strategies:
1. Fixed TP/SL (50 pips TP, 30 pips SL)
2. ATR-based (2x ATR TP, 1x ATR SL)
3. Support/Resistance based
4. Fibonacci retracement

Output:
- Entry_price, TP_price, SL_price labels
```

**Target generation code:**

```python
def generate_price_targets(df, direction_predictions, atr_multiplier_tp=2.0, atr_multiplier_sl=1.0):
    """
    Generate Entry, TP, SL targets based on direction & ATR
    """
    targets = []

    for i in range(len(direction_predictions)):
        direction = direction_predictions[i]  # 'UP' or 'DOWN'
        confidence = direction_confidences[i]

        current_price = df.iloc[i]['close']
        atr = df.iloc[i]['atr_14']

        if direction == 'UP':
            entry = current_price
            tp = entry + (atr * atr_multiplier_tp)
            sl = entry - (atr * atr_multiplier_sl)
        elif direction == 'DOWN':
            entry = current_price
            tp = entry - (atr * atr_multiplier_tp)
            sl = entry + (atr * atr_multiplier_sl)
        else:  # NEUTRAL
            entry = current_price
            tp = current_price
            sl = current_price

        targets.append({
            'entry': entry,
            'tp': tp,
            'sl': sl,
            'direction': direction,
            'confidence': confidence
        })

    return targets
```

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 5.2: Model architecture (2 ”©–¥”©—Ä)

```bash
Architecture:
Input: [Direction prediction, Confidence, Features]
       ‚Üì
LSTM(128) ‚Üí LSTM(64)
       ‚Üì
Dense(64, relu) ‚Üí Dropout(0.3)
       ‚Üì
3 Outputs: [Entry, TP, SL] (regression)

Code:
- ml_models/price_target_model.py
```

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 5.3: Training pipeline (2 ”©–¥”©—Ä)

```bash
–ê–∂–∏–ª:
- Multi-output regression loss
- Custom metrics (MAE, MAPE for each output)
- Training pipeline –±“Ø—Ç—ç—ç—Ö

Code:
- ml_models/train_price_target.py
```

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 6: Training & Tuning

**–û–≥–Ω–æ–æ:** 2025-12-17 ‚Üí 2025-12-23

_(3 ”©–¥”©—Ä baseline, 3 ”©–¥”©—Ä tuning, 1 ”©–¥”©—Ä evaluation)_

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 7: Integration Testing

**–û–≥–Ω–æ–æ:** 2025-12-24 ‚Üí 2025-12-30

```bash
–ê–∂–∏–ª:
- Model 1 + Model 2 pipeline
- End-to-end testing
- Combined backtesting
- Performance analysis
```

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 8: Optimization & Documentation

**–û–≥–Ω–æ–æ:** 2025-12-31 ‚Üí 2026-01-06

---

## üóìÔ∏è –°–ê–† 3: RL Agent Training (–î–æ–ª–æ–æ —Ö–æ–Ω–æ–≥ 9-12)

**–ó–æ—Ä–∏–ª–≥–æ:** –ê–≤—Ç–æ–º–∞—Ç –∞—Ä–∏–ª–∂–∞–∞–Ω—ã —à–∏–π–¥–≤—ç—Ä –≥–∞—Ä–≥–∞—Ö agent

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 9: Trading Environment

**–û–≥–Ω–æ–æ:** 2026-01-07 ‚Üí 2026-01-13

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 9.1: Gym environment (4 ”©–¥”©—Ä)

```python
# ml_models/trading_environment.py
import gym
from gym import spaces

class ForexTradingEnv(gym.Env):
    """
    Reinforcement Learning Trading Environment
    """
    def __init__(self, df, model1, model2, initial_balance=10000):
        super().__init__()

        self.df = df
        self.model1 = model1  # Direction predictor
        self.model2 = model2  # Price target predictor
        self.initial_balance = initial_balance

        # Actions: [HOLD, BUY, SELL, CLOSE]
        self.action_space = spaces.Discrete(4)

        # Observations: [market features, predictions, position info]
        self.observation_space = spaces.Box(
            low=-np.inf,
            high=np.inf,
            shape=(50,),  # State vector
            dtype=np.float32
        )

        self.reset()

    def reset(self):
        self.current_step = 60
        self.balance = self.initial_balance
        self.position = None
        self.entry_price = 0
        self.tp_price = 0
        self.sl_price = 0
        self.trades = []

        return self._get_state()

    def _get_state(self):
        """Construct state vector"""
        # Market features
        market_features = self.df.iloc[self.current_step][self.feature_columns].values

        # Model predictions
        sequence = self.df.iloc[self.current_step-60:self.current_step][self.feature_columns].values
        direction_pred = self.model1.predict(sequence[np.newaxis, ...])[0]
        price_targets = self.model2.predict(sequence[np.newaxis, ...])[0]

        # Position info
        position_features = [
            1 if self.position == 'LONG' else 0,
            1 if self.position == 'SHORT' else 0,
            self.balance / self.initial_balance,
            self.entry_price,
            self.tp_price,
            self.sl_price
        ]

        state = np.concatenate([
            market_features[-10:],  # Last 10 features
            direction_pred,
            price_targets,
            position_features
        ])

        return state

    def step(self, action):
        current_price = self.df.iloc[self.current_step]['close']
        reward = 0
        done = False

        # Execute action
        # ... (implementation similar to previous example)

        self.current_step += 1

        if self.current_step >= len(self.df) - 1:
            done = True

        return self._get_state(), reward, done, {}
```

#### –î–∞–∞–ª–≥–∞–≤–∞—Ä 9.2: Reward function design (2 ”©–¥”©—Ä)

```python
def calculate_reward(self, action, pnl):
    """
    Sophisticated reward function
    """
    reward = 0

    # P&L reward
    reward += pnl / 100  # Scale by 100

    # Risk-adjusted reward (Sharpe ratio component)
    if len(self.trades) > 10:
        returns = [t['pnl'] for t in self.trades[-10:]]
        sharpe = np.mean(returns) / (np.std(returns) + 1e-6)
        reward += sharpe * 0.1

    # Win rate bonus
    if len(self.trades) > 0:
        win_rate = len([t for t in self.trades if t['pnl'] > 0]) / len(self.trades)
        if win_rate > 0.6:
            reward += 0.5

    # Drawdown penalty
    peak = max([t['balance'] for t in self.equity_curve])
    drawdown = (peak - self.balance) / peak
    if drawdown > 0.2:  # 20% drawdown
        reward -= 1.0

    return reward
```

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 10-11: PPO Agent Training

**–û–≥–Ω–æ–æ:** 2026-01-14 ‚Üí 2026-01-27

```bash
–ê–∂–∏–ª:
- PPO agent —Å—É—Ä–≥–∞–ª—Ç (stable-baselines3)
- Hyperparameter tuning
- Multiple episodes
- Performance tracking

Training:
- 1M+ timesteps
- 2 –¥–æ–ª–æ–æ —Ö–æ–Ω–æ–≥
```

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 12: RL Evaluation

**–û–≥–Ω–æ–æ:** 2026-01-28 ‚Üí 2026-02-03

```bash
–ê–∂–∏–ª:
- Backtesting on test set
- Performance metrics
- Comparison with baseline strategies
```

---

## üóìÔ∏è –°–ê–† 4: Integration & Production (–î–æ–ª–æ–æ —Ö–æ–Ω–æ–≥ 13-16)

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 13-14: Full System Integration

**–û–≥–Ω–æ–æ:** 2026-02-04 ‚Üí 2026-02-17

```bash
–ê–∂–∏–ª:
- 3 –º–æ–¥–µ–ª—å –Ω—ç–≥—Ç–≥—ç—Ö
- Backend API integration
- Mobile app updates
- Real-time prediction pipeline
```

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 15: Paper Trading

**–û–≥–Ω–æ–æ:** 2026-02-18 ‚Üí 2026-02-24

```bash
–ê–∂–∏–ª:
- Paper trading system
- Live market testing (no real money)
- Performance monitoring
- Bug fixing
```

---

### ‚úÖ –î–û–õ–û–û –•–û–ù–û–ì 16: Production Deployment

**–û–≥–Ω–æ–æ:** 2026-02-25 ‚Üí 2026-03-03

```bash
–ê–∂–∏–ª:
- Production deployment
- Monitoring setup
- Documentation
- User training
```

---

## üìä –•“Ø–ª—ç—ç–≥–¥—ç–∂ –±—É–π “Ø—Ä –¥“Ø–Ω

### –°–∞—Ä 1 –¥—É—É—Å–∞—Ö–∞–¥:

- ‚úÖ Universal Direction Predictor (85%+ accuracy)
- ‚úÖ 45+ features
- ‚úÖ Comprehensive evaluation

### –°–∞—Ä 2 –¥—É—É—Å–∞—Ö–∞–¥:

- ‚úÖ Price Target Predictor (MAE <10 pips)
- ‚úÖ Model 1 + Model 2 pipeline
- ‚úÖ Combined backtesting

### –°–∞—Ä 3 –¥—É—É—Å–∞—Ö–∞–¥:

- ‚úÖ RL Agent (60%+ win rate)
- ‚úÖ Full hybrid system
- ‚úÖ Advanced backtesting

### –°–∞—Ä 4 –¥—É—É—Å–∞—Ö–∞–¥:

- ‚úÖ Production-ready system
- ‚úÖ Real-time trading capability
- ‚úÖ Monitoring & maintenance

---

## üéØ Success Metrics

| Metric             | Target   | Measurement      |
| ------------------ | -------- | ---------------- |
| Direction Accuracy | 85%+     | Model 1 test set |
| Price Target MAE   | <10 pips | Model 2 test set |
| RL Win Rate        | 60%+     | Backtesting      |
| Sharpe Ratio       | 1.5+     | RL agent         |
| Max Drawdown       | <15%     | RL agent         |
| Profit Factor      | 1.8+     | RL agent         |

---

## üõ†Ô∏è Tools & Libraries

```bash
# Core ML
tensorflow>=2.15.0
keras>=3.0.0
stable-baselines3
gym
optuna

# Data
pandas
numpy
talib
scikit-learn

# Visualization
matplotlib
seaborn
plotly

# Backend
flask
pymongo

# Monitoring
tensorboard
mlflow
```

---

## üìù Deliverables

### Code:

- `ml_models/hybrid_direction_model.py`
- `ml_models/price_target_model.py`
- `ml_models/trading_environment.py`
- `ml_models/rl_agent.py`
- `ml_models/training_pipeline.py`

### Models:

- `models/hybrid_direction_predictor_best.keras`
- `models/price_target_predictor_best.keras`
- `models/rl_agent_ppo.zip`

### Documentation:

- `docs/MODEL1_DIRECTION_PREDICTOR.md`
- `docs/MODEL2_PRICE_TARGET.md`
- `docs/MODEL3_RL_AGENT.md`
- `docs/HYBRID_SYSTEM_GUIDE.md`

---

## ‚ö†Ô∏è Risks & Mitigation

| Risk                | Impact | Mitigation                                     |
| ------------------- | ------ | ---------------------------------------------- |
| Insufficient data   | High   | Extend data collection period                  |
| Overfitting         | High   | Robust cross-validation, regularization        |
| Slow training       | Medium | Use GPU, optimize code                         |
| Poor RL convergence | High   | Tune reward function, try different algorithms |
| Production bugs     | Medium | Extensive testing, paper trading               |

---

## üéì Learning Resources

**Week 1-4:**

- TensorFlow documentation
- Transformer papers

**Week 5-8:**

- Multi-output regression techniques
- ATR-based trading strategies

**Week 9-12:**

- "Reinforcement Learning" by Sutton & Barto
- Stable-Baselines3 documentation

**Week 13-16:**

- Production ML deployment
- MLOps best practices

---

**–¢”©–ª”©–≤–ª”©–≥”©”©–≥ –±–∞—Ç–∞–ª—Å–∞–Ω:** 2025-11-12  
**–î—É—É—Å–∞—Ö —Ö—É–≥–∞—Ü–∞–∞:** 2026-03-12  
**–°—Ç–∞—Ç—É—Å:** –≠—Ö–ª—ç—Ö—ç–¥ –±—ç–ª—ç–Ω ‚úÖ

**–ê–º–∂–∏–ª—Ç —Ö“Ø—Å—å–µ! üöÄ**
