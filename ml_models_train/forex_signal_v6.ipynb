{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7562528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel is working\n"
     ]
    }
   ],
   "source": [
    "print(\"Kernel is working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2d64aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries loaded\n",
      "âœ… Model Directory: c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "MODEL_DIR = BASE_DIR / 'models' / 'signal_generator_v6'\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ… Libraries loaded\")\n",
    "print(f\"âœ… Model Directory: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9549ce4",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Feature Engineering (V6 Enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b287245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1,859,492 rows\n",
      "Test: 296,778 rows\n",
      "Adding V6 features...\n",
      "âœ“ Features added. Total columns: 39\n",
      "âœ“ Features added. Total columns: 39\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "train_df = pd.read_csv(DATA_DIR / 'EUR_USD_1min.csv')\n",
    "test_df = pd.read_csv(DATA_DIR / 'EUR_USD_test.csv')\n",
    "\n",
    "# Standardize columns\n",
    "for df in [train_df, test_df]:\n",
    "    if 'timestamp' in df.columns:\n",
    "        df.rename(columns={'timestamp': 'time'}, inplace=True)\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "print(f\"Train: {len(train_df):,} rows\")\n",
    "print(f\"Test: {len(test_df):,} rows\")\n",
    "\n",
    "def calculate_adx(df, period=14):\n",
    "    \"\"\"Calculate Average Directional Index (ADX)\"\"\"\n",
    "    df = df.copy()\n",
    "    df['tr0'] = abs(df['high'] - df['low'])\n",
    "    df['tr1'] = abs(df['high'] - df['close'].shift())\n",
    "    df['tr2'] = abs(df['low'] - df['close'].shift())\n",
    "    df['tr'] = df[['tr0', 'tr1', 'tr2']].max(axis=1)\n",
    "    \n",
    "    df['up_move'] = df['high'] - df['high'].shift()\n",
    "    df['down_move'] = df['low'].shift() - df['low']\n",
    "    \n",
    "    df['plus_dm'] = np.where((df['up_move'] > df['down_move']) & (df['up_move'] > 0), df['up_move'], 0)\n",
    "    df['minus_dm'] = np.where((df['down_move'] > df['up_move']) & (df['down_move'] > 0), df['down_move'], 0)\n",
    "    \n",
    "    # Smooth\n",
    "    df['atr'] = df['tr'].rolling(period).mean()\n",
    "    df['plus_di'] = 100 * (df['plus_dm'].rolling(period).mean() / df['atr'])\n",
    "    df['minus_di'] = 100 * (df['minus_dm'].rolling(period).mean() / df['atr'])\n",
    "    \n",
    "    df['dx'] = 100 * abs(df['plus_di'] - df['minus_di']) / (df['plus_di'] + df['minus_di'] + 1e-10)\n",
    "    df['adx'] = df['dx'].rolling(period).mean()\n",
    "    \n",
    "    return df['adx'], df['plus_di'], df['minus_di']\n",
    "\n",
    "def add_features_v6(df):\n",
    "    \"\"\"V6 Features: V5 + ADX + CCI + Williams %R\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- V5 Time Features ---\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['day_of_week'] = df['time'].dt.dayofweek\n",
    "    df['is_london'] = ((df['hour'] >= 8) & (df['hour'] < 16)).astype(int)\n",
    "    df['is_ny'] = ((df['hour'] >= 13) & (df['hour'] < 21)).astype(int)\n",
    "    \n",
    "    # --- Basic MAs ---\n",
    "    for p in [5, 10, 20, 50, 200]:\n",
    "        df[f'sma_{p}'] = df['close'].rolling(p).mean()\n",
    "        df[f'ema_{p}'] = df['close'].ewm(span=p, adjust=False).mean()\n",
    "    \n",
    "    # --- RSI ---\n",
    "    delta = df['close'].diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / (loss + 1e-10)\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # --- MACD ---\n",
    "    ema12 = df['close'].ewm(span=12).mean()\n",
    "    ema26 = df['close'].ewm(span=26).mean()\n",
    "    df['macd'] = ema12 - ema26\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9).mean()\n",
    "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    \n",
    "    # --- Bollinger Bands ---\n",
    "    df['bb_mid'] = df['close'].rolling(20).mean()\n",
    "    df['bb_std'] = df['close'].rolling(20).std()\n",
    "    df['bb_upper'] = df['bb_mid'] + 2 * df['bb_std']\n",
    "    df['bb_lower'] = df['bb_mid'] - 2 * df['bb_std']\n",
    "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_mid']\n",
    "    \n",
    "    # --- NEW V6 INDICATORS ---\n",
    "    \n",
    "    # 1. ADX (Trend Strength)\n",
    "    df['adx'], df['plus_di'], df['minus_di'] = calculate_adx(df)\n",
    "    df['trend_strength'] = np.where(df['adx'] > 25, 1, 0) # Strong trend\n",
    "    \n",
    "    # 2. CCI (Commodity Channel Index)\n",
    "    tp = (df['high'] + df['low'] + df['close']) / 3\n",
    "    sma_tp = tp.rolling(20).mean()\n",
    "    mad_tp = tp.rolling(20).apply(lambda x: np.abs(x - x.mean()).mean())\n",
    "    df['cci'] = (tp - sma_tp) / (0.015 * mad_tp)\n",
    "    \n",
    "    # 3. Williams %R\n",
    "    hh = df['high'].rolling(14).max()\n",
    "    ll = df['low'].rolling(14).min()\n",
    "    df['williams_r'] = -100 * (hh - df['close']) / (hh - ll + 1e-10)\n",
    "    \n",
    "    # 4. Volatility (Standard Deviation of returns)\n",
    "    df['returns'] = df['close'].pct_change()\n",
    "    df['volatility'] = df['returns'].rolling(20).std() * 100\n",
    "    \n",
    "    # 5. Interaction Features\n",
    "    df['rsi_x_adx'] = df['rsi'] * df['adx'] / 100\n",
    "    df['momentum_score'] = (df['rsi'] > 50).astype(int) + (df['macd'] > df['macd_signal']).astype(int) + (df['plus_di'] > df['minus_di']).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Adding V6 features...\")\n",
    "train_df = add_features_v6(train_df)\n",
    "test_df = add_features_v6(test_df)\n",
    "print(f\"âœ“ Features added. Total columns: {len(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493d491",
   "metadata": {},
   "source": [
    "## 2. Labeling (BUY / SELL / HOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecde840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution (Train):\n",
      "  SELL: 10.7%\n",
      "  HOLD: 78.9%\n",
      "  BUY: 10.4%\n",
      "\n",
      "Label Distribution (Test):\n",
      "  SELL: 12.9%\n",
      "  HOLD: 72.9%\n",
      "  BUY: 14.1%\n"
     ]
    }
   ],
   "source": [
    "def create_labels_v6(df, forward_periods=60, min_pips=15, ratio=1.5):\n",
    "    \"\"\"\n",
    "    3-Class Labeling:\n",
    "    2 (BUY):  Up move >= min_pips AND Up > Down * ratio\n",
    "    0 (SELL): Down move >= min_pips AND Down > Up * ratio\n",
    "    1 (HOLD): Everything else\n",
    "    \n",
    "    Note: Using 0,1,2 instead of -1,0,1 for XGBoost compatibility\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    min_move = min_pips * 0.0001\n",
    "    \n",
    "    # Future Max/Min\n",
    "    df['future_max'] = df['high'].rolling(forward_periods).max().shift(-forward_periods)\n",
    "    df['future_min'] = df['low'].rolling(forward_periods).min().shift(-forward_periods)\n",
    "    \n",
    "    df['up_move'] = df['future_max'] - df['close']\n",
    "    df['down_move'] = df['close'] - df['future_min']\n",
    "    \n",
    "    conditions = [\n",
    "        (df['up_move'] >= min_move) & (df['up_move'] > df['down_move'] * ratio),  # BUY\n",
    "        (df['down_move'] >= min_move) & (df['down_move'] > df['up_move'] * ratio)  # SELL\n",
    "    ]\n",
    "    choices = [2, 0]  # BUY=2, SELL=0, HOLD=1\n",
    "    \n",
    "    df['signal'] = np.select(conditions, choices, default=1)\n",
    "    \n",
    "    # Drop helper columns\n",
    "    df.drop(['future_max', 'future_min', 'up_move', 'down_move'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Label mapping for display\n",
    "LABEL_MAP = {0: 'SELL', 1: 'HOLD', 2: 'BUY'}\n",
    "\n",
    "train_df = create_labels_v6(train_df)\n",
    "test_df = create_labels_v6(test_df)\n",
    "\n",
    "print(\"Label Distribution (Train):\")\n",
    "for val, name in LABEL_MAP.items():\n",
    "    pct = (train_df['signal'] == val).mean() * 100\n",
    "    print(f\"  {name}: {pct:.1f}%\")\n",
    "\n",
    "print(\"\\nLabel Distribution (Test):\")\n",
    "for val, name in LABEL_MAP.items():\n",
    "    pct = (test_df['signal'] == val).mean() * 100\n",
    "    print(f\"  {name}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372877a1",
   "metadata": {},
   "source": [
    "## 3. Training 5-Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc786556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1,858,074 samples with 33 features\n",
      "Classes: [0 1 2]\n",
      "GPU Available: True\n",
      "GPU Available: True\n",
      "\n",
      "ðŸš€ Starting Training...\n",
      "  Training XGB1... \n",
      "ðŸš€ Starting Training...\n",
      "  Training XGB1... âœ“ Accuracy: 73.41%\n",
      "  Training XGB2... âœ“ Accuracy: 73.41%\n",
      "  Training XGB2... âœ“ Accuracy: 73.24%\n",
      "  Training LGB1... âœ“ Accuracy: 73.24%\n",
      "  Training LGB1... âœ“ Accuracy: 73.42%\n",
      "  Training LGB2... âœ“ Accuracy: 73.42%\n",
      "  Training LGB2... âœ“ Accuracy: 73.44%\n",
      "  Training CAT... âœ“ Accuracy: 73.44%\n",
      "  Training CAT... âœ“ Accuracy: 73.43%\n",
      "âœ“ Accuracy: 73.43%\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "exclude_cols = ['time', 'signal', 'open', 'high', 'low', 'close', 'volume', 'tick_volume']\n",
    "feature_cols = [c for c in train_df.columns if c not in exclude_cols]\n",
    "\n",
    "# Filter for training (remove NaNs)\n",
    "train_clean = train_df.dropna(subset=feature_cols + ['signal']).copy()\n",
    "test_clean = test_df.dropna(subset=feature_cols + ['signal']).copy()\n",
    "\n",
    "# We train on ALL data (0, 1, 2) to learn to distinguish HOLD from signals\n",
    "X_train = train_clean[feature_cols].values\n",
    "y_train = train_clean['signal'].values.astype(int)\n",
    "X_test = test_clean[feature_cols].values\n",
    "y_test = test_clean['signal'].values.astype(int)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training on {len(X_train):,} samples with {len(feature_cols)} features\")\n",
    "print(f\"Classes: {np.unique(y_train)}\")\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "print(f\"GPU Available: {GPU_AVAILABLE}\")\n",
    "\n",
    "# Install CatBoost if needed\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CATBOOST_AVAILABLE = False\n",
    "    print(\"CatBoost not installed. Run: pip install catboost\")\n",
    "\n",
    "# --- Define Models (ALL GPU enabled) ---\n",
    "models = {}\n",
    "\n",
    "# 1. XGBoost (GPU) - Default config\n",
    "models['xgb1'] = xgb.XGBClassifier(\n",
    "    n_estimators=500, max_depth=8, learning_rate=0.05, \n",
    "    subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
    "    tree_method='hist', device='cuda', verbosity=0\n",
    ")\n",
    "\n",
    "# 2. XGBoost (GPU) - Deeper trees\n",
    "models['xgb2'] = xgb.XGBClassifier(\n",
    "    n_estimators=400, max_depth=12, learning_rate=0.03, \n",
    "    subsample=0.7, colsample_bytree=0.7, random_state=43,\n",
    "    tree_method='hist', device='cuda', verbosity=0,\n",
    "    reg_alpha=0.1, reg_lambda=1.0\n",
    ")\n",
    "\n",
    "# 3. LightGBM (GPU) - Default config\n",
    "models['lgb1'] = lgb.LGBMClassifier(\n",
    "    n_estimators=500, max_depth=8, learning_rate=0.05,\n",
    "    subsample=0.8, colsample_bytree=0.8, random_state=42, \n",
    "    verbose=-1, device='gpu'\n",
    ")\n",
    "\n",
    "# 4. LightGBM (GPU) - More trees, less depth\n",
    "models['lgb2'] = lgb.LGBMClassifier(\n",
    "    n_estimators=700, max_depth=6, learning_rate=0.03,\n",
    "    subsample=0.75, colsample_bytree=0.75, random_state=44, \n",
    "    verbose=-1, device='gpu',\n",
    "    num_leaves=63, min_child_samples=20\n",
    ")\n",
    "\n",
    "# 5. CatBoost (GPU) - Robust gradient boosting\n",
    "if CATBOOST_AVAILABLE:\n",
    "    models['cat'] = CatBoostClassifier(\n",
    "        iterations=500, depth=8, learning_rate=0.05,\n",
    "        random_seed=42, task_type='GPU', devices='0',\n",
    "        verbose=False, loss_function='MultiClass'\n",
    "    )\n",
    "\n",
    "# --- Train Loop ---\n",
    "predictions = {}\n",
    "probabilities = {}\n",
    "\n",
    "print(\"\\nðŸš€ Starting Training...\")\n",
    "for name, model in models.items():\n",
    "    print(f\"  Training {name.upper()}...\", end=\" \")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    predictions[name] = model.predict(X_test_scaled)\n",
    "    probabilities[name] = model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    acc = accuracy_score(y_test, predictions[name])\n",
    "    print(f\"âœ“ Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea50243",
   "metadata": {},
   "source": [
    "## 4. Ensemble & Directional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1beec3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Classes: [0 1 2]\n",
      "============================================================\n",
      "ðŸ“Š ENSEMBLE V6 RESULTS\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        SELL       0.35      0.10      0.16     38401\n",
      "        HOLD       0.76      0.97      0.85    216283\n",
      "         BUY       0.37      0.07      0.12     41895\n",
      "\n",
      "    accuracy                           0.73    296579\n",
      "   macro avg       0.50      0.38      0.38    296579\n",
      "weighted avg       0.65      0.73      0.66    296579\n",
      "\n",
      "\n",
      "ðŸ” DIRECTIONAL PERFORMANCE (BUY vs SELL)\n",
      "------------------------------------------------------------\n",
      "BUY Signals:   8277 | Accuracy:  37.33%\n",
      "SELL Signals: 11252 | Accuracy:  35.22%\n",
      "\n",
      "ðŸ’¡ RECOMMENDATION:\n",
      "   âš ï¸ Both sides have low base accuracy. Rely on High Confidence Thresholds.\n"
     ]
    }
   ],
   "source": [
    "# Weighted Soft Voting (5 GPU models)\n",
    "# XGB1, XGB2, LGB1, LGB2, CatBoost\n",
    "if CATBOOST_AVAILABLE:\n",
    "    weights = {'xgb1': 0.20, 'xgb2': 0.20, 'lgb1': 0.20, 'lgb2': 0.20, 'cat': 0.20}\n",
    "else:\n",
    "    weights = {'xgb1': 0.25, 'xgb2': 0.25, 'lgb1': 0.25, 'lgb2': 0.25}\n",
    "\n",
    "# Combine Probabilities\n",
    "# Classes: 0=SELL, 1=HOLD, 2=BUY\n",
    "print(f\"Model Classes: {models['xgb1'].classes_}\")\n",
    "\n",
    "final_proba = np.zeros_like(probabilities['xgb1'])\n",
    "for name, w in weights.items():\n",
    "    final_proba += w * probabilities[name]\n",
    "\n",
    "# Get Predictions\n",
    "final_pred = models['xgb1'].classes_[np.argmax(final_proba, axis=1)]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“Š ENSEMBLE V6 RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, final_pred, target_names=['SELL', 'HOLD', 'BUY']))\n",
    "\n",
    "# --- Directional Analysis ---\n",
    "print(\"\\nðŸ” DIRECTIONAL PERFORMANCE (BUY vs SELL)\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# BUY Analysis (Class 2)\n",
    "buy_mask = (final_pred == 2)\n",
    "buy_total = buy_mask.sum()\n",
    "buy_correct = (y_test[buy_mask] == 2).sum()\n",
    "buy_acc = buy_correct / buy_total * 100 if buy_total > 0 else 0\n",
    "\n",
    "# SELL Analysis (Class 0)\n",
    "sell_mask = (final_pred == 0)\n",
    "sell_total = sell_mask.sum()\n",
    "sell_correct = (y_test[sell_mask] == 0).sum()\n",
    "sell_acc = sell_correct / sell_total * 100 if sell_total > 0 else 0\n",
    "\n",
    "print(f\"BUY Signals:  {buy_total:>5} | Accuracy: {buy_acc:>6.2f}%\")\n",
    "print(f\"SELL Signals: {sell_total:>5} | Accuracy: {sell_acc:>6.2f}%\")\n",
    "\n",
    "# Recommendation\n",
    "print(\"\\nðŸ’¡ RECOMMENDATION:\")\n",
    "if buy_acc > 55 and sell_acc > 55:\n",
    "    print(\"   âœ… Use BOTH BUY and SELL signals.\")\n",
    "elif buy_acc > 55 and sell_acc < 50:\n",
    "    print(\"   âš ï¸ SELL accuracy is low. Use BUY-ONLY mode.\")\n",
    "elif sell_acc > 55 and buy_acc < 50:\n",
    "    print(\"   âš ï¸ BUY accuracy is low. Use SELL-ONLY mode.\")\n",
    "else:\n",
    "    print(\"   âš ï¸ Both sides have low base accuracy. Rely on High Confidence Thresholds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b773cf2",
   "metadata": {},
   "source": [
    "## 5. High Confidence Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60f2e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸ“Š ACCURACY BY CONFIDENCE THRESHOLD\n",
      "======================================================================\n",
      " Conf |  Type |  Signals |  Correct | Accuracy\n",
      "----------------------------------------------------------------------\n",
      "   50% |   BUY |      371 |      154 |     41.5%\n",
      "   50% |  SELL |      926 |      371 |     40.1%\n",
      "   60% |   BUY |       17 |        5 |     29.4%\n",
      "   60% |  SELL |      129 |       37 |     28.7%\n",
      "   70% |  SELL |       25 |        1 |      4.0%\n",
      "   75% |  SELL |        9 |        0 |      0.0%\n",
      "   80% |  SELL |        2 |        0 |      0.0%\n",
      "----------------------------------------------------------------------\n",
      "ðŸ† Best Configuration: {'threshold': 50, 'mode': 'BUY_ONLY'}\n"
     ]
    }
   ],
   "source": [
    "# Get probability for predicted class\n",
    "max_proba = np.max(final_proba, axis=1) * 100\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“Š ACCURACY BY CONFIDENCE THRESHOLD\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Conf':>5} | {'Type':>5} | {'Signals':>8} | {'Correct':>8} | {'Accuracy':>8}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "best_config = {'threshold': 0, 'mode': 'BOTH'}\n",
    "best_acc = 0\n",
    "\n",
    "for conf in [50, 60, 70, 75, 80, 85, 90]:\n",
    "    # BUY (class 2)\n",
    "    mask_b = (final_pred == 2) & (max_proba >= conf)\n",
    "    sig_b = mask_b.sum()\n",
    "    acc_b = (y_test[mask_b] == 2).mean() * 100 if sig_b > 0 else 0\n",
    "    \n",
    "    # SELL (class 0)\n",
    "    mask_s = (final_pred == 0) & (max_proba >= conf)\n",
    "    sig_s = mask_s.sum()\n",
    "    acc_s = (y_test[mask_s] == 0).mean() * 100 if sig_s > 0 else 0\n",
    "    \n",
    "    if sig_b > 0: print(f\"{conf:>5}% | {'BUY':>5} | {sig_b:>8} | {int(sig_b*acc_b/100):>8} | {acc_b:>8.1f}%\")\n",
    "    if sig_s > 0: print(f\"{conf:>5}% | {'SELL':>5} | {sig_s:>8} | {int(sig_s*acc_s/100):>8} | {acc_s:>8.1f}%\")\n",
    "    \n",
    "    # Track best\n",
    "    if acc_b > best_acc and sig_b > 10:\n",
    "        best_acc = acc_b\n",
    "        best_config = {'threshold': conf, 'mode': 'BUY_ONLY'}\n",
    "    if acc_s > best_acc and sig_s > 10:\n",
    "        best_acc = acc_s\n",
    "        best_config = {'threshold': conf, 'mode': 'SELL_ONLY'}\n",
    "    if acc_b > 55 and acc_s > 55 and (acc_b + acc_s)/2 > best_acc:\n",
    "        best_acc = (acc_b + acc_s)/2\n",
    "        best_config = {'threshold': conf, 'mode': 'BOTH'}\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(f\"ðŸ† Best Configuration: {best_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Models\n",
    "print(\"Saving V6 Ensemble...\")\n",
    "for name, model in models.items():\n",
    "    joblib.dump(model, MODEL_DIR / f'{name}_v6.joblib')\n",
    "\n",
    "joblib.dump(scaler, MODEL_DIR / 'scaler_v6.joblib')\n",
    "joblib.dump(feature_cols, MODEL_DIR / 'feature_cols_v6.joblib')\n",
    "joblib.dump(best_config, MODEL_DIR / 'config_v6.joblib')\n",
    "\n",
    "print(\"âœ… V6 Models Saved Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645d99f",
   "metadata": {},
   "source": [
    "## 6. V6 Alternative: BUY vs SELL Only (Like V5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfdbfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸ”„ V6 BINARY: BUY vs SELL Only (HOLD Ñ…Ð°ÑÑÐ°Ð½)\n",
      "======================================================================\n",
      "Train: 393,219 samples (BUY/SELL only)\n",
      "Test: 80,296 samples\n",
      "BUY ratio (train): 49.3%\n",
      "BUY ratio (test): 52.2%\n",
      "\n",
      "ðŸš€ Training Binary Models (GPU)...\n",
      "  Training XGB1... Train: 393,219 samples (BUY/SELL only)\n",
      "Test: 80,296 samples\n",
      "BUY ratio (train): 49.3%\n",
      "BUY ratio (test): 52.2%\n",
      "\n",
      "ðŸš€ Training Binary Models (GPU)...\n",
      "  Training XGB1... âœ“ Accuracy: 49.75%\n",
      "  Training XGB2... âœ“ Accuracy: 49.75%\n",
      "  Training XGB2... âœ“ Accuracy: 49.66%\n",
      "  Training LGB1... âœ“ Accuracy: 49.66%\n",
      "  Training LGB1... âœ“ Accuracy: 49.14%\n",
      "  Training LGB2... âœ“ Accuracy: 49.14%\n",
      "  Training LGB2... âœ“ Accuracy: 49.50%\n",
      "  Training CAT... âœ“ Accuracy: 49.50%\n",
      "  Training CAT... âœ“ Accuracy: 50.40%\n",
      "âœ“ Accuracy: 50.40%\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# V6 BINARY: BUY vs SELL ONLY (HOLD-Ð³ Ñ…Ð°ÑÑÐ°Ð½)\n",
    "# V5-Ñ‚Ð°Ð¹ Ð¸Ð¶Ð¸Ð» Ð°Ñ€Ð³Ð° - Ð¸Ð»Ò¯Ò¯ ÑÐ°Ð¹Ð½ Ò¯Ñ€ Ð´Ò¯Ð½ Ð³Ð°Ñ€Ð½Ð°\n",
    "# ================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ”„ V6 BINARY: BUY vs SELL Only (HOLD Ñ…Ð°ÑÑÐ°Ð½)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Filter BUY/SELL only (remove HOLD = class 1)\n",
    "train_binary = train_clean[train_clean['signal'] != 1].copy()\n",
    "test_binary = test_clean[test_clean['signal'] != 1].copy()\n",
    "\n",
    "# Convert labels: SELL=0, BUY=1 (was SELL=0, BUY=2)\n",
    "train_binary['signal_bin'] = (train_binary['signal'] == 2).astype(int)\n",
    "test_binary['signal_bin'] = (test_binary['signal'] == 2).astype(int)\n",
    "\n",
    "X_train_bin = train_binary[feature_cols].values\n",
    "y_train_bin = train_binary['signal_bin'].values\n",
    "X_test_bin = test_binary[feature_cols].values\n",
    "y_test_bin = test_binary['signal_bin'].values\n",
    "\n",
    "# Scale\n",
    "scaler_bin = StandardScaler()\n",
    "X_train_bin_scaled = scaler_bin.fit_transform(X_train_bin)\n",
    "X_test_bin_scaled = scaler_bin.transform(X_test_bin)\n",
    "\n",
    "print(f\"Train: {len(X_train_bin):,} samples (BUY/SELL only)\")\n",
    "print(f\"Test: {len(X_test_bin):,} samples\")\n",
    "print(f\"BUY ratio (train): {y_train_bin.mean()*100:.1f}%\")\n",
    "print(f\"BUY ratio (test): {y_test_bin.mean()*100:.1f}%\")\n",
    "\n",
    "# --- Train GPU Models (Binary Classification) ---\n",
    "models_bin = {}\n",
    "\n",
    "# 1. XGBoost (GPU)\n",
    "models_bin['xgb1'] = xgb.XGBClassifier(\n",
    "    n_estimators=500, max_depth=8, learning_rate=0.05, \n",
    "    subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
    "    tree_method='hist', device='cuda', verbosity=0\n",
    ")\n",
    "\n",
    "# 2. XGBoost (GPU) - Deeper\n",
    "models_bin['xgb2'] = xgb.XGBClassifier(\n",
    "    n_estimators=400, max_depth=12, learning_rate=0.03, \n",
    "    subsample=0.7, colsample_bytree=0.7, random_state=43,\n",
    "    tree_method='hist', device='cuda', verbosity=0,\n",
    "    reg_alpha=0.1, reg_lambda=1.0\n",
    ")\n",
    "\n",
    "# 3. LightGBM (GPU)\n",
    "models_bin['lgb1'] = lgb.LGBMClassifier(\n",
    "    n_estimators=500, max_depth=8, learning_rate=0.05,\n",
    "    subsample=0.8, colsample_bytree=0.8, random_state=42, \n",
    "    verbose=-1, device='gpu'\n",
    ")\n",
    "\n",
    "# 4. LightGBM (GPU) - Different config\n",
    "models_bin['lgb2'] = lgb.LGBMClassifier(\n",
    "    n_estimators=700, max_depth=6, learning_rate=0.03,\n",
    "    subsample=0.75, colsample_bytree=0.75, random_state=44, \n",
    "    verbose=-1, device='gpu', num_leaves=63\n",
    ")\n",
    "\n",
    "# 5. CatBoost (GPU)\n",
    "models_bin['cat'] = CatBoostClassifier(\n",
    "    iterations=500, depth=8, learning_rate=0.05,\n",
    "    random_seed=42, task_type='GPU', devices='0',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Train\n",
    "predictions_bin = {}\n",
    "probabilities_bin = {}\n",
    "\n",
    "print(\"\\nðŸš€ Training Binary Models (GPU)...\")\n",
    "for name, model in models_bin.items():\n",
    "    print(f\"  Training {name.upper()}...\", end=\" \")\n",
    "    model.fit(X_train_bin_scaled, y_train_bin)\n",
    "    predictions_bin[name] = model.predict(X_test_bin_scaled)\n",
    "    probabilities_bin[name] = model.predict_proba(X_test_bin_scaled)\n",
    "    acc = accuracy_score(y_test_bin, predictions_bin[name])\n",
    "    print(f\"âœ“ Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d04cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸ“Š V6 BINARY ENSEMBLE (BUY vs SELL)\n",
      "======================================================================\n",
      "\n",
      "Model Agreement on BUY: 21,377 signals\n",
      "\n",
      "ðŸ“Š BUY Signal Accuracy by Confidence:\n",
      "------------------------------------------------------------\n",
      "  Confidence |    Signals |    Correct |   Accuracy\n",
      "------------------------------------------------------------\n",
      "        50%+ |      40122 |      20818 |      51.9%\n",
      "        60%+ |      19827 |      10351 |      52.2%\n",
      "        70%+ |       4542 |       2482 |      54.6%\n",
      "        75%+ |       1436 |        789 |      54.9%\n",
      "        80%+ |        423 |        241 |      57.0%\n",
      "        85%+ |        114 |         71 |      62.3%\n",
      "        90%+ |         16 |         10 |      62.5%\n",
      "\n",
      "ðŸ“Š SELL Signal Accuracy by Confidence:\n",
      "------------------------------------------------------------\n",
      "        50%+ |      40174 |      19097 |      47.5%\n",
      "        60%+ |      11145 |       5248 |      47.1%\n",
      "        70%+ |       1287 |        616 |      47.9%\n",
      "        75%+ |        392 |        166 |      42.3%\n",
      "        80%+ |        119 |         42 |      35.3%\n",
      "        85%+ |         18 |          7 |      38.9%\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# V6 BINARY ENSEMBLE RESULTS\n",
    "# ================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“Š V6 BINARY ENSEMBLE (BUY vs SELL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Weighted Ensemble\n",
    "weights_bin = {'xgb1': 0.20, 'xgb2': 0.20, 'lgb1': 0.20, 'lgb2': 0.20, 'cat': 0.20}\n",
    "\n",
    "final_proba_bin = np.zeros_like(probabilities_bin['xgb1'])\n",
    "for name, w in weights_bin.items():\n",
    "    final_proba_bin += w * probabilities_bin[name]\n",
    "\n",
    "buy_prob = final_proba_bin[:, 1] * 100\n",
    "\n",
    "# Model agreement bonus\n",
    "all_agree_buy = np.all([predictions_bin[name] == 1 for name in models_bin.keys()], axis=0)\n",
    "confidence_bin = buy_prob.copy()\n",
    "confidence_bin[all_agree_buy] = np.minimum(confidence_bin[all_agree_buy] + 5, 100)\n",
    "\n",
    "print(f\"\\nModel Agreement on BUY: {all_agree_buy.sum():,} signals\")\n",
    "\n",
    "# Results by Confidence\n",
    "print(\"\\nðŸ“Š BUY Signal Accuracy by Confidence:\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Confidence':>12} | {'Signals':>10} | {'Correct':>10} | {'Accuracy':>10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "v6_results = {}\n",
    "for conf in [50, 60, 70, 75, 80, 85, 90]:\n",
    "    mask = confidence_bin >= conf\n",
    "    if mask.sum() > 0:\n",
    "        signals = mask.sum()\n",
    "        correct = y_test_bin[mask].sum()\n",
    "        acc = correct / signals * 100\n",
    "        v6_results[conf] = {'signals': signals, 'correct': correct, 'accuracy': acc}\n",
    "        print(f\"{conf:>10}%+ | {signals:>10} | {correct:>10} | {acc:>9.1f}%\")\n",
    "\n",
    "# SELL (low confidence = SELL signal)\n",
    "print(\"\\nðŸ“Š SELL Signal Accuracy by Confidence:\")\n",
    "print(\"-\"*60)\n",
    "for conf in [50, 60, 70, 75, 80, 85, 90]:\n",
    "    sell_conf = 100 - confidence_bin  # Invert for SELL\n",
    "    mask = sell_conf >= conf\n",
    "    if mask.sum() > 0:\n",
    "        signals = mask.sum()\n",
    "        correct = (y_test_bin[mask] == 0).sum()  # SELL = 0\n",
    "        acc = correct / signals * 100\n",
    "        print(f\"{conf:>10}%+ | {signals:>10} | {correct:>10} | {acc:>9.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c828b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸ“Š V6 vs V5 COMPARISON\n",
      "======================================================================\n",
      "\n",
      "   Threshold | V5 Signals |   V5 Acc | V6 Signals |   V6 Acc |   Winner\n",
      "---------------------------------------------------------------------------\n",
      "        70%+ |          0 |     0.0% |       4522 |    55.4% |     V6 âœ“\n",
      "        75%+ |          0 |     0.0% |       1415 |    56.6% |     V6 âœ“\n",
      "        80%+ |          0 |     0.0% |        410 |    58.3% |     V6 âœ“\n",
      "        85%+ |          0 |     0.0% |        106 |    64.2% |     V6 âœ“\n",
      "        90%+ |          0 |     0.0% |         21 |    76.2% |     V6 âœ“\n",
      "\n",
      "   Threshold | V5 Signals |   V5 Acc | V6 Signals |   V6 Acc |   Winner\n",
      "---------------------------------------------------------------------------\n",
      "        70%+ |          0 |     0.0% |       4522 |    55.4% |     V6 âœ“\n",
      "        75%+ |          0 |     0.0% |       1415 |    56.6% |     V6 âœ“\n",
      "        80%+ |          0 |     0.0% |        410 |    58.3% |     V6 âœ“\n",
      "        85%+ |          0 |     0.0% |        106 |    64.2% |     V6 âœ“\n",
      "        90%+ |          0 |     0.0% |         21 |    76.2% |     V6 âœ“\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# V6 vs V5 COMPARISON\n",
    "# ================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“Š V6 vs V5 COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load V5 models for comparison\n",
    "v5_dir = BASE_DIR / 'models' / 'signal_generator_v5'\n",
    "try:\n",
    "    v5_xgb = joblib.load(v5_dir / 'xgboost_v5.joblib')\n",
    "    v5_lgb = joblib.load(v5_dir / 'lightgbm_v5.joblib')\n",
    "    v5_rf = joblib.load(v5_dir / 'rf_v5.joblib')\n",
    "    v5_scaler = joblib.load(v5_dir / 'scaler_v5.joblib')\n",
    "    v5_feature_cols = joblib.load(v5_dir / 'feature_cols_v5.joblib')\n",
    "    \n",
    "    # Check missing features for V5\n",
    "    missing = [c for c in v5_feature_cols if c not in test_binary.columns]\n",
    "    for c in missing:\n",
    "        test_binary[c] = 0\n",
    "    \n",
    "    X_test_v5 = test_binary[v5_feature_cols].values\n",
    "    X_test_v5_scaled = v5_scaler.transform(X_test_v5)\n",
    "    \n",
    "    # V5 predictions\n",
    "    v5_xgb_proba = v5_xgb.predict_proba(X_test_v5_scaled)\n",
    "    v5_lgb_proba = v5_lgb.predict_proba(X_test_v5_scaled)\n",
    "    v5_rf_proba = v5_rf.predict_proba(X_test_v5_scaled)\n",
    "    \n",
    "    v5_weights = [0.4, 0.35, 0.25]\n",
    "    v5_proba = v5_weights[0] * v5_xgb_proba + v5_weights[1] * v5_lgb_proba + v5_weights[2] * v5_rf_proba\n",
    "    v5_buy_prob = v5_proba[:, 1] * 100\n",
    "    \n",
    "    # Agreement bonus\n",
    "    v5_pred = [(p[:, 1] > 0.5).astype(int) for p in [v5_xgb_proba, v5_lgb_proba, v5_rf_proba]]\n",
    "    v5_agree = (v5_pred[0] == 1) & (v5_pred[1] == 1) & (v5_pred[2] == 1)\n",
    "    v5_conf = v5_buy_prob.copy()\n",
    "    v5_conf[v5_agree] = np.minimum(v5_conf[v5_agree] + 5, 100)\n",
    "    \n",
    "    print(f\"\\n{'Threshold':>12} | {'V5 Signals':>10} | {'V5 Acc':>8} | {'V6 Signals':>10} | {'V6 Acc':>8} | {'Winner':>8}\")\n",
    "    print(\"-\"*75)\n",
    "    \n",
    "    for conf in [70, 75, 80, 85, 90]:\n",
    "        # V5\n",
    "        v5_mask = v5_conf >= conf\n",
    "        v5_sig = v5_mask.sum()\n",
    "        v5_acc = y_test_bin[v5_mask].mean() * 100 if v5_sig > 0 else 0\n",
    "        \n",
    "        # V6\n",
    "        v6_mask = confidence_bin >= conf\n",
    "        v6_sig = v6_mask.sum()\n",
    "        v6_acc = y_test_bin[v6_mask].mean() * 100 if v6_sig > 0 else 0\n",
    "        \n",
    "        winner = \"V6 âœ“\" if v6_acc > v5_acc else (\"V5 âœ“\" if v5_acc > v6_acc else \"TIE\")\n",
    "        print(f\"{conf:>10}%+ | {v5_sig:>10} | {v5_acc:>7.1f}% | {v6_sig:>10} | {v6_acc:>7.1f}% | {winner:>8}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"V5 comparison error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e9120d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving V6 Binary Models...\n",
      "âœ… V6 Binary Models Saved!\n",
      "   Location: c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v6\n",
      "âœ… V6 Binary Models Saved!\n",
      "   Location: c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v6\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# SAVE V6 BINARY MODELS\n",
    "# ================================================================\n",
    "print(\"Saving V6 Binary Models...\")\n",
    "\n",
    "for name, model in models_bin.items():\n",
    "    joblib.dump(model, MODEL_DIR / f'{name}_v6_bin.joblib')\n",
    "\n",
    "joblib.dump(scaler_bin, MODEL_DIR / 'scaler_v6_bin.joblib')\n",
    "joblib.dump(feature_cols, MODEL_DIR / 'feature_cols_v6.joblib')\n",
    "joblib.dump(weights_bin, MODEL_DIR / 'weights_v6.joblib')\n",
    "\n",
    "# Best config\n",
    "best_v6 = {'threshold': 75, 'mode': 'BINARY_BUY_SELL', 'models': list(models_bin.keys())}\n",
    "joblib.dump(best_v6, MODEL_DIR / 'config_v6.joblib')\n",
    "\n",
    "print(\"âœ… V6 Binary Models Saved!\")\n",
    "print(f\"   Location: {MODEL_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
