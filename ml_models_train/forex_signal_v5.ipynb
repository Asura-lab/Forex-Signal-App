{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bac5256c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸš€ FOREX SIGNAL GENERATOR V5\n",
      "   Calibrated Probabilities + Time Features\n",
      "============================================================\n",
      "âœ“ Libraries loaded\n",
      "âœ“ GPU Available: True\n",
      "âœ“ Models Directory: c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "# GPU check\n",
    "import torch\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "MODEL_DIR = BASE_DIR / 'models' / 'signal_generator_v5'\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸš€ FOREX SIGNAL GENERATOR V5\")\n",
    "print(\"   Calibrated Probabilities + Time Features\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ Libraries loaded\")\n",
    "print(f\"âœ“ GPU Available: {GPU_AVAILABLE}\")\n",
    "print(f\"âœ“ Models Directory: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ddfd4a",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbce2e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 1,859,492 rows\n",
      "Test data: 296,778 rows\n",
      "\n",
      "Train period: 2019-12-31 16:00:00+00:00 to 2024-12-30 16:00:00+00:00\n",
      "Test period: 2024-12-31 16:00:00+00:00 to 2025-10-17 06:11:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(DATA_DIR / 'EUR_USD_1min.csv')\n",
    "test_df = pd.read_csv(DATA_DIR / 'EUR_USD_test.csv')\n",
    "\n",
    "# Rename timestamp to time if needed\n",
    "if 'timestamp' in train_df.columns:\n",
    "    train_df.rename(columns={'timestamp': 'time'}, inplace=True)\n",
    "if 'timestamp' in test_df.columns:\n",
    "    test_df.rename(columns={'timestamp': 'time'}, inplace=True)\n",
    "\n",
    "# Convert time to datetime\n",
    "train_df['time'] = pd.to_datetime(train_df['time'])\n",
    "test_df['time'] = pd.to_datetime(test_df['time'])\n",
    "\n",
    "print(f\"Train data: {len(train_df):,} rows\")\n",
    "print(f\"Test data: {len(test_df):,} rows\")\n",
    "print(f\"\\nTrain period: {train_df['time'].min()} to {train_df['time'].max()}\")\n",
    "print(f\"Test period: {test_df['time'].min()} to {test_df['time'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea4841",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering (V2 Base + V5 Enhancements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5141533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding V5 features...\n",
      "âœ“ Features added: 83 columns\n",
      "âœ“ Features added: 83 columns\n"
     ]
    }
   ],
   "source": [
    "def add_features_v5(df):\n",
    "    \"\"\"V5 Features = V2 Core Features + Time Features + Enhanced Momentum\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ==================== TIME FEATURES (NEW in V5) ====================\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['day_of_week'] = df['time'].dt.dayofweek\n",
    "    \n",
    "    # Trading Sessions (UTC)\n",
    "    # Asian: 00:00-08:00, London: 08:00-16:00, NY: 13:00-21:00\n",
    "    df['is_asian'] = ((df['hour'] >= 0) & (df['hour'] < 8)).astype(int)\n",
    "    df['is_london'] = ((df['hour'] >= 8) & (df['hour'] < 16)).astype(int)\n",
    "    df['is_ny'] = ((df['hour'] >= 13) & (df['hour'] < 21)).astype(int)\n",
    "    df['is_overlap'] = ((df['hour'] >= 13) & (df['hour'] < 16)).astype(int)  # London-NY overlap\n",
    "    \n",
    "    # Avoid low liquidity times\n",
    "    df['is_low_liquidity'] = ((df['hour'] >= 21) | (df['hour'] < 2)).astype(int)\n",
    "    \n",
    "    # ==================== V2 CORE FEATURES ====================\n",
    "    # Moving Averages\n",
    "    for period in [5, 10, 20, 50, 100, 200]:\n",
    "        df[f'sma_{period}'] = df['close'].rolling(period).mean()\n",
    "        df[f'ema_{period}'] = df['close'].ewm(span=period, adjust=False).mean()\n",
    "    \n",
    "    # MA Crossovers\n",
    "    df['sma_5_20_cross'] = (df['sma_5'] > df['sma_20']).astype(int)\n",
    "    df['sma_20_50_cross'] = (df['sma_20'] > df['sma_50']).astype(int)\n",
    "    df['ema_10_50_cross'] = (df['ema_10'] > df['ema_50']).astype(int)\n",
    "    df['golden_cross'] = (df['sma_50'] > df['sma_200']).astype(int)\n",
    "    \n",
    "    # Price vs MAs\n",
    "    df['price_vs_sma20'] = (df['close'] - df['sma_20']) / df['sma_20'] * 100\n",
    "    df['price_vs_sma50'] = (df['close'] - df['sma_50']) / df['sma_50'] * 100\n",
    "    df['price_above_all_ma'] = ((df['close'] > df['sma_20']) & \n",
    "                                 (df['close'] > df['sma_50']) & \n",
    "                                 (df['close'] > df['ema_20'])).astype(int)\n",
    "    \n",
    "    # RSI\n",
    "    for period in [7, 14, 21]:\n",
    "        delta = df['close'].diff()\n",
    "        gain = delta.where(delta > 0, 0).rolling(period).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(period).mean()\n",
    "        rs = gain / (loss + 1e-10)\n",
    "        df[f'rsi_{period}'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    df['rsi_oversold'] = (df['rsi_14'] < 30).astype(int)\n",
    "    df['rsi_bullish'] = ((df['rsi_14'] > 50) & (df['rsi_14'] < 70)).astype(int)\n",
    "    \n",
    "    # MACD\n",
    "    ema12 = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    df['macd'] = ema12 - ema26\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
    "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    df['macd_cross'] = (df['macd'] > df['macd_signal']).astype(int)\n",
    "    df['macd_bullish'] = ((df['macd'] > df['macd_signal']) & (df['macd_hist'] > 0)).astype(int)\n",
    "    \n",
    "    # Stochastic\n",
    "    for period in [14, 21]:\n",
    "        low_min = df['low'].rolling(period).min()\n",
    "        high_max = df['high'].rolling(period).max()\n",
    "        df[f'stoch_k_{period}'] = 100 * (df['close'] - low_min) / (high_max - low_min + 1e-10)\n",
    "        df[f'stoch_d_{period}'] = df[f'stoch_k_{period}'].rolling(3).mean()\n",
    "    \n",
    "    df['stoch_oversold'] = (df['stoch_k_14'] < 20).astype(int)\n",
    "    df['stoch_bullish'] = ((df['stoch_k_14'] > df['stoch_d_14']) & (df['stoch_k_14'] < 80)).astype(int)\n",
    "    \n",
    "    # ATR\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = abs(df['high'] - df['close'].shift())\n",
    "    low_close = abs(df['low'] - df['close'].shift())\n",
    "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    df['atr_14'] = tr.rolling(14).mean()\n",
    "    df['atr_pips'] = df['atr_14'] * 10000\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['bb_middle'] = df['close'].rolling(20).mean()\n",
    "    bb_std = df['close'].rolling(20).std()\n",
    "    df['bb_upper'] = df['bb_middle'] + 2 * bb_std\n",
    "    df['bb_lower'] = df['bb_middle'] - 2 * bb_std\n",
    "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle'] * 100\n",
    "    df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-10)\n",
    "    df['bb_squeeze'] = (df['bb_width'] < df['bb_width'].rolling(50).mean()).astype(int)\n",
    "    \n",
    "    # Candle Patterns\n",
    "    df['candle_body'] = df['close'] - df['open']\n",
    "    df['candle_range'] = df['high'] - df['low']\n",
    "    df['candle_body_pct'] = df['candle_body'] / (df['candle_range'] + 1e-10)\n",
    "    df['upper_shadow'] = df['high'] - df[['open', 'close']].max(axis=1)\n",
    "    df['lower_shadow'] = df[['open', 'close']].min(axis=1) - df['low']\n",
    "    df['is_bullish'] = (df['close'] > df['open']).astype(int)\n",
    "    df['is_hammer'] = ((df['lower_shadow'] > df['candle_body'].abs() * 2) & \n",
    "                       (df['upper_shadow'] < df['candle_body'].abs() * 0.5)).astype(int)\n",
    "    df['bullish_engulfing'] = ((df['is_bullish'] == 1) & \n",
    "                               (df['is_bullish'].shift(1) == 0) &\n",
    "                               (df['close'] > df['open'].shift(1))).astype(int)\n",
    "    \n",
    "    # Pivot Points\n",
    "    df['pivot'] = (df['high'].shift() + df['low'].shift() + df['close'].shift()) / 3\n",
    "    df['r1'] = 2 * df['pivot'] - df['low'].shift()\n",
    "    df['s1'] = 2 * df['pivot'] - df['high'].shift()\n",
    "    df['near_support'] = (df['close'] < df['s1'] * 1.001).astype(int)\n",
    "    \n",
    "    # Trend Strength\n",
    "    df['trend_short'] = np.where(df['ema_10'] > df['ema_20'], 1, -1)\n",
    "    df['trend_medium'] = np.where(df['ema_20'] > df['ema_50'], 1, -1)\n",
    "    df['trend_long'] = np.where(df['ema_50'] > df['ema_200'], 1, -1)\n",
    "    df['trend_alignment'] = df['trend_short'] + df['trend_medium'] + df['trend_long']\n",
    "    df['strong_uptrend'] = (df['trend_alignment'] == 3).astype(int)\n",
    "    \n",
    "    # ==================== V5 ENHANCED FEATURES ====================\n",
    "    # Momentum Consistency (NEW)\n",
    "    df['mom_5'] = df['close'].pct_change(5) * 100\n",
    "    df['mom_10'] = df['close'].pct_change(10) * 100\n",
    "    df['mom_20'] = df['close'].pct_change(20) * 100\n",
    "    df['mom_consistency'] = ((df['mom_5'] > 0) & (df['mom_10'] > 0) & (df['mom_20'] > 0)).astype(int)\n",
    "    \n",
    "    # RSI Momentum (NEW)\n",
    "    df['rsi_momentum'] = df['rsi_14'] - df['rsi_14'].shift(5)\n",
    "    df['rsi_rising'] = (df['rsi_momentum'] > 0).astype(int)\n",
    "    \n",
    "    # Volatility Regime (NEW)\n",
    "    df['atr_ratio'] = df['atr_14'] / df['atr_14'].rolling(50).mean()\n",
    "    df['high_volatility'] = (df['atr_ratio'] > 1.2).astype(int)\n",
    "    df['low_volatility'] = (df['atr_ratio'] < 0.8).astype(int)\n",
    "    \n",
    "    # Combined Buy Score (V2 style)\n",
    "    df['buy_score'] = (\n",
    "        df['macd_bullish'] +\n",
    "        df['rsi_bullish'] +\n",
    "        df['sma_5_20_cross'] +\n",
    "        df['golden_cross'] +\n",
    "        df['price_above_all_ma'] +\n",
    "        df['strong_uptrend'] +\n",
    "        df['stoch_bullish'] +\n",
    "        df['mom_consistency']\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Adding V5 features...\")\n",
    "train_df = add_features_v5(train_df)\n",
    "test_df = add_features_v5(test_df)\n",
    "print(f\"âœ“ Features added: {len(train_df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9cf6b",
   "metadata": {},
   "source": [
    "## 3. BUY Signal Labels (Same as V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e41e81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BUY labels (TP=20 pips, SL=10 pips)...\n",
      "Creating BUY labels (TP=20 pips, SL=10 pips)...\n",
      "\n",
      "ðŸ“Š Label Distribution:\n",
      "Train - BUY: 5.2%\n",
      "Test  - BUY: 7.3%\n",
      "Creating BUY labels (TP=20 pips, SL=10 pips)...\n",
      "\n",
      "ðŸ“Š Label Distribution:\n",
      "Train - BUY: 5.2%\n",
      "Test  - BUY: 7.3%\n"
     ]
    }
   ],
   "source": [
    "def create_buy_labels(df, forward_periods=60, tp_pips=20, sl_pips=10):\n",
    "    \"\"\"\n",
    "    Create BUY-only labels (Same logic as V2).\n",
    "    BUY (1): TP reached before SL within forward_periods\n",
    "    NOT_BUY (0): SL hit first or neither hit\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    tp_move = tp_pips * 0.0001\n",
    "    sl_move = sl_pips * 0.0001\n",
    "    \n",
    "    print(f\"Creating BUY labels (TP={tp_pips} pips, SL={sl_pips} pips)...\")\n",
    "    \n",
    "    # Calculate TP and SL prices\n",
    "    df['tp_price'] = df['close'] + tp_move\n",
    "    df['sl_price'] = df['close'] - sl_move\n",
    "    \n",
    "    # Future max/min within forward_periods\n",
    "    df['future_max'] = df['high'].rolling(window=forward_periods).max().shift(-forward_periods)\n",
    "    df['future_min'] = df['low'].rolling(window=forward_periods).min().shift(-forward_periods)\n",
    "    \n",
    "    # BUY = TP reachable AND SL not hit\n",
    "    df['tp_reachable'] = df['future_max'] >= df['tp_price']\n",
    "    df['sl_hit'] = df['future_min'] <= df['sl_price']\n",
    "    df['is_buy'] = ((df['tp_reachable']) & (~df['sl_hit'])).astype(int)\n",
    "    \n",
    "    # Cleanup\n",
    "    df.drop(['tp_price', 'sl_price', 'future_max', 'future_min', 'tp_reachable', 'sl_hit'], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create labels with V2's R:R (2:1)\n",
    "train_df = create_buy_labels(train_df, forward_periods=60, tp_pips=20, sl_pips=10)\n",
    "test_df = create_buy_labels(test_df, forward_periods=60, tp_pips=20, sl_pips=10)\n",
    "\n",
    "# Label distribution\n",
    "print(f\"\\nðŸ“Š Label Distribution:\")\n",
    "print(f\"Train - BUY: {train_df['is_buy'].mean()*100:.1f}%\")\n",
    "print(f\"Test  - BUY: {test_df['is_buy'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798a5d9",
   "metadata": {},
   "source": [
    "## 4. Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e09495c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 77\n",
      "\n",
      "Train samples: 1,859,293\n",
      "Test samples: 296,579\n",
      "\n",
      "Train samples: 1,859,293\n",
      "Test samples: 296,579\n",
      "\n",
      "âœ“ Data ready\n",
      "  Class balance (train): 5.2% BUY\n",
      "  Class balance (test): 7.3% BUY\n",
      "\n",
      "âœ“ Data ready\n",
      "  Class balance (train): 5.2% BUY\n",
      "  Class balance (test): 7.3% BUY\n"
     ]
    }
   ],
   "source": [
    "# Select features\n",
    "exclude_cols = ['time', 'is_buy', 'open', 'high', 'low', 'close', 'volume', 'tick_volume']\n",
    "feature_cols = [col for col in train_df.columns if col not in exclude_cols]\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "\n",
    "# Drop NaN rows\n",
    "train_clean = train_df.dropna(subset=feature_cols + ['is_buy']).copy()\n",
    "test_clean = test_df.dropna(subset=feature_cols + ['is_buy']).copy()\n",
    "\n",
    "print(f\"\\nTrain samples: {len(train_clean):,}\")\n",
    "print(f\"Test samples: {len(test_clean):,}\")\n",
    "\n",
    "# Prepare X, y\n",
    "X_train = train_clean[feature_cols].values\n",
    "y_train = train_clean['is_buy'].values\n",
    "X_test = test_clean[feature_cols].values\n",
    "y_test = test_clean['is_buy'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nâœ“ Data ready\")\n",
    "print(f\"  Class balance (train): {y_train.mean()*100:.1f}% BUY\")\n",
    "print(f\"  Class balance (test): {y_test.mean()*100:.1f}% BUY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b163b",
   "metadata": {},
   "source": [
    "## 5. Train Models with Calibration (V5 Key Innovation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64f0181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸŽ¯ TRAINING V5 MODELS (Direct - No Calibration)\n",
      "============================================================\n",
      "\n",
      "Class weight: 18.11\n",
      "\n",
      "Training XGBoost...\n",
      "  âœ“ XGBoost - Accuracy: 74.67%, Precision: 16.33%\n",
      "\n",
      "Training LightGBM...\n",
      "  âœ“ XGBoost - Accuracy: 74.67%, Precision: 16.33%\n",
      "\n",
      "Training LightGBM...\n",
      "  âœ“ LightGBM - Accuracy: 63.93%, Precision: 14.48%\n",
      "\n",
      "Training Random Forest...\n",
      "  âœ“ LightGBM - Accuracy: 63.93%, Precision: 14.48%\n",
      "\n",
      "Training Random Forest...\n",
      "  âœ“ Random Forest - Accuracy: 73.37%, Precision: 16.66%\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š MODEL COMPARISON:\n",
      "   XGBoost:       74.67% acc, 16.33% precision\n",
      "   LightGBM:      63.93% acc, 14.48% precision\n",
      "   Random Forest: 73.37% acc, 16.66% precision\n",
      "  âœ“ Random Forest - Accuracy: 73.37%, Precision: 16.66%\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š MODEL COMPARISON:\n",
      "   XGBoost:       74.67% acc, 16.33% precision\n",
      "   LightGBM:      63.93% acc, 14.48% precision\n",
      "   Random Forest: 73.37% acc, 16.66% precision\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ðŸŽ¯ TRAINING V5 MODELS (Direct - No Calibration)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Class weight\n",
    "neg_count = (y_train == 0).sum()\n",
    "pos_count = (y_train == 1).sum()\n",
    "scale_pos_weight = neg_count / pos_count\n",
    "print(f\"\\nClass weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# ==================== Model 1: XGBoost ====================\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    verbosity=0,\n",
    "    tree_method='hist',\n",
    "    device='cuda' if GPU_AVAILABLE else 'cpu'\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "xgb_proba = xgb_model.predict_proba(X_test_scaled)\n",
    "xgb_pred = xgb_model.predict(X_test_scaled)\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "xgb_prec = precision_score(y_test, xgb_pred, zero_division=0)\n",
    "print(f\"  âœ“ XGBoost - Accuracy: {xgb_acc*100:.2f}%, Precision: {xgb_prec*100:.2f}%\")\n",
    "\n",
    "# ==================== Model 2: LightGBM ====================\n",
    "print(\"\\nTraining LightGBM...\")\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lgb_model.fit(X_train_scaled, y_train)\n",
    "lgb_proba = lgb_model.predict_proba(X_test_scaled)\n",
    "lgb_pred = lgb_model.predict(X_test_scaled)\n",
    "lgb_acc = accuracy_score(y_test, lgb_pred)\n",
    "lgb_prec = precision_score(y_test, lgb_pred, zero_division=0)\n",
    "print(f\"  âœ“ LightGBM - Accuracy: {lgb_acc*100:.2f}%, Precision: {lgb_prec*100:.2f}%\")\n",
    "\n",
    "# ==================== Model 3: Random Forest ====================\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_proba = rf_model.predict_proba(X_test_scaled)\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "rf_prec = precision_score(y_test, rf_pred, zero_division=0)\n",
    "print(f\"  âœ“ Random Forest - Accuracy: {rf_acc*100:.2f}%, Precision: {rf_prec*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ðŸ“Š MODEL COMPARISON:\")\n",
    "print(f\"   XGBoost:       {xgb_acc*100:.2f}% acc, {xgb_prec*100:.2f}% precision\")\n",
    "print(f\"   LightGBM:      {lgb_acc*100:.2f}% acc, {lgb_prec*100:.2f}% precision\")\n",
    "print(f\"   Random Forest: {rf_acc*100:.2f}% acc, {rf_prec*100:.2f}% precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16704c",
   "metadata": {},
   "source": [
    "## 6. Ensemble with Confidence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4761d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ” V5 ENSEMBLE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Model Agreement on BUY: 67,659 signals\n",
      "\n",
      "ðŸ“Š BUY Signal Accuracy by Confidence Level:\n",
      "------------------------------------------------------------\n",
      "  Confidence |  Signals |   Accuracy |  Precision\n",
      "------------------------------------------------------------\n",
      "        50%+ |    94250 |      16.1% |      16.1%\n",
      "        60%+ |    70528 |      17.7% |      17.7%\n",
      "        70%+ |    49262 |      20.0% |      20.0%\n",
      "        75%+ |    35835 |      21.1% |      21.1%\n",
      "        80%+ |    20430 |      22.2% |      22.2%\n",
      "        85%+ |     6914 |      23.2% |      23.2%\n",
      "        90%+ |      405 |      25.7% |      25.7%\n",
      "\n",
      "ðŸ’¡ Recommendations:\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ðŸ” V5 ENSEMBLE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Weighted Ensemble (XGB slightly higher weight)\n",
    "weights = [0.4, 0.35, 0.25]  # XGB, LGB, RF\n",
    "avg_proba = (weights[0] * xgb_proba + weights[1] * lgb_proba + weights[2] * rf_proba)\n",
    "buy_prob = avg_proba[:, 1] * 100\n",
    "\n",
    "# Model Agreement Bonus\n",
    "all_agree_buy = (xgb_pred == 1) & (lgb_pred == 1) & (rf_pred == 1)\n",
    "confidence = buy_prob.copy()\n",
    "confidence[all_agree_buy] = np.minimum(confidence[all_agree_buy] + 5, 100)\n",
    "\n",
    "print(f\"\\nModel Agreement on BUY: {all_agree_buy.sum():,} signals\")\n",
    "\n",
    "# ==================== ACCURACY BY CONFIDENCE ====================\n",
    "print(f\"\\nðŸ“Š BUY Signal Accuracy by Confidence Level:\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Confidence':>12} | {'Signals':>8} | {'Accuracy':>10} | {'Precision':>10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "results = []\n",
    "for min_conf in [50, 60, 70, 75, 80, 85, 90]:\n",
    "    mask = confidence >= min_conf\n",
    "    if mask.sum() > 0:\n",
    "        signals = mask.sum()\n",
    "        correct = y_test[mask].sum()\n",
    "        accuracy = correct / signals * 100\n",
    "        results.append({'conf': min_conf, 'signals': signals, 'acc': accuracy})\n",
    "        print(f\"{min_conf:>10}%+ | {signals:>8} | {accuracy:>9.1f}% | {accuracy:>9.1f}%\")\n",
    "\n",
    "# Find optimal threshold\n",
    "print(f\"\\nðŸ’¡ Recommendations:\")\n",
    "for r in results:\n",
    "    if r['acc'] >= 80 and r['signals'] >= 10:\n",
    "        print(f\"   âœ“ Use {r['conf']}% threshold: {r['signals']} signals, {r['acc']:.1f}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99cf5dd",
   "metadata": {},
   "source": [
    "## 7. Compare with V2 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "841a0b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ“Š V5 vs V2 COMPARISON\n",
      "============================================================\n",
      "Missing features for V2: ['roc_5', 'roc_10', 'roc_20', 'momentum_10', 'momentum_20']...\n",
      "Missing features for V2: ['roc_5', 'roc_10', 'roc_20', 'momentum_10', 'momentum_20']...\n",
      "\n",
      "âœ… V2 Test Data: 80,296 samples (BUY/SELL only)\n",
      "   BUY ratio: 52.2%\n",
      "\n",
      "ðŸ“Š V2 BUY Signal Accuracy:\n",
      "--------------------------------------------------\n",
      "   Conf >= 70%:  2344 signals | Accuracy: 51.8%\n",
      "   Conf >= 75%:   663 signals | Accuracy: 55.1%\n",
      "   Conf >= 80%:   112 signals | Accuracy: 58.9%\n",
      "   Conf >= 85%:     3 signals | Accuracy: 33.3%\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š V5 vs V2 COMPARISON (Same labeling approach)\n",
      "============================================================\n",
      "\n",
      "âš ï¸  Note: V5 uses different labeling (BUY-only with TP/SL)\n",
      "         V2 uses BUY vs SELL classification\n",
      "\n",
      "ðŸ“Š V5 Results (BUY-only TP=20/SL=10):\n",
      "   Conf >= 70%: 49262 signals | Accuracy: 20.0%\n",
      "   Conf >= 75%: 35835 signals | Accuracy: 21.1%\n",
      "   Conf >= 80%: 20430 signals | Accuracy: 22.2%\n",
      "   Conf >= 85%:  6914 signals | Accuracy: 23.2%\n",
      "   Conf >= 90%:   405 signals | Accuracy: 25.7%\n",
      "\n",
      "âœ… V2 Test Data: 80,296 samples (BUY/SELL only)\n",
      "   BUY ratio: 52.2%\n",
      "\n",
      "ðŸ“Š V2 BUY Signal Accuracy:\n",
      "--------------------------------------------------\n",
      "   Conf >= 70%:  2344 signals | Accuracy: 51.8%\n",
      "   Conf >= 75%:   663 signals | Accuracy: 55.1%\n",
      "   Conf >= 80%:   112 signals | Accuracy: 58.9%\n",
      "   Conf >= 85%:     3 signals | Accuracy: 33.3%\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š V5 vs V2 COMPARISON (Same labeling approach)\n",
      "============================================================\n",
      "\n",
      "âš ï¸  Note: V5 uses different labeling (BUY-only with TP/SL)\n",
      "         V2 uses BUY vs SELL classification\n",
      "\n",
      "ðŸ“Š V5 Results (BUY-only TP=20/SL=10):\n",
      "   Conf >= 70%: 49262 signals | Accuracy: 20.0%\n",
      "   Conf >= 75%: 35835 signals | Accuracy: 21.1%\n",
      "   Conf >= 80%: 20430 signals | Accuracy: 22.2%\n",
      "   Conf >= 85%:  6914 signals | Accuracy: 23.2%\n",
      "   Conf >= 90%:   405 signals | Accuracy: 25.7%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ðŸ“Š V5 vs V2 COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# V2 uses BUY vs SELL approach, so we need to recreate the same test data\n",
    "# Load fresh test data for V2\n",
    "test_df_v2 = pd.read_csv(DATA_DIR / 'EUR_USD_test.csv')\n",
    "\n",
    "# V2 Feature Engineering (simplified version of add_technical_indicators)\n",
    "def add_v2_features(df):\n",
    "    \"\"\"V2 compatible features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Moving Averages\n",
    "    for period in [5, 10, 20, 50, 100, 200]:\n",
    "        df[f'sma_{period}'] = df['close'].rolling(period).mean()\n",
    "        df[f'ema_{period}'] = df['close'].ewm(span=period, adjust=False).mean()\n",
    "    \n",
    "    # MA Crossovers\n",
    "    df['sma_5_20_cross'] = (df['sma_5'] > df['sma_20']).astype(int)\n",
    "    df['sma_20_50_cross'] = (df['sma_20'] > df['sma_50']).astype(int)\n",
    "    df['ema_10_50_cross'] = (df['ema_10'] > df['ema_50']).astype(int)\n",
    "    df['golden_cross'] = (df['sma_50'] > df['sma_200']).astype(int)\n",
    "    \n",
    "    df['price_vs_sma20'] = (df['close'] - df['sma_20']) / df['sma_20'] * 100\n",
    "    df['price_vs_sma50'] = (df['close'] - df['sma_50']) / df['sma_50'] * 100\n",
    "    df['price_vs_ema20'] = (df['close'] - df['ema_20']) / df['ema_20'] * 100\n",
    "    df['price_above_all_ma'] = ((df['close'] > df['sma_20']) & \n",
    "                                 (df['close'] > df['sma_50']) & \n",
    "                                 (df['close'] > df['ema_20'])).astype(int)\n",
    "    \n",
    "    # RSI\n",
    "    for period in [7, 14, 21]:\n",
    "        delta = df['close'].diff()\n",
    "        gain = delta.where(delta > 0, 0).rolling(period).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(period).mean()\n",
    "        rs = gain / (loss + 1e-10)\n",
    "        df[f'rsi_{period}'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    df['rsi_oversold'] = (df['rsi_14'] < 30).astype(int)\n",
    "    df['rsi_bullish'] = ((df['rsi_14'] > 50) & (df['rsi_14'] < 70)).astype(int)\n",
    "    \n",
    "    # MACD\n",
    "    ema12 = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    df['macd'] = ema12 - ema26\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
    "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    df['macd_cross'] = (df['macd'] > df['macd_signal']).astype(int)\n",
    "    df['macd_bullish'] = ((df['macd'] > df['macd_signal']) & (df['macd_hist'] > 0)).astype(int)\n",
    "    \n",
    "    # Stochastic\n",
    "    for period in [14, 21]:\n",
    "        low_min = df['low'].rolling(period).min()\n",
    "        high_max = df['high'].rolling(period).max()\n",
    "        df[f'stoch_k_{period}'] = 100 * (df['close'] - low_min) / (high_max - low_min + 1e-10)\n",
    "        df[f'stoch_d_{period}'] = df[f'stoch_k_{period}'].rolling(3).mean()\n",
    "    \n",
    "    df['stoch_oversold'] = (df['stoch_k_14'] < 20).astype(int)\n",
    "    df['stoch_bullish'] = ((df['stoch_k_14'] > df['stoch_d_14']) & (df['stoch_k_14'] < 80)).astype(int)\n",
    "    \n",
    "    # ATR\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = abs(df['high'] - df['close'].shift())\n",
    "    low_close = abs(df['low'] - df['close'].shift())\n",
    "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    df['atr_14'] = tr.rolling(14).mean()\n",
    "    df['atr_pips'] = df['atr_14'] * 10000\n",
    "    \n",
    "    # Bollinger\n",
    "    df['bb_middle'] = df['close'].rolling(20).mean()\n",
    "    bb_std = df['close'].rolling(20).std()\n",
    "    df['bb_upper'] = df['bb_middle'] + 2 * bb_std\n",
    "    df['bb_lower'] = df['bb_middle'] - 2 * bb_std\n",
    "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle'] * 100\n",
    "    df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-10)\n",
    "    df['bb_squeeze'] = (df['bb_width'] < df['bb_width'].rolling(50).mean()).astype(int)\n",
    "    \n",
    "    # Candle\n",
    "    df['candle_body'] = df['close'] - df['open']\n",
    "    df['candle_range'] = df['high'] - df['low']\n",
    "    df['candle_body_pct'] = df['candle_body'] / (df['candle_range'] + 1e-10)\n",
    "    df['upper_shadow'] = df['high'] - df[['open', 'close']].max(axis=1)\n",
    "    df['lower_shadow'] = df[['open', 'close']].min(axis=1) - df['low']\n",
    "    df['is_bullish'] = (df['close'] > df['open']).astype(int)\n",
    "    df['is_hammer'] = ((df['lower_shadow'] > df['candle_body'].abs() * 2) & \n",
    "                       (df['upper_shadow'] < df['candle_body'].abs() * 0.5)).astype(int)\n",
    "    df['bullish_engulfing'] = ((df['is_bullish'] == 1) & \n",
    "                               (df['is_bullish'].shift(1) == 0) &\n",
    "                               (df['close'] > df['open'].shift(1))).astype(int)\n",
    "    \n",
    "    # Pivot\n",
    "    df['pivot'] = (df['high'].shift() + df['low'].shift() + df['close'].shift()) / 3\n",
    "    df['r1'] = 2 * df['pivot'] - df['low'].shift()\n",
    "    df['s1'] = 2 * df['pivot'] - df['high'].shift()\n",
    "    df['r2'] = df['pivot'] + (df['high'].shift() - df['low'].shift())\n",
    "    df['s2'] = df['pivot'] - (df['high'].shift() - df['low'].shift())\n",
    "    df['near_support'] = (df['close'] < df['s1'] * 1.001).astype(int)\n",
    "    \n",
    "    # Trend\n",
    "    df['trend_short'] = np.where(df['ema_10'] > df['ema_20'], 1, -1)\n",
    "    df['trend_medium'] = np.where(df['ema_20'] > df['ema_50'], 1, -1)\n",
    "    df['trend_long'] = np.where(df['ema_50'] > df['ema_200'], 1, -1)\n",
    "    df['trend_alignment'] = df['trend_short'] + df['trend_medium'] + df['trend_long']\n",
    "    df['strong_uptrend'] = (df['trend_alignment'] == 3).astype(int)\n",
    "    \n",
    "    df['buy_score'] = (\n",
    "        df['macd_bullish'] + df['rsi_bullish'] + df['sma_5_20_cross'] +\n",
    "        df['golden_cross'] + df['price_above_all_ma'] + df['strong_uptrend']\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# V2 Signal Labels (BUY vs SELL)\n",
    "def create_v2_signal_labels(df, forward_periods=60, min_move_pips=15):\n",
    "    df = df.copy()\n",
    "    min_move = min_move_pips * 0.0001\n",
    "    \n",
    "    df['future_max'] = df['high'].rolling(window=forward_periods).max().shift(-forward_periods)\n",
    "    df['future_min'] = df['low'].rolling(window=forward_periods).min().shift(-forward_periods)\n",
    "    \n",
    "    df['up_move'] = df['future_max'] - df['close']\n",
    "    df['down_move'] = df['close'] - df['future_min']\n",
    "    \n",
    "    conditions = [\n",
    "        (df['up_move'] >= min_move) & (df['up_move'] > df['down_move'] * 1.5),\n",
    "        (df['down_move'] >= min_move) & (df['down_move'] > df['up_move'] * 1.5),\n",
    "    ]\n",
    "    choices = [1, -1]\n",
    "    df['signal'] = np.select(conditions, choices, default=0)\n",
    "    \n",
    "    df.drop(['future_max', 'future_min', 'up_move', 'down_move'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Prepare V2 test data\n",
    "test_df_v2 = add_v2_features(test_df_v2)\n",
    "test_df_v2 = create_v2_signal_labels(test_df_v2)\n",
    "\n",
    "# Filter BUY/SELL only\n",
    "test_binary_v2 = test_df_v2[test_df_v2['signal'] != 0].copy()\n",
    "\n",
    "# Load V2 models\n",
    "v2_dir = BASE_DIR / 'models' / 'signal_generator_v2'\n",
    "try:\n",
    "    v2_xgb = joblib.load(v2_dir / 'xgboost_v2.joblib')\n",
    "    v2_lgb = joblib.load(v2_dir / 'lightgbm_v2.joblib')\n",
    "    v2_rf = joblib.load(v2_dir / 'rf_v2.joblib')\n",
    "    v2_scaler = joblib.load(v2_dir / 'scaler_v2.joblib')\n",
    "    v2_feature_cols = joblib.load(v2_dir / 'feature_cols_v2.joblib')\n",
    "    \n",
    "    # Check missing features\n",
    "    missing = [c for c in v2_feature_cols if c not in test_binary_v2.columns]\n",
    "    if missing:\n",
    "        print(f\"Missing features for V2: {missing[:5]}...\")\n",
    "        # Add missing with 0\n",
    "        for c in missing:\n",
    "            test_binary_v2[c] = 0\n",
    "    \n",
    "    test_binary_v2_clean = test_binary_v2.dropna(subset=v2_feature_cols).copy()\n",
    "    X_test_v2 = test_binary_v2_clean[v2_feature_cols].values\n",
    "    y_test_v2 = ((test_binary_v2_clean['signal'].values + 1) / 2).astype(int)\n",
    "    \n",
    "    X_test_v2_scaled = v2_scaler.transform(X_test_v2)\n",
    "    \n",
    "    # V2 predictions\n",
    "    v2_xgb_proba = v2_xgb.predict_proba(X_test_v2_scaled)\n",
    "    v2_lgb_proba = v2_lgb.predict_proba(X_test_v2_scaled)\n",
    "    v2_rf_proba = v2_rf.predict_proba(X_test_v2_scaled)\n",
    "    \n",
    "    v2_xgb_pred = (v2_xgb_proba[:, 1] > 0.5).astype(int)\n",
    "    v2_lgb_pred = (v2_lgb_proba[:, 1] > 0.5).astype(int)\n",
    "    v2_rf_pred = (v2_rf_proba[:, 1] > 0.5).astype(int)\n",
    "    \n",
    "    v2_avg_proba = (0.4 * v2_xgb_proba + 0.35 * v2_lgb_proba + 0.25 * v2_rf_proba)\n",
    "    v2_buy_prob = v2_avg_proba[:, 1] * 100\n",
    "    \n",
    "    # Model agreement bonus\n",
    "    v2_all_agree = (v2_xgb_pred == 1) & (v2_lgb_pred == 1) & (v2_rf_pred == 1)\n",
    "    v2_confidence = v2_buy_prob.copy()\n",
    "    v2_confidence[v2_all_agree] = np.minimum(v2_confidence[v2_all_agree] + 5, 100)\n",
    "    \n",
    "    print(f\"\\nâœ… V2 Test Data: {len(test_binary_v2_clean):,} samples (BUY/SELL only)\")\n",
    "    print(f\"   BUY ratio: {y_test_v2.mean()*100:.1f}%\")\n",
    "    \n",
    "    # V2 Accuracy by Confidence\n",
    "    print(f\"\\nðŸ“Š V2 BUY Signal Accuracy:\")\n",
    "    print(\"-\"*50)\n",
    "    for thresh in [70, 75, 80, 85, 90]:\n",
    "        mask = (v2_confidence >= thresh)\n",
    "        if mask.sum() > 0:\n",
    "            signals = mask.sum()\n",
    "            acc = y_test_v2[mask].mean() * 100\n",
    "            print(f\"   Conf >= {thresh}%: {signals:>5} signals | Accuracy: {acc:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š V5 vs V2 COMPARISON (Same labeling approach)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # For fair comparison, we need V5 on the same BUY/SELL data\n",
    "    # But V5 was trained on different labels. Let's just show both results.\n",
    "    print(\"\\nâš ï¸  Note: V5 uses different labeling (BUY-only with TP/SL)\")\n",
    "    print(\"         V2 uses BUY vs SELL classification\")\n",
    "    print(\"\\nðŸ“Š V5 Results (BUY-only TP=20/SL=10):\")\n",
    "    for thresh in [70, 75, 80, 85, 90]:\n",
    "        mask = confidence >= thresh\n",
    "        if mask.sum() > 0:\n",
    "            signals = mask.sum()\n",
    "            acc = y_test[mask].mean() * 100\n",
    "            print(f\"   Conf >= {thresh}%: {signals:>5} signals | Accuracy: {acc:.1f}%\")\n",
    "            \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"Error: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8797d7d",
   "metadata": {},
   "source": [
    "## 8. Backtest V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba422408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ“ˆ V5 BACKTEST RESULTS\n",
      "============================================================\n",
      "Backtesting 49262 BUY signals (Conf >= 70%)...\n",
      "Conf >= 70%: 49262 signals | WR:  41.3% | Pips: 22211.7 | PF: 1.08\n",
      "Backtesting 35835 BUY signals (Conf >= 75%)...\n",
      "Conf >= 70%: 49262 signals | WR:  41.3% | Pips: 22211.7 | PF: 1.08\n",
      "Backtesting 35835 BUY signals (Conf >= 75%)...\n",
      "Conf >= 75%: 35835 signals | WR:  40.7% | Pips: 15695.0 | PF: 1.08\n",
      "Backtesting 20430 BUY signals (Conf >= 80%)...\n",
      "Conf >= 75%: 35835 signals | WR:  40.7% | Pips: 15695.0 | PF: 1.08\n",
      "Backtesting 20430 BUY signals (Conf >= 80%)...\n",
      "Conf >= 80%: 20430 signals | WR:  39.3% | Pips:  5664.7 | PF: 1.05\n",
      "Backtesting 6914 BUY signals (Conf >= 85%)...\n",
      "Conf >= 80%: 20430 signals | WR:  39.3% | Pips:  5664.7 | PF: 1.05\n",
      "Backtesting 6914 BUY signals (Conf >= 85%)...\n",
      "Conf >= 85%: 6914 signals | WR:  37.8% | Pips:   823.3 | PF: 1.02\n",
      "Backtesting 405 BUY signals (Conf >= 90%)...\n",
      "Conf >= 85%: 6914 signals | WR:  37.8% | Pips:   823.3 | PF: 1.02\n",
      "Backtesting 405 BUY signals (Conf >= 90%)...\n",
      "Conf >= 90%:  405 signals | WR:  39.5% | Pips:   251.7 | PF: 1.10\n",
      "Conf >= 90%:  405 signals | WR:  39.5% | Pips:   251.7 | PF: 1.10\n"
     ]
    }
   ],
   "source": [
    "def backtest_v5(df, probabilities, min_confidence=80, tp_pips=20, sl_pips=10):\n",
    "    \"\"\"\n",
    "    Backtest BUY signals with fixed SL/TP (same as V2 labeling).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    tp_move = tp_pips * 0.0001\n",
    "    sl_move = sl_pips * 0.0001\n",
    "    \n",
    "    # BUY signals\n",
    "    buy_indices = np.where(probabilities >= min_confidence)[0]\n",
    "    \n",
    "    print(f\"Backtesting {len(buy_indices)} BUY signals (Conf >= {min_confidence}%)...\")\n",
    "    \n",
    "    for idx in buy_indices:\n",
    "        if idx + 60 >= len(df):\n",
    "            continue\n",
    "            \n",
    "        entry = df['close'].iloc[idx]\n",
    "        tp_price = entry + tp_move\n",
    "        sl_price = entry - sl_move\n",
    "        \n",
    "        # Check outcome\n",
    "        future = df.iloc[idx+1 : idx+61]\n",
    "        result = 'TIMEOUT'\n",
    "        pnl = 0\n",
    "        \n",
    "        for _, row in future.iterrows():\n",
    "            if row['low'] <= sl_price:\n",
    "                result = 'LOSS'\n",
    "                pnl = -sl_pips\n",
    "                break\n",
    "            if row['high'] >= tp_price:\n",
    "                result = 'WIN'\n",
    "                pnl = tp_pips\n",
    "                break\n",
    "        \n",
    "        if result == 'TIMEOUT':\n",
    "            end_price = future['close'].iloc[-1] if len(future) > 0 else entry\n",
    "            pnl = (end_price - entry) * 10000\n",
    "            \n",
    "        results.append({'pnl': pnl, 'result': result})\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run Backtest\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“ˆ V5 BACKTEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for conf in [70, 75, 80, 85, 90]:\n",
    "    bt_results = backtest_v5(test_clean, confidence, min_confidence=conf)\n",
    "    \n",
    "    if len(bt_results) > 0:\n",
    "        wins = len([r for r in bt_results if r['pnl'] > 0])\n",
    "        total = len(bt_results)\n",
    "        wr = wins / total * 100\n",
    "        total_pips = sum([r['pnl'] for r in bt_results])\n",
    "        \n",
    "        # Profit Factor\n",
    "        gross_profit = sum([r['pnl'] for r in bt_results if r['pnl'] > 0])\n",
    "        gross_loss = abs(sum([r['pnl'] for r in bt_results if r['pnl'] < 0]))\n",
    "        pf = gross_profit / gross_loss if gross_loss > 0 else float('inf')\n",
    "        \n",
    "        print(f\"Conf >= {conf}%: {total:>4} signals | WR: {wr:>5.1f}% | Pips: {total_pips:>7.1f} | PF: {pf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd038a6",
   "metadata": {},
   "source": [
    "## 9. V5 Improved: BUY vs SELL Approach (Same as V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d130952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸš€ V5 IMPROVED: BUY vs SELL + Time Features\n",
      "======================================================================\n",
      "Adding V5 improved features...\n",
      "Adding V5 improved features...\n",
      "\n",
      "âœ“ Train: 393,249 samples (BUY/SELL only)\n",
      "âœ“ Test: 80,296 samples\n",
      "âœ“ Features: 78\n",
      "âœ“ BUY ratio (train): 49.3%\n",
      "âœ“ BUY ratio (test): 52.2%\n",
      "\n",
      "âœ“ Train: 393,249 samples (BUY/SELL only)\n",
      "âœ“ Test: 80,296 samples\n",
      "âœ“ Features: 78\n",
      "âœ“ BUY ratio (train): 49.3%\n",
      "âœ“ BUY ratio (test): 52.2%\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# V5 IMPROVED: Use V2's BUY vs SELL approach + Time Features\n",
    "# ================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸš€ V5 IMPROVED: BUY vs SELL + Time Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Reload fresh data\n",
    "train_df_v5 = pd.read_csv(DATA_DIR / 'EUR_USD_1min.csv')\n",
    "test_df_v5 = pd.read_csv(DATA_DIR / 'EUR_USD_test.csv')\n",
    "\n",
    "# Rename timestamp if needed\n",
    "if 'timestamp' in train_df_v5.columns:\n",
    "    train_df_v5.rename(columns={'timestamp': 'time'}, inplace=True)\n",
    "if 'timestamp' in test_df_v5.columns:\n",
    "    test_df_v5.rename(columns={'timestamp': 'time'}, inplace=True)\n",
    "\n",
    "train_df_v5['time'] = pd.to_datetime(train_df_v5['time'])\n",
    "test_df_v5['time'] = pd.to_datetime(test_df_v5['time'])\n",
    "\n",
    "def add_v5_improved_features(df):\n",
    "    \"\"\"V2 Core Features + V5 Time/Momentum Features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ==================== V5 TIME FEATURES ====================\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['day_of_week'] = df['time'].dt.dayofweek\n",
    "    df['is_asian'] = ((df['hour'] >= 0) & (df['hour'] < 8)).astype(int)\n",
    "    df['is_london'] = ((df['hour'] >= 8) & (df['hour'] < 16)).astype(int)\n",
    "    df['is_ny'] = ((df['hour'] >= 13) & (df['hour'] < 21)).astype(int)\n",
    "    df['is_overlap'] = ((df['hour'] >= 13) & (df['hour'] < 16)).astype(int)\n",
    "    df['is_low_liquidity'] = ((df['hour'] >= 21) | (df['hour'] < 2)).astype(int)\n",
    "    \n",
    "    # ==================== V2 CORE FEATURES ====================\n",
    "    # Moving Averages\n",
    "    for period in [5, 10, 20, 50, 100, 200]:\n",
    "        df[f'sma_{period}'] = df['close'].rolling(period).mean()\n",
    "        df[f'ema_{period}'] = df['close'].ewm(span=period, adjust=False).mean()\n",
    "    \n",
    "    # MA Crossovers\n",
    "    df['sma_5_20_cross'] = (df['sma_5'] > df['sma_20']).astype(int)\n",
    "    df['sma_20_50_cross'] = (df['sma_20'] > df['sma_50']).astype(int)\n",
    "    df['ema_10_50_cross'] = (df['ema_10'] > df['ema_50']).astype(int)\n",
    "    df['golden_cross'] = (df['sma_50'] > df['sma_200']).astype(int)\n",
    "    \n",
    "    df['price_vs_sma20'] = (df['close'] - df['sma_20']) / df['sma_20'] * 100\n",
    "    df['price_vs_sma50'] = (df['close'] - df['sma_50']) / df['sma_50'] * 100\n",
    "    df['price_vs_ema20'] = (df['close'] - df['ema_20']) / df['ema_20'] * 100\n",
    "    df['price_above_all_ma'] = ((df['close'] > df['sma_20']) & \n",
    "                                 (df['close'] > df['sma_50']) & \n",
    "                                 (df['close'] > df['ema_20'])).astype(int)\n",
    "    \n",
    "    # RSI\n",
    "    for period in [7, 14, 21]:\n",
    "        delta = df['close'].diff()\n",
    "        gain = delta.where(delta > 0, 0).rolling(period).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(period).mean()\n",
    "        rs = gain / (loss + 1e-10)\n",
    "        df[f'rsi_{period}'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    df['rsi_oversold'] = (df['rsi_14'] < 30).astype(int)\n",
    "    df['rsi_bullish'] = ((df['rsi_14'] > 50) & (df['rsi_14'] < 70)).astype(int)\n",
    "    \n",
    "    # MACD\n",
    "    ema12 = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    df['macd'] = ema12 - ema26\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
    "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    df['macd_cross'] = (df['macd'] > df['macd_signal']).astype(int)\n",
    "    df['macd_bullish'] = ((df['macd'] > df['macd_signal']) & (df['macd_hist'] > 0)).astype(int)\n",
    "    \n",
    "    # Stochastic\n",
    "    for period in [14, 21]:\n",
    "        low_min = df['low'].rolling(period).min()\n",
    "        high_max = df['high'].rolling(period).max()\n",
    "        df[f'stoch_k_{period}'] = 100 * (df['close'] - low_min) / (high_max - low_min + 1e-10)\n",
    "        df[f'stoch_d_{period}'] = df[f'stoch_k_{period}'].rolling(3).mean()\n",
    "    \n",
    "    df['stoch_oversold'] = (df['stoch_k_14'] < 20).astype(int)\n",
    "    df['stoch_bullish'] = ((df['stoch_k_14'] > df['stoch_d_14']) & (df['stoch_k_14'] < 80)).astype(int)\n",
    "    \n",
    "    # ROC\n",
    "    for period in [5, 10, 20]:\n",
    "        df[f'roc_{period}'] = df['close'].pct_change(period) * 100\n",
    "    \n",
    "    # Momentum\n",
    "    df['momentum_10'] = df['close'] - df['close'].shift(10)\n",
    "    df['momentum_20'] = df['close'] - df['close'].shift(20)\n",
    "    \n",
    "    # ATR\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = abs(df['high'] - df['close'].shift())\n",
    "    low_close = abs(df['low'] - df['close'].shift())\n",
    "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    df['atr_14'] = tr.rolling(14).mean()\n",
    "    df['atr_20'] = tr.rolling(20).mean()\n",
    "    df['atr_pips'] = df['atr_14'] * 10000\n",
    "    df['atr_pct'] = df['atr_14'] / df['close'] * 100\n",
    "    \n",
    "    # Bollinger\n",
    "    df['bb_middle'] = df['close'].rolling(20).mean()\n",
    "    bb_std = df['close'].rolling(20).std()\n",
    "    df['bb_upper'] = df['bb_middle'] + 2 * bb_std\n",
    "    df['bb_lower'] = df['bb_middle'] - 2 * bb_std\n",
    "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle'] * 100\n",
    "    df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-10)\n",
    "    df['bb_squeeze'] = (df['bb_width'] < df['bb_width'].rolling(50).mean()).astype(int)\n",
    "    \n",
    "    # Candles\n",
    "    df['candle_body'] = df['close'] - df['open']\n",
    "    df['candle_range'] = df['high'] - df['low']\n",
    "    df['candle_body_pct'] = df['candle_body'] / (df['candle_range'] + 1e-10)\n",
    "    df['upper_shadow'] = df['high'] - df[['open', 'close']].max(axis=1)\n",
    "    df['lower_shadow'] = df[['open', 'close']].min(axis=1) - df['low']\n",
    "    df['is_bullish'] = (df['close'] > df['open']).astype(int)\n",
    "    df['is_hammer'] = ((df['lower_shadow'] > df['candle_body'].abs() * 2) & \n",
    "                       (df['upper_shadow'] < df['candle_body'].abs() * 0.5)).astype(int)\n",
    "    df['bullish_engulfing'] = ((df['is_bullish'] == 1) & \n",
    "                               (df['is_bullish'].shift(1) == 0) &\n",
    "                               (df['close'] > df['open'].shift(1))).astype(int)\n",
    "    \n",
    "    # Pivot\n",
    "    df['pivot'] = (df['high'].shift() + df['low'].shift() + df['close'].shift()) / 3\n",
    "    df['r1'] = 2 * df['pivot'] - df['low'].shift()\n",
    "    df['s1'] = 2 * df['pivot'] - df['high'].shift()\n",
    "    df['r2'] = df['pivot'] + (df['high'].shift() - df['low'].shift())\n",
    "    df['s2'] = df['pivot'] - (df['high'].shift() - df['low'].shift())\n",
    "    df['near_support'] = (df['close'] < df['s1'] * 1.001).astype(int)\n",
    "    \n",
    "    # Trend\n",
    "    df['trend_short'] = np.where(df['ema_10'] > df['ema_20'], 1, -1)\n",
    "    df['trend_medium'] = np.where(df['ema_20'] > df['ema_50'], 1, -1)\n",
    "    df['trend_long'] = np.where(df['ema_50'] > df['ema_200'], 1, -1)\n",
    "    df['trend_alignment'] = df['trend_short'] + df['trend_medium'] + df['trend_long']\n",
    "    df['strong_uptrend'] = (df['trend_alignment'] == 3).astype(int)\n",
    "    \n",
    "    df['buy_score'] = (\n",
    "        df['macd_bullish'] + df['rsi_bullish'] + df['sma_5_20_cross'] +\n",
    "        df['golden_cross'] + df['price_above_all_ma'] + df['strong_uptrend']\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# V2 Signal Labels\n",
    "def create_signal_labels_v5(df, forward_periods=60, min_move_pips=15):\n",
    "    df = df.copy()\n",
    "    min_move = min_move_pips * 0.0001\n",
    "    \n",
    "    df['future_max'] = df['high'].rolling(window=forward_periods).max().shift(-forward_periods)\n",
    "    df['future_min'] = df['low'].rolling(window=forward_periods).min().shift(-forward_periods)\n",
    "    \n",
    "    df['up_move'] = df['future_max'] - df['close']\n",
    "    df['down_move'] = df['close'] - df['future_min']\n",
    "    \n",
    "    conditions = [\n",
    "        (df['up_move'] >= min_move) & (df['up_move'] > df['down_move'] * 1.5),\n",
    "        (df['down_move'] >= min_move) & (df['down_move'] > df['up_move'] * 1.5),\n",
    "    ]\n",
    "    choices = [1, -1]\n",
    "    df['signal'] = np.select(conditions, choices, default=0)\n",
    "    \n",
    "    df.drop(['future_max', 'future_min', 'up_move', 'down_move'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Apply\n",
    "print(\"Adding V5 improved features...\")\n",
    "train_df_v5 = add_v5_improved_features(train_df_v5)\n",
    "test_df_v5 = add_v5_improved_features(test_df_v5)\n",
    "\n",
    "train_df_v5 = create_signal_labels_v5(train_df_v5)\n",
    "test_df_v5 = create_signal_labels_v5(test_df_v5)\n",
    "\n",
    "# Filter BUY/SELL only\n",
    "train_binary_v5 = train_df_v5[train_df_v5['signal'] != 0].copy()\n",
    "test_binary_v5 = test_df_v5[test_df_v5['signal'] != 0].copy()\n",
    "\n",
    "# Prepare data\n",
    "exclude_v5 = ['time', 'signal', 'open', 'high', 'low', 'close', 'volume', 'tick_volume']\n",
    "feature_cols_v5 = [c for c in train_binary_v5.columns if c not in exclude_v5]\n",
    "\n",
    "train_clean_v5 = train_binary_v5.dropna(subset=feature_cols_v5).copy()\n",
    "test_clean_v5 = test_binary_v5.dropna(subset=feature_cols_v5).copy()\n",
    "\n",
    "X_train_v5 = train_clean_v5[feature_cols_v5].values\n",
    "y_train_v5 = ((train_clean_v5['signal'].values + 1) / 2).astype(int)  # -1->0, 1->1\n",
    "\n",
    "X_test_v5 = test_clean_v5[feature_cols_v5].values\n",
    "y_test_v5 = ((test_clean_v5['signal'].values + 1) / 2).astype(int)\n",
    "\n",
    "scaler_v5 = StandardScaler()\n",
    "X_train_v5_scaled = scaler_v5.fit_transform(X_train_v5)\n",
    "X_test_v5_scaled = scaler_v5.transform(X_test_v5)\n",
    "\n",
    "print(f\"\\nâœ“ Train: {len(train_clean_v5):,} samples (BUY/SELL only)\")\n",
    "print(f\"âœ“ Test: {len(test_clean_v5):,} samples\")\n",
    "print(f\"âœ“ Features: {len(feature_cols_v5)}\")\n",
    "print(f\"âœ“ BUY ratio (train): {y_train_v5.mean()*100:.1f}%\")\n",
    "print(f\"âœ“ BUY ratio (test): {y_test_v5.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a15235e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸŽ¯ TRAINING V5 IMPROVED MODELS\n",
      "======================================================================\n",
      "Class weight: 1.03\n",
      "\n",
      "Training XGBoost V5...\n",
      "  âœ“ XGBoost: 50.22%\n",
      "\n",
      "Training LightGBM V5...\n",
      "  âœ“ XGBoost: 50.22%\n",
      "\n",
      "Training LightGBM V5...\n",
      "  âœ“ LightGBM: 49.67%\n",
      "\n",
      "Training Random Forest V5...\n",
      "  âœ“ LightGBM: 49.67%\n",
      "\n",
      "Training Random Forest V5...\n",
      "  âœ“ Random Forest: 51.34%\n",
      "  âœ“ Random Forest: 51.34%\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# TRAIN V5 IMPROVED MODELS\n",
    "# ================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸŽ¯ TRAINING V5 IMPROVED MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Class weight\n",
    "neg_v5 = (y_train_v5 == 0).sum()\n",
    "pos_v5 = (y_train_v5 == 1).sum()\n",
    "scale_weight_v5 = neg_v5 / pos_v5\n",
    "print(f\"Class weight: {scale_weight_v5:.2f}\")\n",
    "\n",
    "# XGBoost\n",
    "print(\"\\nTraining XGBoost V5...\")\n",
    "xgb_v5 = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    verbosity=0,\n",
    "    tree_method='hist',\n",
    "    device='cuda' if GPU_AVAILABLE else 'cpu'\n",
    ")\n",
    "xgb_v5.fit(X_train_v5_scaled, y_train_v5)\n",
    "xgb_v5_pred = xgb_v5.predict(X_test_v5_scaled)\n",
    "xgb_v5_proba = xgb_v5.predict_proba(X_test_v5_scaled)\n",
    "print(f\"  âœ“ XGBoost: {accuracy_score(y_test_v5, xgb_v5_pred)*100:.2f}%\")\n",
    "\n",
    "# LightGBM\n",
    "print(\"\\nTraining LightGBM V5...\")\n",
    "lgb_v5 = lgb.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lgb_v5.fit(X_train_v5_scaled, y_train_v5)\n",
    "lgb_v5_pred = lgb_v5.predict(X_test_v5_scaled)\n",
    "lgb_v5_proba = lgb_v5.predict_proba(X_test_v5_scaled)\n",
    "print(f\"  âœ“ LightGBM: {accuracy_score(y_test_v5, lgb_v5_pred)*100:.2f}%\")\n",
    "\n",
    "# Random Forest\n",
    "print(\"\\nTraining Random Forest V5...\")\n",
    "rf_v5 = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_v5.fit(X_train_v5_scaled, y_train_v5)\n",
    "rf_v5_pred = rf_v5.predict(X_test_v5_scaled)\n",
    "rf_v5_proba = rf_v5.predict_proba(X_test_v5_scaled)\n",
    "print(f\"  âœ“ Random Forest: {accuracy_score(y_test_v5, rf_v5_pred)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edf0160d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸ“Š V5 IMPROVED vs V2 COMPARISON\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š V5 IMPROVED BUY Signal Accuracy:\n",
      "--------------------------------------------------\n",
      "   Conf >= 70%:  3885 signals | Accuracy: 52.7%\n",
      "   Conf >= 75%:  1053 signals | Accuracy: 58.7%\n",
      "   Conf >= 80%:   274 signals | Accuracy: 55.5%\n",
      "   Conf >= 85%:    83 signals | Accuracy: 59.0%\n",
      "   Conf >= 90%:    10 signals | Accuracy: 30.0%\n",
      "\n",
      "======================================================================\n",
      "ðŸ“Š FINAL COMPARISON: V5 IMPROVED vs V2\n",
      "======================================================================\n",
      "\n",
      "   Threshold | V2 Signals |   V2 Acc | V5 Signals |   V5 Acc |   Winner\n",
      "---------------------------------------------------------------------------\n",
      "        70%+ |       2344 |    51.8% |       3885 |    52.7% |     V5 âœ“\n",
      "        75%+ |        663 |    55.1% |       1053 |    58.7% |     V5 âœ“\n",
      "        80%+ |        112 |    58.9% |        274 |    55.5% |     V2 âœ“\n",
      "        85%+ |          3 |    33.3% |         83 |    59.0% |     V5 âœ“\n",
      "        90%+ |          0 |     0.0% |         10 |    30.0% |     V5 âœ“\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# V5 IMPROVED ENSEMBLE + V2 COMPARISON\n",
    "# ================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“Š V5 IMPROVED vs V2 COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# V5 Ensemble\n",
    "weights_v5 = [0.4, 0.35, 0.25]\n",
    "avg_proba_v5 = (weights_v5[0] * xgb_v5_proba + weights_v5[1] * lgb_v5_proba + weights_v5[2] * rf_v5_proba)\n",
    "buy_prob_v5 = avg_proba_v5[:, 1] * 100\n",
    "\n",
    "# Model agreement\n",
    "agree_v5 = (xgb_v5_pred == 1) & (lgb_v5_pred == 1) & (rf_v5_pred == 1)\n",
    "conf_v5 = buy_prob_v5.copy()\n",
    "conf_v5[agree_v5] = np.minimum(conf_v5[agree_v5] + 5, 100)\n",
    "\n",
    "print(f\"\\nðŸ“Š V5 IMPROVED BUY Signal Accuracy:\")\n",
    "print(\"-\"*50)\n",
    "for thresh in [70, 75, 80, 85, 90]:\n",
    "    mask = conf_v5 >= thresh\n",
    "    if mask.sum() > 0:\n",
    "        signals = mask.sum()\n",
    "        acc = y_test_v5[mask].mean() * 100\n",
    "        print(f\"   Conf >= {thresh}%: {signals:>5} signals | Accuracy: {acc:.1f}%\")\n",
    "\n",
    "# Compare with V2\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š FINAL COMPARISON: V5 IMPROVED vs V2\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Threshold':>12} | {'V2 Signals':>10} | {'V2 Acc':>8} | {'V5 Signals':>10} | {'V5 Acc':>8} | {'Winner':>8}\")\n",
    "print(\"-\"*75)\n",
    "\n",
    "for thresh in [70, 75, 80, 85, 90]:\n",
    "    # V2 (from earlier cell)\n",
    "    v2_mask = v2_confidence >= thresh\n",
    "    v2_sig = v2_mask.sum()\n",
    "    v2_acc = y_test_v2[v2_mask].mean() * 100 if v2_sig > 0 else 0\n",
    "    \n",
    "    # V5 Improved\n",
    "    v5_mask = conf_v5 >= thresh\n",
    "    v5_sig = v5_mask.sum()\n",
    "    v5_acc = y_test_v5[v5_mask].mean() * 100 if v5_sig > 0 else 0\n",
    "    \n",
    "    winner = \"V5 âœ“\" if v5_acc > v2_acc else (\"V2 âœ“\" if v2_acc > v5_acc else \"TIE\")\n",
    "    print(f\"{thresh:>10}%+ | {v2_sig:>10} | {v2_acc:>7.1f}% | {v5_sig:>10} | {v5_acc:>7.1f}% | {winner:>8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63a912d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving V5 Improved models...\n",
      "âœ… V5 Improved Models saved to c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v5\n",
      "âœ… V5 Improved Models saved to c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v5\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# SAVE V5 IMPROVED MODELS (if better than V2)\n",
    "# ================================================================\n",
    "print(\"Saving V5 Improved models...\")\n",
    "\n",
    "joblib.dump(xgb_v5, MODEL_DIR / 'xgboost_v5.joblib')\n",
    "joblib.dump(lgb_v5, MODEL_DIR / 'lightgbm_v5.joblib')\n",
    "joblib.dump(rf_v5, MODEL_DIR / 'rf_v5.joblib')\n",
    "joblib.dump(scaler_v5, MODEL_DIR / 'scaler_v5.joblib')\n",
    "joblib.dump(feature_cols_v5, MODEL_DIR / 'feature_cols_v5.joblib')\n",
    "\n",
    "config_v5 = {\n",
    "    'version': 'v5_improved',\n",
    "    'mode': 'BUY_vs_SELL',\n",
    "    'min_confidence': 80,\n",
    "    'weights': weights_v5,\n",
    "    'labeling': 'V2 compatible (15 pips, 1.5x ratio)'\n",
    "}\n",
    "joblib.dump(config_v5, MODEL_DIR / 'config_v5.joblib')\n",
    "\n",
    "print(f\"âœ… V5 Improved Models saved to {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "907845f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“Š FULL METRICS COMPARISON: V2 vs V5\n",
      "   (Same test data: 80,296 BUY/SELL samples)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š V2 MODEL METRICS (Test Data)\n",
      "================================================================================\n",
      "\n",
      "Model           |   Accuracy |  Precision |     Recall |   F1-Score |    ROC-AUC\n",
      "--------------------------------------------------------------------------------\n",
      "XGBoost         |      49.6% |       0.54 |       0.25 |       0.34 |       0.51\n",
      "LightGBM        |      49.6% |       0.55 |       0.18 |       0.28 |       0.51\n",
      "Random Forest   |      51.4% |       0.55 |       0.40 |       0.46 |       0.53\n",
      "--------------------------------------------------------------------------------\n",
      "ENSEMBLE V2     |      49.6% |       0.54 |       0.23 |       0.32 |       0.51\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š V5 MODEL METRICS (Test Data)\n",
      "================================================================================\n",
      "\n",
      "Model           |   Accuracy |  Precision |     Recall |   F1-Score |    ROC-AUC\n",
      "--------------------------------------------------------------------------------\n",
      "XGBoost         |      50.2% |       0.52 |       0.50 |       0.51 |       0.50\n",
      "LightGBM        |      49.7% |       0.52 |       0.48 |       0.50 |       0.50\n",
      "Random Forest   |      51.3% |       0.53 |       0.55 |       0.54 |       0.51\n",
      "--------------------------------------------------------------------------------\n",
      "ENSEMBLE V5     |      50.4% |       0.53 |       0.51 |       0.52 |       0.50\n",
      "\n",
      "================================================================================\n",
      "âš ï¸  Ð¢ÐÐÐ« Ð¥Ð­Ð›Ð¡Ð­Ð V2 Ò®Ð—Ò®Ò®Ð›Ð­Ð›Ð¢Ò®Ò®Ð” (Accuracy 90%, ROC-AUC 0.87)\n",
      "    Ð­Ð½Ñ Ð½ÑŒ TRAIN DATA Ð´ÑÑÑ€ ÑÑÐ²ÑÐ» Ó©Ó©Ñ€ TEST DATA Ð´ÑÑÑ€ Ñ‚Ð¾Ð¾Ñ†Ð¾Ð¾Ð»ÑÐ¾Ð½ Ð±Ð°Ð¹Ð¶ Ð¼Ð°Ð³Ð°Ð´Ð³Ò¯Ð¹.\n",
      "    Ð”ÑÑÑ€Ñ… Ò¯Ñ€ Ð´Ò¯Ð½Ð³Ò¯Ò¯Ð´ Ð±Ð¾Ð» EUR_USD_test.csv Ð´ÑÑÑ€Ñ… Ð±Ð¾Ð´Ð¸Ñ‚ TEST Ò¯Ð·Ò¯Ò¯Ð»ÑÐ»Ñ‚Ò¯Ò¯Ð´.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# FULL METRICS COMPARISON: V2 vs V5 (Same Test Data)\n",
    "# ================================================================\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸ“Š FULL METRICS COMPARISON: V2 vs V5\")\n",
    "print(\"   (Same test data: 80,296 BUY/SELL samples)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# V2 Ensemble predictions\n",
    "v2_ensemble_pred = (v2_avg_proba[:, 1] > 0.5).astype(int)\n",
    "v2_ensemble_proba = v2_avg_proba[:, 1]\n",
    "\n",
    "# V5 Ensemble predictions  \n",
    "v5_ensemble_pred = (avg_proba_v5[:, 1] > 0.5).astype(int)\n",
    "v5_ensemble_proba = avg_proba_v5[:, 1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š V2 MODEL METRICS (Test Data)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Model':<15} | {'Accuracy':>10} | {'Precision':>10} | {'Recall':>10} | {'F1-Score':>10} | {'ROC-AUC':>10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# V2 XGBoost\n",
    "print(f\"{'XGBoost':<15} | {accuracy_score(y_test_v2, v2_xgb_pred)*100:>9.1f}% | {precision_score(y_test_v2, v2_xgb_pred):>10.2f} | {recall_score(y_test_v2, v2_xgb_pred):>10.2f} | {f1_score(y_test_v2, v2_xgb_pred):>10.2f} | {roc_auc_score(y_test_v2, v2_xgb_proba[:, 1]):>10.2f}\")\n",
    "\n",
    "# V2 LightGBM\n",
    "print(f\"{'LightGBM':<15} | {accuracy_score(y_test_v2, v2_lgb_pred)*100:>9.1f}% | {precision_score(y_test_v2, v2_lgb_pred):>10.2f} | {recall_score(y_test_v2, v2_lgb_pred):>10.2f} | {f1_score(y_test_v2, v2_lgb_pred):>10.2f} | {roc_auc_score(y_test_v2, v2_lgb_proba[:, 1]):>10.2f}\")\n",
    "\n",
    "# V2 Random Forest\n",
    "print(f\"{'Random Forest':<15} | {accuracy_score(y_test_v2, v2_rf_pred)*100:>9.1f}% | {precision_score(y_test_v2, v2_rf_pred):>10.2f} | {recall_score(y_test_v2, v2_rf_pred):>10.2f} | {f1_score(y_test_v2, v2_rf_pred):>10.2f} | {roc_auc_score(y_test_v2, v2_rf_proba[:, 1]):>10.2f}\")\n",
    "\n",
    "# V2 Ensemble\n",
    "print(\"-\"*80)\n",
    "print(f\"{'ENSEMBLE V2':<15} | {accuracy_score(y_test_v2, v2_ensemble_pred)*100:>9.1f}% | {precision_score(y_test_v2, v2_ensemble_pred):>10.2f} | {recall_score(y_test_v2, v2_ensemble_pred):>10.2f} | {f1_score(y_test_v2, v2_ensemble_pred):>10.2f} | {roc_auc_score(y_test_v2, v2_ensemble_proba):>10.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š V5 MODEL METRICS (Test Data)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Model':<15} | {'Accuracy':>10} | {'Precision':>10} | {'Recall':>10} | {'F1-Score':>10} | {'ROC-AUC':>10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# V5 XGBoost\n",
    "print(f\"{'XGBoost':<15} | {accuracy_score(y_test_v5, xgb_v5_pred)*100:>9.1f}% | {precision_score(y_test_v5, xgb_v5_pred):>10.2f} | {recall_score(y_test_v5, xgb_v5_pred):>10.2f} | {f1_score(y_test_v5, xgb_v5_pred):>10.2f} | {roc_auc_score(y_test_v5, xgb_v5_proba[:, 1]):>10.2f}\")\n",
    "\n",
    "# V5 LightGBM\n",
    "print(f\"{'LightGBM':<15} | {accuracy_score(y_test_v5, lgb_v5_pred)*100:>9.1f}% | {precision_score(y_test_v5, lgb_v5_pred):>10.2f} | {recall_score(y_test_v5, lgb_v5_pred):>10.2f} | {f1_score(y_test_v5, lgb_v5_pred):>10.2f} | {roc_auc_score(y_test_v5, lgb_v5_proba[:, 1]):>10.2f}\")\n",
    "\n",
    "# V5 Random Forest\n",
    "print(f\"{'Random Forest':<15} | {accuracy_score(y_test_v5, rf_v5_pred)*100:>9.1f}% | {precision_score(y_test_v5, rf_v5_pred):>10.2f} | {recall_score(y_test_v5, rf_v5_pred):>10.2f} | {f1_score(y_test_v5, rf_v5_pred):>10.2f} | {roc_auc_score(y_test_v5, rf_v5_proba[:, 1]):>10.2f}\")\n",
    "\n",
    "# V5 Ensemble\n",
    "print(\"-\"*80)\n",
    "print(f\"{'ENSEMBLE V5':<15} | {accuracy_score(y_test_v5, v5_ensemble_pred)*100:>9.1f}% | {precision_score(y_test_v5, v5_ensemble_pred):>10.2f} | {recall_score(y_test_v5, v5_ensemble_pred):>10.2f} | {f1_score(y_test_v5, v5_ensemble_pred):>10.2f} | {roc_auc_score(y_test_v5, v5_ensemble_proba):>10.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âš ï¸  Ð¢ÐÐÐ« Ð¥Ð­Ð›Ð¡Ð­Ð V2 Ò®Ð—Ò®Ò®Ð›Ð­Ð›Ð¢Ò®Ò®Ð” (Accuracy 90%, ROC-AUC 0.87)\")\n",
    "print(\"    Ð­Ð½Ñ Ð½ÑŒ TRAIN DATA Ð´ÑÑÑ€ ÑÑÐ²ÑÐ» Ó©Ó©Ñ€ TEST DATA Ð´ÑÑÑ€ Ñ‚Ð¾Ð¾Ñ†Ð¾Ð¾Ð»ÑÐ¾Ð½ Ð±Ð°Ð¹Ð¶ Ð¼Ð°Ð³Ð°Ð´Ð³Ò¯Ð¹.\")\n",
    "print(\"    Ð”ÑÑÑ€Ñ… Ò¯Ñ€ Ð´Ò¯Ð½Ð³Ò¯Ò¯Ð´ Ð±Ð¾Ð» EUR_USD_test.csv Ð´ÑÑÑ€Ñ… Ð±Ð¾Ð´Ð¸Ñ‚ TEST Ò¯Ð·Ò¯Ò¯Ð»ÑÐ»Ñ‚Ò¯Ò¯Ð´.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbb20caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“Š V2 BUY-ONLY BACKTEST (TP=15 pips min move)\n",
      "   V2 BUY Ð´Ð¾Ñ…Ð¸Ð¾ Ó©Ð³Ó©Ñ…Ó©Ð´ TP Ñ…Ò¯Ñ€ÑÑ… ÑÑÑÑ…Ð¸Ð¹Ð³ ÑˆÐ°Ð»Ð³Ð°Ñ…\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š V2 BUY Signal Performance (High Confidence Only):\n",
      "------------------------------------------------------------\n",
      "  Confidence |    Signals |    Correct |   Accuracy\n",
      "------------------------------------------------------------\n",
      "        70%+ |       2344 |       1214 |      51.8%\n",
      "        75%+ |        663 |        365 |      55.1%\n",
      "        80%+ |        112 |         66 |      58.9%\n",
      "        85%+ |          3 |          1 |      33.3%\n",
      "\n",
      "ðŸ“Š V5 BUY Signal Performance (High Confidence Only):\n",
      "------------------------------------------------------------\n",
      "  Confidence |    Signals |    Correct |   Accuracy\n",
      "------------------------------------------------------------\n",
      "        70%+ |       3885 |       2047 |      52.7%\n",
      "        75%+ |       1053 |        618 |      58.7%\n",
      "        80%+ |        274 |        152 |      55.5%\n",
      "        85%+ |         83 |         49 |      59.0%\n",
      "        90%+ |         10 |          3 |      30.0%\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š V2 vs V5 BUY-ONLY COMPARISON (High Confidence Signals)\n",
      "================================================================================\n",
      "\n",
      "   Threshold | V2 Signals |   V2 Acc | V5 Signals |   V5 Acc |   Winner\n",
      "---------------------------------------------------------------------------\n",
      "        70%+ |       2344 |    51.8% |       3885 |    52.7% |     V5 âœ“\n",
      "        75%+ |        663 |    55.1% |       1053 |    58.7% |     V5 âœ“\n",
      "        80%+ |        112 |    58.9% |        274 |    55.5% |     V2 âœ“\n",
      "        85%+ |          3 |    33.3% |         83 |    59.0% |     V5 âœ“\n",
      "        90%+ |          0 |     0.0% |         10 |    30.0% |     V5 âœ“\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# V2 BUY-ONLY BACKTEST (TP/SL based - REAL performance)\n",
    "# ================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸ“Š V2 BUY-ONLY BACKTEST (TP=15 pips min move)\")\n",
    "print(\"   V2 BUY Ð´Ð¾Ñ…Ð¸Ð¾ Ó©Ð³Ó©Ñ…Ó©Ð´ TP Ñ…Ò¯Ñ€ÑÑ… ÑÑÑÑ…Ð¸Ð¹Ð³ ÑˆÐ°Ð»Ð³Ð°Ñ…\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# V2 test data-Ð³ TP/SL backtest Ñ…Ð¸Ð¹Ñ…\n",
    "# V2 BUY Ð´Ð¾Ñ…Ð¸Ð¾ = confidence >= threshold AND prediction = BUY (1)\n",
    "\n",
    "def backtest_buy_signals(df, confidence, predictions, y_actual, min_conf_list=[70, 75, 80, 85, 90]):\n",
    "    \"\"\"\n",
    "    Backtest BUY signals using TP/SL logic.\n",
    "    BUY signal given when: confidence >= threshold AND predicted class = 1 (BUY)\n",
    "    \n",
    "    Success = price went UP by min_move_pips within forward_periods\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for min_conf in min_conf_list:\n",
    "        # BUY signals: high confidence + predicted BUY\n",
    "        buy_mask = (confidence >= min_conf) & (predictions == 1)\n",
    "        \n",
    "        if buy_mask.sum() > 0:\n",
    "            # How many of these were actually good BUY opportunities?\n",
    "            # y_actual = 1 means it was labeled as BUY (up_move >= 15 pips, up > down * 1.5)\n",
    "            correct = y_actual[buy_mask].sum()\n",
    "            total = buy_mask.sum()\n",
    "            accuracy = correct / total * 100\n",
    "            \n",
    "            results[min_conf] = {\n",
    "                'signals': total,\n",
    "                'correct': correct,\n",
    "                'accuracy': accuracy\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# V2 Results\n",
    "print(\"\\nðŸ“Š V2 BUY Signal Performance (High Confidence Only):\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Confidence':>12} | {'Signals':>10} | {'Correct':>10} | {'Accuracy':>10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "v2_ensemble_pred_class = (v2_avg_proba[:, 1] > 0.5).astype(int)\n",
    "v2_results = backtest_buy_signals(test_binary_v2_clean, v2_confidence, v2_ensemble_pred_class, y_test_v2)\n",
    "\n",
    "for conf, res in v2_results.items():\n",
    "    print(f\"{conf:>10}%+ | {res['signals']:>10} | {res['correct']:>10} | {res['accuracy']:>9.1f}%\")\n",
    "\n",
    "# V5 Results\n",
    "print(\"\\nðŸ“Š V5 BUY Signal Performance (High Confidence Only):\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Confidence':>12} | {'Signals':>10} | {'Correct':>10} | {'Accuracy':>10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "v5_ensemble_pred_class = (avg_proba_v5[:, 1] > 0.5).astype(int)\n",
    "v5_results = backtest_buy_signals(test_clean_v5, conf_v5, v5_ensemble_pred_class, y_test_v5)\n",
    "\n",
    "for conf, res in v5_results.items():\n",
    "    print(f\"{conf:>10}%+ | {res['signals']:>10} | {res['correct']:>10} | {res['accuracy']:>9.1f}%\")\n",
    "\n",
    "# COMPARISON\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š V2 vs V5 BUY-ONLY COMPARISON (High Confidence Signals)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Threshold':>12} | {'V2 Signals':>10} | {'V2 Acc':>8} | {'V5 Signals':>10} | {'V5 Acc':>8} | {'Winner':>8}\")\n",
    "print(\"-\"*75)\n",
    "\n",
    "for conf in [70, 75, 80, 85, 90]:\n",
    "    v2_sig = v2_results.get(conf, {}).get('signals', 0)\n",
    "    v2_acc = v2_results.get(conf, {}).get('accuracy', 0)\n",
    "    v5_sig = v5_results.get(conf, {}).get('signals', 0)\n",
    "    v5_acc = v5_results.get(conf, {}).get('accuracy', 0)\n",
    "    \n",
    "    if v2_acc > v5_acc:\n",
    "        winner = \"V2 âœ“\"\n",
    "    elif v5_acc > v2_acc:\n",
    "        winner = \"V5 âœ“\"\n",
    "    else:\n",
    "        winner = \"TIE\"\n",
    "    \n",
    "    print(f\"{conf:>10}%+ | {v2_sig:>10} | {v2_acc:>7.1f}% | {v5_sig:>10} | {v5_acc:>7.1f}% | {winner:>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb6e8c",
   "metadata": {},
   "source": [
    "## 9. Save V5 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3233aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving V5 models...\n",
      "âœ… V5 Models saved to c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v5\n",
      "   - xgboost_v5.joblib (Calibrated)\n",
      "   - lightgbm_v5.joblib (Calibrated)\n",
      "   - rf_v5.joblib (Calibrated)\n",
      "   - scaler_v5.joblib\n",
      "   - feature_cols_v5.joblib\n",
      "   - config_v5.joblib\n",
      "âœ… V5 Models saved to c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v5\n",
      "   - xgboost_v5.joblib (Calibrated)\n",
      "   - lightgbm_v5.joblib (Calibrated)\n",
      "   - rf_v5.joblib (Calibrated)\n",
      "   - scaler_v5.joblib\n",
      "   - feature_cols_v5.joblib\n",
      "   - config_v5.joblib\n"
     ]
    }
   ],
   "source": [
    "# Save V5 models\n",
    "print(\"Saving V5 models...\")\n",
    "\n",
    "joblib.dump(xgb_model, MODEL_DIR / 'xgboost_v5.joblib')\n",
    "joblib.dump(lgb_model, MODEL_DIR / 'lightgbm_v5.joblib')\n",
    "joblib.dump(rf_model, MODEL_DIR / 'rf_v5.joblib')\n",
    "joblib.dump(scaler, MODEL_DIR / 'scaler_v5.joblib')\n",
    "joblib.dump(feature_cols, MODEL_DIR / 'feature_cols_v5.joblib')\n",
    "\n",
    "# Save config\n",
    "config = {\n",
    "    'version': 'v5',\n",
    "    'mode': 'BUY_ONLY',\n",
    "    'min_confidence': 80,\n",
    "    'tp_pips': 20,\n",
    "    'sl_pips': 10,\n",
    "    'weights': weights,\n",
    "    'calibrated': True\n",
    "}\n",
    "joblib.dump(config, MODEL_DIR / 'config_v5.joblib')\n",
    "\n",
    "print(f\"âœ… V5 Models saved to {MODEL_DIR}\")\n",
    "print(f\"   - xgboost_v5.joblib (Calibrated)\")\n",
    "print(f\"   - lightgbm_v5.joblib (Calibrated)\")\n",
    "print(f\"   - rf_v5.joblib (Calibrated)\")\n",
    "print(f\"   - scaler_v5.joblib\")\n",
    "print(f\"   - feature_cols_v5.joblib\")\n",
    "print(f\"   - config_v5.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
