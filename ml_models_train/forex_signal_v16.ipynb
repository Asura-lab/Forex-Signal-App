{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d8d46f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ FOREX SIGNAL V16: Multi-Timeframe Analysis (Combined Data)\n",
      "âœ“ Model Directory: c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import joblib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(r'c:\\Users\\Acer\\Desktop\\Forex-Signal-App')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "MODEL_DIR = BASE_DIR / 'models' / 'signal_generator_v16'\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Constants\n",
    "TIMEFRAMES = ['1min', '5min', '15min', '30min', '1h']\n",
    "TARGET_TIMEFRAME = '1min'  # We predict on 1-min data using MTF context\n",
    "FORWARD_BARS = 15          # Predict 15 minutes into the future\n",
    "TP_PIPS = 10\n",
    "SL_PIPS = 10\n",
    "\n",
    "print(f\"ðŸš€ FOREX SIGNAL V16: Multi-Timeframe Analysis (Combined Data)\")\n",
    "print(f\"âœ“ Model Directory: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff889997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TRAIN data...\n",
      "  1min: 3,354,904 rows\n",
      "  5min: 671,581 rows\n",
      "  15min: 224,382 rows\n",
      "  30min: 112,194 rows\n",
      "  1h: 56,098 rows\n",
      "  4h: 14,498 rows\n",
      "\n",
      "Loading TEST data...\n",
      "  1min: 743,476 rows\n",
      "  5min: 148,502 rows\n",
      "  15min: 49,807 rows\n",
      "  30min: 24,907 rows\n",
      "  1h: 12,454 rows\n",
      "  4h: 3,220 rows\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data (Train & Test Separately)\n",
    "def load_tf_data(timeframe, dataset_type='train'):\n",
    "    \"\"\"\n",
    "    Load specific timeframe data from train or test folder\n",
    "    \"\"\"\n",
    "    filename = f'EURUSD_{timeframe}.csv'\n",
    "    file_path = DATA_DIR / dataset_type / filename\n",
    "        \n",
    "    if not file_path.exists():\n",
    "        print(f\"âš ï¸ Warning: {file_path} not found.\")\n",
    "        return None\n",
    "        \n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Standardize columns\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    \n",
    "    # Ensure time column is datetime\n",
    "    if 'time' in df.columns:\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        df.set_index('time', inplace=True)\n",
    "        df.sort_index(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "timeframes_map = {\n",
    "    '1min': 'm1',\n",
    "    '5min': 'm5',\n",
    "    '15min': 'm15',\n",
    "    '30min': 'm30',\n",
    "    '1h': 'h1',\n",
    "    '4h': 'h4'\n",
    "}\n",
    "\n",
    "dfs_train = {}\n",
    "dfs_test = {}\n",
    "\n",
    "print(\"Loading TRAIN data...\")\n",
    "for tf_name, tf_code in timeframes_map.items():\n",
    "    dfs_train[tf_name] = load_tf_data(tf_code, 'train')\n",
    "    if dfs_train[tf_name] is not None:\n",
    "        print(f\"  {tf_name}: {len(dfs_train[tf_name]):,} rows\")\n",
    "\n",
    "print(\"\\nLoading TEST data...\")\n",
    "for tf_name, tf_code in timeframes_map.items():\n",
    "    dfs_test[tf_name] = load_tf_data(tf_code, 'test')\n",
    "    if dfs_test[tf_name] is not None:\n",
    "        print(f\"  {tf_name}: {len(dfs_test[tf_name]):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0afcb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TRAIN features...\n",
      "Processing TEST features...\n",
      "Feature engineering complete.\n"
     ]
    }
   ],
   "source": [
    "# 2. Feature Engineering\n",
    "def add_technical_indicators(df):\n",
    "    \"\"\"\n",
    "    Calculates technical indicators for a given dataframe.\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return None\n",
    "        \n",
    "    df = df.copy()\n",
    "    \n",
    "    # RSI (14)\n",
    "    delta = df['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / (loss + 1e-10)\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD (12, 26, 9)\n",
    "    ema12 = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    df['macd'] = ema12 - ema26\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
    "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    \n",
    "    # Bollinger Bands (20, 2)\n",
    "    df['bb_mid'] = df['close'].rolling(window=20).mean()\n",
    "    df['bb_std'] = df['close'].rolling(window=20).std()\n",
    "    df['bb_upper'] = df['bb_mid'] + (df['bb_std'] * 2)\n",
    "    df['bb_lower'] = df['bb_mid'] - (df['bb_std'] * 2)\n",
    "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_mid']\n",
    "    \n",
    "    # EMAs\n",
    "    for span in [9, 21, 50, 200]:\n",
    "        df[f'ema_{span}'] = df['close'].ewm(span=span, adjust=False).mean()\n",
    "        \n",
    "    # ATR (14)\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = (df['high'] - df['close'].shift()).abs()\n",
    "    low_close = (df['low'] - df['close'].shift()).abs()\n",
    "    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "    true_range = ranges.max(axis=1)\n",
    "    df['atr'] = true_range.rolling(14).mean()\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "def process_all_timeframes(dfs_dict):\n",
    "    processed = {}\n",
    "    for tf, df in dfs_dict.items():\n",
    "        if df is not None:\n",
    "            # print(f\"Processing {tf}...\")\n",
    "            processed[tf] = add_technical_indicators(df)\n",
    "            \n",
    "            # No renaming needed for independent models\n",
    "            # We keep original column names (open, high, low, close) \n",
    "            # so create_target can find them easily.\n",
    "            \n",
    "    return processed\n",
    "\n",
    "print(\"Processing TRAIN features...\")\n",
    "processed_train = process_all_timeframes(dfs_train)\n",
    "\n",
    "print(\"Processing TEST features...\")\n",
    "processed_test = process_all_timeframes(dfs_test)\n",
    "\n",
    "print(\"Feature engineering complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faa7f3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating targets for ALL timeframes...\n",
      "  Creating target for TRAIN 1min...\n",
      "  Creating target for TRAIN 5min...\n",
      "  Creating target for TRAIN 15min...\n",
      "  Creating target for TRAIN 30min...\n",
      "  Creating target for TRAIN 1h...\n",
      "  Creating target for TRAIN 4h...\n",
      "  Creating target for TEST 1min...\n",
      "  Creating target for TEST 5min...\n",
      "  Creating target for TEST 15min...\n",
      "  Creating target for TEST 30min...\n",
      "  Creating target for TEST 1h...\n",
      "  Creating target for TEST 4h...\n",
      "Target creation complete.\n"
     ]
    }
   ],
   "source": [
    "# 3. Define Target (Per Timeframe)\n",
    "def create_target(df, tp_pips=10, sl_pips=10, forward_bars=15):\n",
    "    targets = []\n",
    "    pip_size = 0.0001\n",
    "    tp = tp_pips * pip_size\n",
    "    sl = sl_pips * pip_size\n",
    "    \n",
    "    closes = df['close'].values\n",
    "    highs = df['high'].values\n",
    "    lows = df['low'].values\n",
    "    \n",
    "    for i in range(len(df) - forward_bars):\n",
    "        current_close = closes[i]\n",
    "        \n",
    "        # Look ahead window\n",
    "        future_highs = highs[i+1 : i+1+forward_bars]\n",
    "        future_lows = lows[i+1 : i+1+forward_bars]\n",
    "        \n",
    "        max_high = np.max(future_highs)\n",
    "        min_low = np.min(future_lows)\n",
    "        \n",
    "        # Check for Buy Signal\n",
    "        if (max_high - current_close) >= tp and (current_close - min_low) < sl:\n",
    "            targets.append(1) # BUY\n",
    "        # Check for Sell Signal\n",
    "        elif (current_close - min_low) >= tp and (max_high - current_close) < sl:\n",
    "            targets.append(2) # SELL\n",
    "        else:\n",
    "            targets.append(0) # HOLD\n",
    "            \n",
    "    # Pad the end\n",
    "    targets.extend([0] * forward_bars)\n",
    "    return np.array(targets)\n",
    "\n",
    "print(\"Creating targets for ALL timeframes...\")\n",
    "\n",
    "# Apply to TRAIN\n",
    "train_datasets = {}\n",
    "for tf, df in processed_train.items():\n",
    "    if df is not None and len(df) > FORWARD_BARS:\n",
    "        print(f\"  Creating target for TRAIN {tf}...\")\n",
    "        df = df.copy()\n",
    "        df['target'] = create_target(df, TP_PIPS, SL_PIPS, FORWARD_BARS)\n",
    "        train_datasets[tf] = df.iloc[:-FORWARD_BARS] # Remove last rows\n",
    "\n",
    "# Apply to TEST\n",
    "test_datasets = {}\n",
    "for tf, df in processed_test.items():\n",
    "    if df is not None and len(df) > FORWARD_BARS:\n",
    "        print(f\"  Creating target for TEST {tf}...\")\n",
    "        df = df.copy()\n",
    "        df['target'] = create_target(df, TP_PIPS, SL_PIPS, FORWARD_BARS)\n",
    "        test_datasets[tf] = df.iloc[:-FORWARD_BARS]\n",
    "\n",
    "print(\"Target creation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "103daa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model for 1min...\n",
      "  âœ“ 1min Model Trained.\n",
      "\n",
      "Training Model for 5min...\n",
      "  âœ“ 5min Model Trained.\n",
      "\n",
      "Training Model for 15min...\n",
      "  âœ“ 15min Model Trained.\n",
      "\n",
      "Training Model for 30min...\n",
      "  âœ“ 30min Model Trained.\n",
      "\n",
      "Training Model for 1h...\n",
      "  âœ“ 1h Model Trained.\n",
      "\n",
      "Training Model for 4h...\n",
      "  âœ“ 4h Model Trained.\n",
      "\n",
      "All models trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# 4. Train Independent Models (Ensemble of Ensembles)\n",
    "models = {}\n",
    "scalers = {}\n",
    "feature_cols_dict = {}\n",
    "\n",
    "for tf, df_train in train_datasets.items():\n",
    "    print(f\"\\nTraining Model for {tf}...\")\n",
    "    \n",
    "    # Define features (exclude target and raw OHLC)\n",
    "    cols = [c for c in df_train.columns if c not in ['target', 'open', 'high', 'low', 'close', 'tick_volume', 'spread', 'volume']]\n",
    "    # We might want to keep the 'time' index, but it's the index.\n",
    "    \n",
    "    X_train = df_train[cols]\n",
    "    y_train = df_train['target']\n",
    "    \n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Train XGBoost\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        objective='multi:softprob',\n",
    "        num_class=3,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    models[tf] = model\n",
    "    scalers[tf] = scaler\n",
    "    feature_cols_dict[tf] = cols\n",
    "    \n",
    "    print(f\"  âœ“ {tf} Model Trained.\")\n",
    "\n",
    "print(\"\\nAll models trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a998fe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined.\n"
     ]
    }
   ],
   "source": [
    "# 5. Evaluation Functions\n",
    "def get_predictions(models, scalers, datasets):\n",
    "    preds_dict = {}\n",
    "    for tf, df in datasets.items():\n",
    "        if tf in models:\n",
    "            # print(f\"  Predicting {tf}...\")\n",
    "            model = models[tf]\n",
    "            scaler = scalers[tf]\n",
    "            cols = feature_cols_dict[tf]\n",
    "            \n",
    "            X = df[cols]\n",
    "            X_scaled = scaler.transform(X)\n",
    "            \n",
    "            probs = model.predict_proba(X_scaled)\n",
    "            preds_df = pd.DataFrame(probs, columns=['HOLD', 'BUY', 'SELL'], index=df.index)\n",
    "            preds_dict[tf] = preds_df\n",
    "    return preds_dict\n",
    "\n",
    "def evaluate_ensemble(preds_dict, datasets, name=\"Set\"):\n",
    "    base_tf = '1min'\n",
    "    if base_tf not in datasets:\n",
    "        print(f\"Error: 1min data needed for {name} evaluation.\")\n",
    "        return\n",
    "\n",
    "    base_index = datasets[base_tf].index\n",
    "    agg_probs = pd.DataFrame(0.0, index=base_index, columns=['HOLD', 'BUY', 'SELL'])\n",
    "    \n",
    "    count = 0\n",
    "    for tf, preds_df in preds_dict.items():\n",
    "        # Align to 1min\n",
    "        # Forward fill to propagate higher timeframe signals to 1min bars\n",
    "        aligned_preds = preds_df.reindex(base_index, method='ffill')\n",
    "        agg_probs = agg_probs.add(aligned_preds, fill_value=0)\n",
    "        count += 1\n",
    "        \n",
    "    final_probs = agg_probs / count\n",
    "    final_classes = final_probs.idxmax(axis=1)\n",
    "    \n",
    "    class_map = {'HOLD': 0, 'BUY': 1, 'SELL': 2}\n",
    "    y_pred = final_classes.map(class_map).fillna(0).astype(int)\n",
    "    y_true = datasets[base_tf]['target'].reindex(base_index).fillna(0).astype(int)\n",
    "    \n",
    "    print(f\"\\n=== {name} Ensemble Performance ===\")\n",
    "    print(f\"Overall Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # --- Trade Only Evaluation ---\n",
    "    # Filter where model predicted BUY (1) or SELL (2)\n",
    "    trade_mask = y_pred != 0\n",
    "    if trade_mask.sum() > 0:\n",
    "        trade_preds = y_pred[trade_mask]\n",
    "        trade_actuals = y_true[trade_mask]\n",
    "        \n",
    "        print(f\"\\n=== {name} Trade Only Performance (Excluding HOLD predictions) ===\")\n",
    "        print(f\"Total Trades Predicted: {len(trade_preds)}\")\n",
    "        print(f\"Trade Accuracy: {accuracy_score(trade_actuals, trade_preds):.4f}\")\n",
    "        \n",
    "        # We are interested if the trade was correct. \n",
    "        # Note: If model predicts BUY(1) but actual is SELL(2), it's a loss.\n",
    "        # If model predicts BUY(1) but actual is HOLD(0), it's a loss (false signal).\n",
    "        \n",
    "        print(classification_report(trade_actuals, trade_preds, zero_division=0))\n",
    "    else:\n",
    "        print(f\"\\n=== {name} Trade Only Performance ===\")\n",
    "        print(\"No trades predicted (All HOLD).\")\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "print(\"Evaluation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db8772e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for TRAINING set...\n",
      "\n",
      "=== TRAIN Ensemble Performance ===\n",
      "Overall Accuracy: 0.8632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93   2902360\n",
      "           1       0.17      0.00      0.01    224491\n",
      "           2       0.19      0.01      0.01    228019\n",
      "\n",
      "    accuracy                           0.86   3354870\n",
      "   macro avg       0.41      0.34      0.32   3354870\n",
      "weighted avg       0.77      0.86      0.80   3354870\n",
      "\n",
      "\n",
      "=== TRAIN Trade Only Performance (Excluding HOLD predictions) ===\n",
      "Total Trades Predicted: 11831\n",
      "Trade Accuracy: 0.1806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      8527\n",
      "           1       0.17      0.61      0.26      1606\n",
      "           2       0.19      0.68      0.30      1698\n",
      "\n",
      "    accuracy                           0.18     11831\n",
      "   macro avg       0.12      0.43      0.19     11831\n",
      "weighted avg       0.05      0.18      0.08     11831\n",
      "\n",
      "\n",
      "Generating predictions for TEST set...\n",
      "\n",
      "=== TEST Ensemble Performance ===\n",
      "Overall Accuracy: 0.9078\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95    674901\n",
      "           1       0.07      0.00      0.00     33974\n",
      "           2       0.20      0.00      0.00     34567\n",
      "\n",
      "    accuracy                           0.91    743442\n",
      "   macro avg       0.39      0.33      0.32    743442\n",
      "weighted avg       0.84      0.91      0.86    743442\n",
      "\n",
      "\n",
      "=== TEST Trade Only Performance (Excluding HOLD predictions) ===\n",
      "Total Trades Predicted: 47\n",
      "Trade Accuracy: 0.1277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.07      0.17      0.10        12\n",
      "           2       0.20      0.22      0.21        18\n",
      "\n",
      "    accuracy                           0.13        47\n",
      "   macro avg       0.09      0.13      0.10        47\n",
      "weighted avg       0.10      0.13      0.11        47\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(time\n",
       " 2024-01-01 22:19:00    0\n",
       " 2024-01-01 22:20:00    0\n",
       " 2024-01-01 22:21:00    0\n",
       " 2024-01-01 22:22:00    0\n",
       " 2024-01-01 22:23:00    0\n",
       "                       ..\n",
       " 2025-12-30 23:40:00    0\n",
       " 2025-12-30 23:41:00    0\n",
       " 2025-12-30 23:42:00    0\n",
       " 2025-12-30 23:43:00    0\n",
       " 2025-12-30 23:44:00    0\n",
       " Name: target, Length: 743442, dtype: int64,\n",
       " time\n",
       " 2024-01-01 22:19:00    0\n",
       " 2024-01-01 22:20:00    0\n",
       " 2024-01-01 22:21:00    0\n",
       " 2024-01-01 22:22:00    0\n",
       " 2024-01-01 22:23:00    0\n",
       "                       ..\n",
       " 2025-12-30 23:40:00    0\n",
       " 2025-12-30 23:41:00    0\n",
       " 2025-12-30 23:42:00    0\n",
       " 2025-12-30 23:43:00    0\n",
       " 2025-12-30 23:44:00    0\n",
       " Length: 743442, dtype: int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Run Evaluation (Train vs Test)\n",
    "print(\"Generating predictions for TRAINING set...\")\n",
    "train_preds = get_predictions(models, scalers, train_datasets)\n",
    "evaluate_ensemble(train_preds, train_datasets, \"TRAIN\")\n",
    "\n",
    "print(\"\\nGenerating predictions for TEST set...\")\n",
    "test_preds = get_predictions(models, scalers, test_datasets)\n",
    "evaluate_ensemble(test_preds, test_datasets, \"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b63780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models...\n",
      "Models saved to c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v16\n"
     ]
    }
   ],
   "source": [
    "# 7. Save Models\n",
    "print(\"Saving models...\")\n",
    "joblib.dump(models, MODEL_DIR / 'models_dict_v16.joblib')\n",
    "joblib.dump(scalers, MODEL_DIR / 'scalers_dict_v16.joblib')\n",
    "joblib.dump(feature_cols_dict, MODEL_DIR / 'feature_cols_dict_v16.joblib')\n",
    "\n",
    "# Save config\n",
    "config = {\n",
    "    'timeframes': TIMEFRAMES,\n",
    "    'tp_pips': TP_PIPS,\n",
    "    'sl_pips': SL_PIPS,\n",
    "    'forward_bars': FORWARD_BARS,\n",
    "    'strategy': 'ensemble_of_ensembles'\n",
    "}\n",
    "joblib.dump(config, MODEL_DIR / 'config_v16.joblib')\n",
    "\n",
    "print(f\"Models saved to {MODEL_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
