{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bdfddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ FOREX SIGNAL V17: Hybrid Multi-Timeframe Ensemble\n",
      "âœ“ Model Directory: c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import joblib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(r'c:\\Users\\Acer\\Desktop\\Forex-Signal-App')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "MODEL_DIR = BASE_DIR / 'models' / 'signal_generator_v17'\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Constants\n",
    "TIMEFRAMES = ['1min', '5min', '15min', '30min', '1h', '4h']\n",
    "FORWARD_BARS = 15\n",
    "TP_PIPS = 10\n",
    "SL_PIPS = 10\n",
    "\n",
    "print(f\"ðŸš€ FOREX SIGNAL V17: Hybrid Multi-Timeframe Ensemble\")\n",
    "print(f\"âœ“ Model Directory: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86402392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TRAIN data...\n",
      "  1min: 3,354,904 rows\n",
      "  5min: 671,581 rows\n",
      "  15min: 224,382 rows\n",
      "  30min: 112,194 rows\n",
      "  1h: 56,098 rows\n",
      "  4h: 14,498 rows\n",
      "\n",
      "Loading TEST data...\n",
      "  1min: 743,476 rows\n",
      "  5min: 148,502 rows\n",
      "  15min: 49,807 rows\n",
      "  30min: 24,907 rows\n",
      "  1h: 12,454 rows\n",
      "  4h: 3,220 rows\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data\n",
    "def load_tf_data(timeframe, dataset_type='train'):\n",
    "    filename = f'EURUSD_{timeframe}.csv'\n",
    "    file_path = DATA_DIR / dataset_type / filename\n",
    "        \n",
    "    if not file_path.exists():\n",
    "        print(f\"âš ï¸ Warning: {file_path} not found.\")\n",
    "        return None\n",
    "        \n",
    "    df = pd.read_csv(file_path)\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    \n",
    "    if 'time' in df.columns:\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        df.set_index('time', inplace=True)\n",
    "        df.sort_index(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "timeframes_map = {\n",
    "    '1min': 'm1',\n",
    "    '5min': 'm5',\n",
    "    '15min': 'm15',\n",
    "    '30min': 'm30',\n",
    "    '1h': 'h1',\n",
    "    '4h': 'h4'\n",
    "}\n",
    "\n",
    "dfs_train = {}\n",
    "dfs_test = {}\n",
    "\n",
    "print(\"Loading TRAIN data...\")\n",
    "for tf_name, tf_code in timeframes_map.items():\n",
    "    dfs_train[tf_name] = load_tf_data(tf_code, 'train')\n",
    "    if dfs_train[tf_name] is not None:\n",
    "        print(f\"  {tf_name}: {len(dfs_train[tf_name]):,} rows\")\n",
    "\n",
    "print(\"\\nLoading TEST data...\")\n",
    "for tf_name, tf_code in timeframes_map.items():\n",
    "    dfs_test[tf_name] = load_tf_data(tf_code, 'test')\n",
    "    if dfs_test[tf_name] is not None:\n",
    "        print(f\"  {tf_name}: {len(dfs_test[tf_name]):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c0c728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TRAIN features...\n",
      "Processing TEST features...\n",
      "Feature engineering complete.\n"
     ]
    }
   ],
   "source": [
    "# 2. Enhanced Feature Engineering (V10 Style)\n",
    "def add_features(df):\n",
    "    if df is None or len(df) == 0:\n",
    "        return None\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- Time Features ---\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['is_london'] = ((df['hour'] >= 8) & (df['hour'] < 16)).astype(int)\n",
    "    df['is_ny'] = ((df['hour'] >= 13) & (df['hour'] < 21)).astype(int)\n",
    "    \n",
    "    # --- Moving Averages ---\n",
    "    for p in [9, 21, 50, 200]:\n",
    "        df[f'ema_{p}'] = df['close'].ewm(span=p, adjust=False).mean()\n",
    "        # Distance from EMA\n",
    "        df[f'dist_ema_{p}'] = (df['close'] - df[f'ema_{p}']) / df[f'ema_{p}']\n",
    "        \n",
    "    # --- RSI ---\n",
    "    delta = df['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / (loss + 1e-10)\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # --- MACD ---\n",
    "    ema12 = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    df['macd'] = ema12 - ema26\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
    "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    \n",
    "    # --- Bollinger Bands ---\n",
    "    df['bb_mid'] = df['close'].rolling(window=20).mean()\n",
    "    df['bb_std'] = df['close'].rolling(window=20).std()\n",
    "    df['bb_upper'] = df['bb_mid'] + (df['bb_std'] * 2)\n",
    "    df['bb_lower'] = df['bb_mid'] - (df['bb_std'] * 2)\n",
    "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_mid']\n",
    "    df['bb_pos'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-10)\n",
    "    \n",
    "    # --- ATR & Volatility ---\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = (df['high'] - df['close'].shift()).abs()\n",
    "    low_close = (df['low'] - df['close'].shift()).abs()\n",
    "    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "    true_range = ranges.max(axis=1)\n",
    "    df['atr'] = true_range.rolling(14).mean()\n",
    "    df['volatility'] = df['close'].rolling(20).std()\n",
    "    \n",
    "    # --- Price Action ---\n",
    "    df['body_size'] = (df['close'] - df['open']).abs()\n",
    "    df['upper_shadow'] = df['high'] - df[['close', 'open']].max(axis=1)\n",
    "    df['lower_shadow'] = df[['close', 'open']].min(axis=1) - df['low']\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "print(\"Processing TRAIN features...\")\n",
    "processed_train = {k: add_features(v) for k, v in dfs_train.items()}\n",
    "\n",
    "print(\"Processing TEST features...\")\n",
    "processed_test = {k: add_features(v) for k, v in dfs_test.items()}\n",
    "\n",
    "print(\"Feature engineering complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1d518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating targets...\n",
      "Target creation complete.\n"
     ]
    }
   ],
   "source": [
    "# 3. Target Creation\n",
    "def create_target(df, tp_pips=10, sl_pips=10, forward_bars=15):\n",
    "    targets = []\n",
    "    pip_size = 0.0001\n",
    "    tp = tp_pips * pip_size\n",
    "    sl = sl_pips * pip_size\n",
    "    \n",
    "    closes = df['close'].values\n",
    "    highs = df['high'].values\n",
    "    lows = df['low'].values\n",
    "    \n",
    "    for i in range(len(df) - forward_bars):\n",
    "        current_close = closes[i]\n",
    "        future_highs = highs[i+1 : i+1+forward_bars]\n",
    "        future_lows = lows[i+1 : i+1+forward_bars]\n",
    "        \n",
    "        max_high = np.max(future_highs)\n",
    "        min_low = np.min(future_lows)\n",
    "        \n",
    "        if (max_high - current_close) >= tp and (current_close - min_low) < sl:\n",
    "            targets.append(1) # BUY\n",
    "        elif (current_close - min_low) >= tp and (max_high - current_close) < sl:\n",
    "            targets.append(2) # SELL\n",
    "        else:\n",
    "            targets.append(0) # HOLD\n",
    "            \n",
    "    targets.extend([0] * forward_bars)\n",
    "    return np.array(targets)\n",
    "\n",
    "print(\"Creating targets...\")\n",
    "train_datasets = {}\n",
    "test_datasets = {}\n",
    "\n",
    "for tf, df in processed_train.items():\n",
    "    if df is not None and len(df) > FORWARD_BARS:\n",
    "        df = df.copy()\n",
    "        df['target'] = create_target(df, TP_PIPS, SL_PIPS, FORWARD_BARS)\n",
    "        train_datasets[tf] = df.iloc[:-FORWARD_BARS]\n",
    "\n",
    "for tf, df in processed_test.items():\n",
    "    if df is not None and len(df) > FORWARD_BARS:\n",
    "        df = df.copy()\n",
    "        df['target'] = create_target(df, TP_PIPS, SL_PIPS, FORWARD_BARS)\n",
    "        test_datasets[tf] = df.iloc[:-FORWARD_BARS]\n",
    "\n",
    "print(\"Target creation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5b26478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model for 1min...\n",
      "  Original Size: 3354870, Balanced Size: 1136567\n",
      "  Class Dist: {0: 684057, 2: 228019, 1: 224491}\n",
      "  âœ“ 1min Model Trained.\n",
      "\n",
      "Training Model for 5min...\n",
      "  Original Size: 671547, Balanced Size: 671547\n",
      "  Class Dist: {0: 359207, 2: 157239, 1: 155101}\n",
      "  âœ“ 5min Model Trained.\n",
      "\n",
      "Training Model for 15min...\n",
      "  Original Size: 224348, Balanced Size: 224348\n",
      "  Class Dist: {0: 85696, 2: 69358, 1: 69294}\n",
      "  âœ“ 15min Model Trained.\n",
      "\n",
      "Training Model for 30min...\n",
      "  Original Size: 112160, Balanced Size: 112160\n",
      "  Class Dist: {0: 45951, 1: 33386, 2: 32823}\n",
      "  âœ“ 30min Model Trained.\n",
      "\n",
      "Training Model for 1h...\n",
      "  Original Size: 56064, Balanced Size: 56064\n",
      "  Class Dist: {0: 30945, 1: 12663, 2: 12456}\n",
      "  âœ“ 1h Model Trained.\n",
      "\n",
      "Training Model for 4h...\n",
      "  Original Size: 14464, Balanced Size: 7879\n",
      "  Class Dist: {0: 4752, 2: 1584, 1: 1543}\n",
      "  âœ“ 4h Model Trained.\n",
      "\n",
      "All models trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# 4. Training with Class Balancing\n",
    "models = {}\n",
    "scalers = {}\n",
    "feature_cols_dict = {}\n",
    "\n",
    "for tf, df_train in train_datasets.items():\n",
    "    print(f\"\\nTraining Model for {tf}...\")\n",
    "    \n",
    "    # Features\n",
    "    cols = [c for c in df_train.columns if c not in ['target', 'open', 'high', 'low', 'close', 'tick_volume', 'spread', 'volume']]\n",
    "    \n",
    "    # --- Undersampling Majority Class (HOLD) ---\n",
    "    # Separate classes\n",
    "    df_hold = df_train[df_train['target'] == 0]\n",
    "    df_buy = df_train[df_train['target'] == 1]\n",
    "    df_sell = df_train[df_train['target'] == 2]\n",
    "    \n",
    "    # Undersample HOLD to match 2x the size of minority classes (to keep some context but reduce dominance)\n",
    "    n_minority = max(len(df_buy), len(df_sell))\n",
    "    if len(df_hold) > n_minority * 3:\n",
    "        df_hold_downsampled = resample(df_hold, \n",
    "                                       replace=False,    # sample without replacement\n",
    "                                       n_samples=n_minority * 3, # match minority size * 3\n",
    "                                       random_state=42)\n",
    "    else:\n",
    "        df_hold_downsampled = df_hold\n",
    "        \n",
    "    # Combine back\n",
    "    df_balanced = pd.concat([df_hold_downsampled, df_buy, df_sell])\n",
    "    \n",
    "    X_train = df_balanced[cols]\n",
    "    y_train = df_balanced['target']\n",
    "    \n",
    "    print(f\"  Original Size: {len(df_train)}, Balanced Size: {len(df_balanced)}\")\n",
    "    print(f\"  Class Dist: {y_train.value_counts().to_dict()}\")\n",
    "    \n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Train XGBoost with scale_pos_weight equivalent logic\n",
    "    # Since we undersampled, we might not need extreme weights, but let's use a balanced approach\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=7,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='multi:softprob',\n",
    "        num_class=3,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    models[tf] = model\n",
    "    scalers[tf] = scaler\n",
    "    feature_cols_dict[tf] = cols\n",
    "    \n",
    "    print(f\"  âœ“ {tf} Model Trained.\")\n",
    "\n",
    "print(\"\\nAll models trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "188fea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for TEST set...\n",
      "\n",
      "=== TEST Ensemble Performance ===\n",
      "Overall Accuracy: 0.8886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94    674901\n",
      "           1       0.10      0.05      0.07     33974\n",
      "           2       0.15      0.02      0.03     34567\n",
      "\n",
      "    accuracy                           0.89    743442\n",
      "   macro avg       0.39      0.35      0.35    743442\n",
      "weighted avg       0.84      0.89      0.86    743442\n",
      "\n",
      "\n",
      "=== TEST Trade Only Performance (Excluding HOLD) ===\n",
      "Total Trades: 21892\n",
      "Trade Accuracy: 0.1126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     16771\n",
      "           1       0.10      0.78      0.18      2392\n",
      "           2       0.15      0.22      0.18      2729\n",
      "\n",
      "    accuracy                           0.11     21892\n",
      "   macro avg       0.08      0.33      0.12     21892\n",
      "weighted avg       0.03      0.11      0.04     21892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Evaluation\n",
    "def get_predictions(models, scalers, datasets):\n",
    "    preds_dict = {}\n",
    "    for tf, df in datasets.items():\n",
    "        if tf in models:\n",
    "            model = models[tf]\n",
    "            scaler = scalers[tf]\n",
    "            cols = feature_cols_dict[tf]\n",
    "            \n",
    "            X = df[cols]\n",
    "            X_scaled = scaler.transform(X)\n",
    "            \n",
    "            probs = model.predict_proba(X_scaled)\n",
    "            preds_df = pd.DataFrame(probs, columns=['HOLD', 'BUY', 'SELL'], index=df.index)\n",
    "            preds_dict[tf] = preds_df\n",
    "    return preds_dict\n",
    "\n",
    "def evaluate_ensemble(preds_dict, datasets, name=\"Set\"):\n",
    "    base_tf = '1min'\n",
    "    if base_tf not in datasets:\n",
    "        print(f\"Error: 1min data needed for {name} evaluation.\")\n",
    "        return\n",
    "\n",
    "    base_index = datasets[base_tf].index\n",
    "    agg_probs = pd.DataFrame(0.0, index=base_index, columns=['HOLD', 'BUY', 'SELL'])\n",
    "    \n",
    "    count = 0\n",
    "    for tf, preds_df in preds_dict.items():\n",
    "        aligned_preds = preds_df.reindex(base_index, method='ffill')\n",
    "        agg_probs = agg_probs.add(aligned_preds, fill_value=0)\n",
    "        count += 1\n",
    "        \n",
    "    final_probs = agg_probs / count\n",
    "    final_classes = final_probs.idxmax(axis=1)\n",
    "    \n",
    "    class_map = {'HOLD': 0, 'BUY': 1, 'SELL': 2}\n",
    "    y_pred = final_classes.map(class_map).fillna(0).astype(int)\n",
    "    y_true = datasets[base_tf]['target'].reindex(base_index).fillna(0).astype(int)\n",
    "    \n",
    "    print(f\"\\n=== {name} Ensemble Performance ===\")\n",
    "    print(f\"Overall Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # --- Trade Only Evaluation ---\n",
    "    trade_mask = y_pred != 0\n",
    "    if trade_mask.sum() > 0:\n",
    "        trade_preds = y_pred[trade_mask]\n",
    "        trade_actuals = y_true[trade_mask]\n",
    "        \n",
    "        print(f\"\\n=== {name} Trade Only Performance (Excluding HOLD) ===\")\n",
    "        print(f\"Total Trades: {len(trade_preds)}\")\n",
    "        print(f\"Trade Accuracy: {accuracy_score(trade_actuals, trade_preds):.4f}\")\n",
    "        print(classification_report(trade_actuals, trade_preds, zero_division=0))\n",
    "    else:\n",
    "        print(f\"\\n=== {name} Trade Only Performance ===\")\n",
    "        print(\"No trades predicted.\")\n",
    "\n",
    "print(\"Generating predictions for TEST set...\")\n",
    "test_preds = get_predictions(models, scalers, test_datasets)\n",
    "evaluate_ensemble(test_preds, test_datasets, \"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f173d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models...\n",
      "Models saved to c:\\Users\\Acer\\Desktop\\Forex-Signal-App\\models\\signal_generator_v17\n"
     ]
    }
   ],
   "source": [
    "# 6. Save Models\n",
    "print(\"Saving models...\")\n",
    "joblib.dump(models, MODEL_DIR / 'models_dict_v17.joblib')\n",
    "joblib.dump(scalers, MODEL_DIR / 'scalers_dict_v17.joblib')\n",
    "joblib.dump(feature_cols_dict, MODEL_DIR / 'feature_cols_dict_v17.joblib')\n",
    "\n",
    "config = {\n",
    "    'timeframes': TIMEFRAMES,\n",
    "    'tp_pips': TP_PIPS,\n",
    "    'sl_pips': SL_PIPS,\n",
    "    'forward_bars': FORWARD_BARS,\n",
    "    'strategy': 'hybrid_ensemble_undersampling'\n",
    "}\n",
    "joblib.dump(config, MODEL_DIR / 'config_v17.joblib')\n",
    "\n",
    "print(f\"Models saved to {MODEL_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
